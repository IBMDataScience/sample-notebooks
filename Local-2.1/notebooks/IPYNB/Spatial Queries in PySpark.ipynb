{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Spatial Queries in PySpark</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook shows you show to use use spatial queries in Spark environments. The notebook uses the spatio-temporal library that is pre-installed on all Spark environments in Watson Studio. You will learn how to perform common spatial queries in Spark. \n",
    "\n",
    "The types of spatial queries you will learn to use are:\n",
    "- In a set of points, find all the points that are within a certain distance to a particular point. For example, find all the hospitals that are within a certain distance to a given location.\n",
    "- In a set of polygons, find all the polygons that contain a particular point. For example, find all the risk areas for fires, floods, or hurricanes that contain a particular location.\n",
    "- In a set of points, find all the points that are contained within a particular polygon. For example, find all the retail outlets in a particular region.\n",
    "\n",
    "Often, a spatial function has one parameter that refers to a spatial column in one table and a second parameter that refers to a spatial constant or to a spatial column in another table. This notebook shows you how to use functions to access and combine data of different types to perform spatial queries.\n",
    "\n",
    "This notebook runs on Python 3.6 with Spark.\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "\n",
    "1.\t[Register the Spark SQL spatial functions](#register)\n",
    "2.\t[Get sample data](#getData)\n",
    "3.\t[Create a geometry column](#createColumn)\n",
    "4.\t[Register the data frames](#registerDataframe)\n",
    "5.  [Run spatial queries](#runQueries)  \n",
    "6.\t[Summary](#summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"register\"></a>\n",
    "## 1. Register the Spark SQL spatial functions\n",
    "\n",
    "Register the Spark SQL spatial functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20200115163434-0000\n",
      "KERNEL_ID = da456e33-1eb9-4712-a259-ea48799f3c08\n"
     ]
    }
   ],
   "source": [
    "spark._jvm.org.apache.spark.sql.types.SqlGeometry.registerAll(spark._jsparkSession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getData\"></a>\n",
    "## 2. Get sample data\n",
    "\n",
    "This notebook uses a sample data set that is available in the IBM Watson Studio Gallery. Direct links are used by default to make sure this notebook is publicly runnable.\n",
    "\n",
    "In your own cases, you should use your preferred way of loading data into a Spark dataframe, depending on where your data source sits.\n",
    "\n",
    "Here are some hints if you are using IBM Cloud Object Storage:\n",
    "- If your data is uploaded directly into the current project, you can simply click `Find and Add Data` button in the top right corner on the menu bar, then click `Insert SparkSession DataFrame` on the data you want. A code will be generated automatically and returns a Spark data frame.\n",
    "- If your data is hosted in a designated bucket, you can use `ibmos2spark` to read the data into a Spark data frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the hospital data where each hospital's location is a latitude-longitude point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_pdf = pd.read_csv('https://api.dataplatform.cloud.ibm.com/v2/gallery-assets/entries/5562ced564e776edc5f91e13d48d8309/data?accessKey=4d77701840fcb2f21587e39fdb063eeb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run into an error running the above code due to link not found, please download the `hospitals.csv` data set in the Watson Studio gallery and insert it manually using the method given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_schema = StructType([StructField('id', IntegerType()),\n",
    "                              StructField('name', StringType()),\n",
    "                              StructField('city', StringType()),\n",
    "                              StructField('state', StringType()),\n",
    "                              StructField('lon', DoubleType()),\n",
    "                              StructField('lat', DoubleType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df = spark.createDataFrame(hospital_pdf, hospital_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------+-----+----------+------------------+\n",
      "| id|                name|        city|state|       lon|               lat|\n",
      "+---+--------------------+------------+-----+----------+------------------+\n",
      "|  1|Southern Hills Me...|  BERRY HILL|   TN|-86.721939|         36.077843|\n",
      "|  2|Sycamore Shoals H...|ELIZABETHTON|   TN|-82.247635|         36.346218|\n",
      "|  3|     Tokona Hospital| GREENEVILLE|   TN|-82.845711|36.151771999999994|\n",
      "+---+--------------------+------------+-----+----------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hospital_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the county data where each county is a polygon/multipolygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_pdf = pd.read_csv('https://api.dataplatform.cloud.ibm.com/v2/gallery-assets/entries/c8cc28f4c30dc4d8c0b13f18c50c3244/data?accessKey=c8cc28f4c30dc4d8c0b13f18c50fa2d5'\n",
    "                          )[['NAME', 'STATE_NAME', 'POP2000', 'shape_WKT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_schema = StructType([StructField('NAME', StringType()),\n",
    "                              StructField('STATE_NAME', StringType()),\n",
    "                              StructField('POP2000', IntegerType()),\n",
    "                              StructField('shape_WKT', StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties_df = spark.createDataFrame(counties_pdf, counties_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+-------+--------------------+\n",
      "|             NAME|STATE_NAME|POP2000|           shape_WKT|\n",
      "+-----------------+----------+-------+--------------------+\n",
      "|Lake of the Woods| Minnesota|   4522|MULTIPOLYGON (((-...|\n",
      "|            Ferry|Washington|   7260|MULTIPOLYGON (((-...|\n",
      "|          Stevens|Washington|  40066|MULTIPOLYGON (((-...|\n",
      "+-----------------+----------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counties_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"createColumn\"></a>\n",
    "## 3. Create a geometry column for hospital and county data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw spatial data in the data frame can be of various types, for example **columns indicating latitude and longitude** or **column indicating wkt string for the geometry**, and so on.\n",
    "\n",
    "Therefore, the first step is to use a spatial query to generate a new spatial column that combines the data in these columns.  \n",
    "For example, use the function:\n",
    "- `ST_Point(lon_col, lat_col)` if the raw spatial data is in a latitude column and a longitude column  \n",
    "- `ST_WKTTOSQL(wkt_col)` if the raw spatial data is in a column containing the wkt string form of the geometry  \n",
    "\n",
    "For the full list of possible query functions, see [Geospatial Toolkit functions](https://www.ibm.com/support/knowledgecenter/en/SSCJDQ/com.ibm.swg.im.dashdb.analytics.doc/doc/geo_functions.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a geometry column for the hospital data using `ST_Point(lon, lat)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------------------------+------------+-----+----------+------------------+------------------------------------------------+\n",
      "|id |name                         |city        |state|lon       |lat               |location                                        |\n",
      "+---+-----------------------------+------------+-----+----------+------------------+------------------------------------------------+\n",
      "|1  |Southern Hills Medical Center|BERRY HILL  |TN   |-86.721939|36.077843         |PointEG: lat=36.077843, long=-86.721939         |\n",
      "|2  |Sycamore Shoals Hospital     |ELIZABETHTON|TN   |-82.247635|36.346218         |PointEG: lat=36.346218, long=-82.247635         |\n",
      "|3  |Tokona Hospital              |GREENEVILLE |TN   |-82.845711|36.151771999999994|PointEG: lat=36.151771999999994, long=-82.845711|\n",
      "+---+-----------------------------+------------+-----+----------+------------------+------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hospital_df.createOrReplaceTempView(\"hospitals\")\n",
    "hospital_df = spark.sql(\"SELECT *, ST_Point(lon, lat) as location from hospitals\")\n",
    "hospital_df.show(3, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a geometry column for the county data using `ST_WKTToSQL(wkt_string)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------+-------+--------------------+\n",
      "|             NAME|STATE_NAME|POP2000|               shape|\n",
      "+-----------------+----------+-------+--------------------+\n",
      "|Lake of the Woods| Minnesota|   4522|AcceleratedMultiP...|\n",
      "|            Ferry|Washington|   7260|AcceleratedMultiP...|\n",
      "|          Stevens|Washington|  40066|AcceleratedMultiP...|\n",
      "+-----------------+----------+-------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counties_df.createOrReplaceTempView('counties')\n",
    "counties_df = spark.sql(\"SELECT NAME, STATE_NAME, POP2000, ST_WKTToSQL(shape_WKT) as shape from counties\")\n",
    "counties_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"registerDataframe\"></a>\n",
    "## 4. Register the hospital and county data frames as a temporary view\n",
    "\n",
    "A data frame can also be used to create a temporary view. Registering a data frame as a table allows you to run SQL queries over its data. Register the hospital and county data frames as a temporary view: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_df.createOrReplaceTempView('hospitals')\n",
    "counties_df.createOrReplaceTempView('counties')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runQueries\"></a>\n",
    "## 5. Run spatial queries\n",
    "\n",
    "1. [Example 1: Query to determine points closest to another point](#ex1)\n",
    "1. [Example 2: Queries to determine which polygon contains a point](#ex2)\n",
    "1. [Example 3: Queries to determine the points in a polygon](#ex3)\n",
    "1. [Example 4: Spatial join queries to determine points in a polygon](#ex4)\n",
    "1. [Example 5: Spatial join queries with additional predicates and aggregation](#ex5)\n",
    "1. [Example 6: Window queries](#ex6)\n",
    "1. [Example 7: Distance queries](#ex7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ex1\"></a>\n",
    "### Example 1: Query to determine points closest to another point\n",
    "\n",
    "This sample query shows you how to find the hospitals that are within a certain distance of a given location (which is constructed using the `ST_Point` constructor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----+\n",
      "|                name|       city|state|\n",
      "+--------------------+-----------+-----+\n",
      "|Park Avenue Hospital|   BRIGHTON|   NY|\n",
      "|County Home and I...|   BRIGHTON|   NY|\n",
      "|    Genesee Hospital|   BRIGHTON|   NY|\n",
      "|   Highland Hospital|   BRIGHTON|   NY|\n",
      "|Rochester General...|IRONDEQUOIT|   NY|\n",
      "|Saint Marys Hospital|   BRIGHTON|   NY|\n",
      "|Strong Memorial H...|   BRIGHTON|   NY|\n",
      "+--------------------+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, city, state\n",
    "FROM hospitals\n",
    "WHERE ST_Distance(location, ST_Point(-77.574722, 43.146732)) < 10000.0\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ex2\"></a>\n",
    "### Example 2: Queries to determine which polygon contains a point\n",
    "\n",
    "The following sample queries show you how to use spatial functions to determine which polygon contains a given point. The examples use the following functions:\n",
    "\n",
    "1. `ST_Contains(geom1, geom2)`: returns TRUE if the `geom2` values are completely contained by the polygons identified by `geom1`.\n",
    "2. `ST_Within(geom1, geom2)`: returns TRUE if the `geom1` values are within the polygons identified by `geom2`.\n",
    "3. `ST_Intersects(geom1, geom2)`: returns TRUE if `geom1` and `geom2` intersect spatially in any way. This can be that they  touch, cross, or contain one other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  NAME|\n",
      "+------+\n",
      "|Ulster|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT NAME \n",
    "FROM counties \n",
    "WHERE ST_Contains(shape, ST_Point(-74.237, 42.037))\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  NAME|\n",
      "+------+\n",
      "|Ulster|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT NAME\n",
    "FROM counties\n",
    "WHERE\n",
    "ST_Within(ST_Point(-74.237, 42.037), shape)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  NAME|\n",
      "+------+\n",
      "|Ulster|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT NAME\n",
    "FROM counties\n",
    "WHERE\n",
    "ST_Intersects(shape, ST_Point(-74.237, 42.037))\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ex3\"></a>\n",
    "### Example 3: Queries to determine the points in a polygon\n",
    "\n",
    "Each of the following queries determine which hospitals are located within the specified polygon, which is defined as a constant using the  well-known text (WKT) representation. The polygon definition consists of the character string POLYGON followed by a pair of $x$ and $y$ coordinates for each vertex, separated by a comma. The individual $x$ and $y$ values are separated by a space. The entire list of coordinate pairs must be in parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE\n",
    "ST_Contains(ST_WKTToSQL('POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'), location)\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name \n",
    "FROM hospitals \n",
    "WHERE ST_Within(location, ST_WKTToSQL('POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name \n",
    "FROM hospitals \n",
    "WHERE ST_Intersects(location, ST_WKTToSQL('POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ex4\"></a>\n",
    "### Example 4: Spatial join queries to determine points in a polygon\n",
    "\n",
    "Just as a regular join function can join two tables based on the values in columns that contain character or numeric data, spatial join functions can be used to join tables based on the values in the columns that contain spatial data. The following examples use the **counties** and **hospitals** tables.\n",
    "\n",
    "You can use the spatial join function to find the hospitals located within a specific county. For example, the following query returns a list of all the hospitals in the Dutchess county:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|    NAME|                name|\n",
      "+--------+--------------------+\n",
      "|Dutchess|Hudson River Stat...|\n",
      "|Dutchess|Vassar Brothers H...|\n",
      "|Dutchess|      Bowne Hospital|\n",
      "|Dutchess|Harlem Valley Sta...|\n",
      "|Dutchess|Matteawan State H...|\n",
      "|Dutchess|New York State Ho...|\n",
      "|Dutchess|Saint Francis Hos...|\n",
      "|Dutchess|United States Vet...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name \n",
    "FROM counties AS c, hospitals AS h \n",
    "WHERE c.NAME = 'Dutchess' \n",
    "AND ST_Intersects(c.shape, h.location)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the SQL `JOIN ... ON ...` notation, which is equivalent to a spatial predicate in the `WHERE` clause. For example, the following query produces the same result set as the previous query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                name|    NAME|\n",
      "+--------------------+--------+\n",
      "|Hudson River Stat...|Dutchess|\n",
      "|Vassar Brothers H...|Dutchess|\n",
      "|      Bowne Hospital|Dutchess|\n",
      "|Harlem Valley Sta...|Dutchess|\n",
      "|Matteawan State H...|Dutchess|\n",
      "|New York State Ho...|Dutchess|\n",
      "|Saint Francis Hos...|Dutchess|\n",
      "|United States Vet...|Dutchess|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT h.name, c.NAME\n",
    "FROM counties AS c\n",
    "JOIN hospitals AS h\n",
    "ON c.NAME = 'Dutchess'\n",
    "AND ST_Intersects(h.location, c.shape)\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query returns the name of the county in which a particular hospital is located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|    NAME|                name|\n",
      "+--------+--------------------+\n",
      "|Dutchess|Vassar Brothers H...|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name\n",
    "FROM hospitals AS h, counties AS c\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND h.name = 'Vassar Brothers Hospital'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ex5\"></a>\n",
    "### Example 5: Spatial join queries with additional predicates and aggregation\n",
    "\n",
    "This example shows you how to use spatial joins in conjunction with additional predicates and aggregation, which can address business problems. These examples continue to use the hospitals and counties tables, but the same principles could be applied to any other type of data.\n",
    "\n",
    "The following example queries the hospitals within each county in New York state, qualifying by the state name in the counties table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|  NAME|                name|\n",
      "+------+--------------------+\n",
      "|Albany|     Albany Hospital|\n",
      "|Albany|Albany Hospital F...|\n",
      "|Albany|Albany Hospital S...|\n",
      "+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name\n",
    "FROM counties AS c, hospitals AS h\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND c.STATE_NAME='New York'\n",
    "ORDER BY c.NAME, h.name\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same results can be obtained by rewriting the above query and using the fields from the hospitals table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|  NAME|                name|\n",
      "+------+--------------------+\n",
      "|Albany|     Albany Hospital|\n",
      "|Albany|Albany Hospital F...|\n",
      "|Albany|Albany Hospital S...|\n",
      "+------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, h.name\n",
    "FROM hospitals AS h, counties AS c\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND h.state='NY'\n",
    "ORDER BY c.NAME, h.name\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following example lists the number of hospitals per county in New York:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+\n",
      "|  NAME|hospital_count|\n",
      "+------+--------------+\n",
      "|Cayuga|             1|\n",
      "| Kings|            26|\n",
      "|Monroe|             9|\n",
      "+------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, COUNT(h.name) AS hospital_count\n",
    "FROM counties AS c, hospitals AS h\n",
    "WHERE ST_Intersects(h.location, c.shape)\n",
    "AND c.STATE_NAME='New York'\n",
    "GROUP BY c.NAME\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify counties where the population is underserved by hospitals, an interesting metric might be the number of people per hospital in each county. Using the population of each county in the year 2000, you can calculate this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+----------+-------------------+\n",
      "|      NAME|hospital_count|Population|people_per_hospital|\n",
      "+----------+--------------+----------+-------------------+\n",
      "|     Bronx|             9|   1332650| 148072.22222222222|\n",
      "|Chautauqua|             1|    139750|           139750.0|\n",
      "|    Oswego|             1|    122377|           122377.0|\n",
      "+----------+--------------+----------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT c.NAME, \n",
    "COUNT(h.name) AS hospital_count, \n",
    "c.POP2000 AS Population, \n",
    "c.POP2000/COUNT(h.name) AS people_per_hospital\n",
    "FROM counties AS c, hospitals AS h\n",
    "WHERE c.STATE_NAME='New York'\n",
    "AND ST_Intersects(h.location, c.shape)\n",
    "GROUP BY c.NAME, c.POP2000\n",
    "ORDER BY people_per_hospital DESC\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With additional detail, such as number of beds, number of doctors per hospital, you could determine a better measure for health care coverage per state and population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ex6\"></a>\n",
    "### Example 6: Window queries\n",
    "\n",
    "A common use case for mapping applications, and in particular for web mapping, is to select objects that fall within a specific rectangular region. This can be done by creating a polygon to represent the rectangle and using the `ST_Intersects` spatial predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE ST_Intersects(location, ST_WKTToSQL(\n",
    " 'POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another spatial predicate that does the same is `EnvelopesIntersect`, which can be used to select objects whose envelope intersects a rectangular region called a window. `EnvelopesIntersect` takes the name of the spatial column as a parameter and four Double values representing the lower-left, and upper-right corners of the rectangle. This spatial predicate is simpler to use and is more efficient than `ST_Intersects` for rectangular windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE EnvelopesIntersect(location, -74.0, 42.0, -73.0, 43.0)\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this predicate is true if any portion of a line or polygon geometry falls within the specified window, parts of the line or polygon might lie outside of the window. This is generally not a problem with mapping applications, which will discard geometries that lie outside the display window.\n",
    "\n",
    "When building web-mapping applications with widely used web-mapping APIs from providers such as Google Maps, Yahoo! Maps, Bing Maps, and others, it is necessary to provide the longitude and latitude values to be used in placing custom markers on the map. You can get this information by using a query such as the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+\n",
      "|                name| longitude| latitude|\n",
      "+--------------------+----------+---------+\n",
      "|   Marshall Hospital|-73.678177|42.718971|\n",
      "|Southwestern Medi...|-73.206772|42.874249|\n",
      "|  Hillcrest Hospital|-73.280113|42.457863|\n",
      "+--------------------+----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_X(location) AS longitude, ST_Y(location) AS latitude\n",
    "FROM hospitals\n",
    "WHERE EnvelopesIntersect(location, -74.0, 42.0, -73.0, 43.0)\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"ex7\"></a>\n",
    "### Example 7: Distance queries\n",
    "\n",
    "Another common spatial query is to find things within a specified distance of a particular location. You have probably used web-mapping applications to get this kind of information. You can issue SQL queries from your application for questions like:\n",
    "\n",
    "- Find customers within 10 miles of a store\n",
    "- Find ATMs within 500 meters of the current location\n",
    "- Find competitive stores within 10 kilometers of a proposed store location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spatial function used for these queries is `ST_Distance`, which computes the distance between the spatial values and returns a result in meters. \n",
    "\n",
    "The following query generates eight results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|   Marshall Hospital|\n",
      "|Southwestern Medi...|\n",
      "|  Hillcrest Hospital|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE ST_Intersects(location, ST_WKTToSQL(\n",
    " 'POLYGON ((-74.0 42.0, -73.0 42.0, -73.0 43.0, -74.0 43.0, -74.0 42.0))'))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different way of querying the same location above is to use the `ST_Buffer` function, where a circular buffer is created around the given geometry and the desired geometries within that buffer are determined. The `ST_Buffer` function takes as parameters a spatial geometry and a distance in meters to the buffer around this spatial value. The results are the same as when you us `ST_Intersects`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                name|\n",
      "+--------------------+\n",
      "|      Adventist Home|\n",
      "|      Bowne Hospital|\n",
      "|Columbia Memorial...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name\n",
    "FROM hospitals\n",
    "WHERE\n",
    "ST_Intersects(location,\n",
    "  ST_Buffer(ST_Point(-74.237, 42.037), 46800.0))\n",
    "ORDER BY name\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query returns the distance from a specified point to each object within a 30 mile (or approximately 46800m) radius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                name|          distance|\n",
      "+--------------------+------------------+\n",
      "|Greene County Mem...| 36634.88406671428|\n",
      "|      Adventist Home|39014.090792071736|\n",
      "|Hudson River Stat...| 43362.54508885234|\n",
      "+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_Distance(location, ST_Point(-74.237, 42.037)) AS distance\n",
    "FROM hospitals\n",
    "WHERE ST_Distance(location, ST_Point(-74.237, 42.037)) < 46800.0\n",
    "ORDER BY distance\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could also use `ST_Buffer` to compute the spatial relation and then determine the distance as is shown in the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|                name|          distance|\n",
      "+--------------------+------------------+\n",
      "|Greene County Mem...| 36634.88406671428|\n",
      "|      Adventist Home|39014.090792071736|\n",
      "|Hudson River Stat...| 43362.54508885234|\n",
      "+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_Distance(location, ST_Point(-74.237, 42.037)) AS distance\n",
    "FROM hospitals\n",
    "WHERE\n",
    "  ST_Intersects(location,\n",
    "  ST_Buffer(ST_Point(-74.237, 42.037), 46800.0))\n",
    "ORDER BY distance\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference to be noted here is that the `ST_Buffer` in this package supports buffering of arbitrary geometries and can be used to compute in that manner. Note that:\n",
    "- The `ST_Buffer` query on large geometries can be expensive.\n",
    "- For a large number of geometries, the user is advised to calculate the buffers separately, store the buffers in columns, and operate on the stored buffers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------------------------------------------------------------+\n",
      "|                name|UDF:ST_Distance(location, UDF:ST_WKTToSQL(LINESTRING (-74.0 42.0, -73.0 42.0)))|\n",
      "+--------------------+-------------------------------------------------------------------------------+\n",
      "|      Avery Hospital|                                                              38777.96495714722|\n",
      "|   Hartford Hospital|                                                               38204.0148377887|\n",
      "|Springfield Munic...|                                                              39761.18673983218|\n",
      "+--------------------+-------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT name, ST_Distance(location, ST_WKTToSQL(\n",
    " 'LINESTRING (-74.0 42.0, -73.0 42.0)'))\n",
    "FROM hospitals\n",
    "WHERE ST_Intersects(location, ST_Buffer(ST_WKTToSQL(\n",
    " 'LINESTRING (-74.0 42.0, -73.0 42.0)'), 46800.0))\n",
    "\"\"\").show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "##  Summary\n",
    "\n",
    "In this notebook, you learned how to query spatial data you downloaded from the IBM Watson Studio Gallery. You registered each data frame (one with data on hospitals and another with county information) as a table to run your queries on. The sample queries showed you how to determine the hospitals within a certain distance or in a polygon, to find the name of the county in which a hospital is located, or to identify the counties where the population is underserved by hospitals. The sample queries showed you how to use and combine the most common Spark SQL spatial functions in queries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "**Linsong Chu**, Research Engineer at IBM Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
