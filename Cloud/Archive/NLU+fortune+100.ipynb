{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=\"https://www.ibm.com/blogs/bluemix/wp-content/uploads/2017/02/NLU.png\", width=270, height=270, align = 'right'> \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/IBM_logo.svg/640px-IBM_logo.svg.png\", width = 90, height = 90, align = 'right', style=\"margin:0px 25px\"></div>\n",
    "\n",
    "# Retrieve DataFrames to visualize data from IBM Watson Natural Language Understanding\n",
    "\n",
    "In this R notebook, you'll use IBM Watson Natural Language Understanding (NLU) to analyze keywords from the websites of the Fortune 100 companies. You'll convert the results of NLU into a set of R DataFrames that you can easily analyze in a notebook. Then you'll create a visual representation of the keywords. \n",
    "\n",
    "Data scientists use NLU to uncover insights about sentiment and emotion from structured and unstructured data and to analyze text to extract metadata, such as concepts, entities, keywords, categories, relations, and semantic roles. NLU returns both the overall sentiment and emotion for the whole document and the specific sentiment and emotion for each of the keywords in the text, for deeper analysis.\n",
    "\n",
    "To start with that tutorial, see [Visualize a customer base with Watson NLU](#visualize). To read a little more about the technology and some of the other fun things you can do, see [Getting personal about Watson Natural Language Understanding](#about) and [Using R & Watson NLU](#using_r). \n",
    "\n",
    "This notebook runs on R with Spark 2.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1.  [Getting personal about Watson Natural Language Understanding](#about)<br>\n",
    "    1.1  [What data do we get from Watson NLU?](#what_data)\n",
    "\n",
    "2.  [Using R & Watson NLU](#using_r)<br>\n",
    "    2.1  [Using the `httr` and `jsonlite` packages](#httr)<br>\n",
    "    2.2  [Functional access to Watson NLU](#functiondetails) <br>\n",
    "    2.3  [Understand the `watsonNLUtoDF()` package](#watsonnlutodf)<br>\n",
    "\n",
    "3.  [Visualize a customer base with Watson NLU](#visualize)<br>\n",
    "    3.1  [Load the customer data](#visualize1) <br>\n",
    "    3.2  [Shape the data for the NLU function](#visualize2)<br>\n",
    "    3.3  [Send customersDF to Watson](#visualize3)<br>\n",
    "    3.4  [Concatenate the concepts and keywords extracted from Watson](#visualize4)<br>\n",
    "    3.5  [Format the Text for a Word Cloud](#visualize5)<br>\n",
    "    3.6  [Visualize with the Brunel library](#visualize6)<br>\n",
    "\n",
    "[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='about'></a>\n",
    "## 1. Getting personal about Watson Natural Language Understanding \n",
    "\n",
    "The first time I tested Watson NLU a huge grin spread across my face. For me it was one another one of those moments where technology inspired awe - sort of like when I played my first PC game as a kid in 1990 or when I saw the iPhone in 2006.  So what exactly is Watson NLU? \n",
    "\n",
    "> *With a sophisticated suite of natural language processing capabilities, NLU can analyze text and extract meta-data from unstructured content such as concepts, entities, keywords, categories, sentiment, emotion, relations, semantic roles. You can also customize the text analysis with NLU for linguistic nuances specific to your domain or industry (such as entities and relations) with custom models developed using Watson Knowledge Studio. With customization, you can further improve the accuracy of meta-data extraction. Whether it is social media monitoring, content recommendation, or advertising optimization, NLU can be easily put to use for extracting the hard to find insights from unstructured content.*  \n",
    "\n",
    "> Source: __[IBM Bluemix Blog](https://www.ibm.com/blogs/bluemix/2017/02/hello-nlu/)__\n",
    "\n",
    "In other words, the NLU service allows you to send unstructured data to Watson and have it return a rich set of structured data.  For example, you can send Watson a block of text and it will understand the information contained therein. Alternatively, you can send a URL and extract all the information from it.\n",
    "\n",
    "Ok, sounds kinda cool, but what's the 'wow' factor?  Read on.\n",
    "\n",
    "<a id='what_data'></a>\n",
    "### 1.1 What data do we get from Watson NLU?\n",
    "\n",
    "The easiest way to get a sense of what NLU does is to __[try the demo](https://natural-language-understanding-demo.mybluemix.net/)__.  So, go there and come back after you've played around with submitting different URLs and text to the service.  \n",
    "\n",
    "Back?  Are you impressed yet?  You must be!  As you saw, we get detailed information about the concepts, sentiment, and categorization of the data we send to Watson.  \n",
    "\n",
    "<a id='using_r'></a>\n",
    "## 2. Using R and Watson NLU\n",
    "\n",
    "I wanted to work with the data from NLU in R but there didn't seem to be many resources available online.  Rather than work directly with the JSON returned by the service, I decided to write a function - `watsonNLUtoDF()` - that converts NLU results from JSON into a list of R DataFrames.  To do so, I had to use two excellent R packages.\n",
    "\n",
    "<a id='httr'></a>\n",
    "### 2.1 The `httr` and `jsonlite` packages\n",
    "\n",
    "The `httr` package is one of the many packages for R that is written by Hadley Wickham. It provides access to `curl` functionality from inside of R, and its simplicity is classic Hadley. For example, if to run `POST()` or `GET()` using a URL is easy. You must include authentication and JSON-structured data in the `POST()` to Watson NLU:\n",
    "\n",
    "> `> POST(URL, authenticate(username, password), body = toJSON(list(features)))`\n",
    "\n",
    "You'll notice the `toJSON()` function in there.  That comes from the `jsonlite` package, which offers excellent support for converting R objects to and from JSON.  As you can see this came in handy when I needed to send JSON to Watson NLU.  It is also essential in parsing the response from Watson into R DataFrames. \n",
    "\n",
    "These two packages let me access Watson NLU from R, but I still needed a way to access the API in a more programmatic, scalable fashion. That's why I wrote the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functiondetails'></a>\n",
    "### 2.2 Functional access to Watson NLU\n",
    "\n",
    "You need to define the function to access NLU and understand its usage and arguments. You can skip ahead and look at the [function documentation](#watsonnlutodf). But before you can run the function, you need to get NLU credentials and import packages.\n",
    "\n",
    "Sign up for NLU and add your NLU credentials:\n",
    "1. Create a service for [Natural Language Understanding (NLU)](https://www.ibm.com/watson/developercloud/natural-language-understanding.html). \n",
    "1. Insert the username and password values for your NLU service in the following cell. \n",
    "1. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@hidden_cell\n",
    "# Add your Watson Natural Language Understanding service credentials\n",
    "username <- \"YOUR USERNAME\"\n",
    "password <- \"YOUR PASSWORD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs’\n",
      "(as ‘lib’ is unspecified)\n",
      "Installing package into ‘/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs’\n",
      "(as ‘lib’ is unspecified)\n",
      "Warning message in install.packages(\"devtools\"):\n",
      "“installation of package ‘devtools’ had non-zero exit status”Downloading GitHub repo Brunel-Visualization/Brunel@v2.3\n",
      "from URL https://api.github.com/repos/Brunel-Visualization/Brunel/zipball/v2.3\n",
      "Installing brunel\n",
      "Installing 1 package: jsonlite\n",
      "Installing package into ‘/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs’\n",
      "(as ‘lib’ is unspecified)\n",
      "Warning message in utils::install.packages(pkgs, repos = repos, type = type, dependencies = dependencies, :\n",
      "“installation of package ‘jsonlite’ had non-zero exit status”'/usr/local/src/bluemix_jupyter_bundle/R/lib64/R/bin/R' --no-site-file  \\\n",
      "  --no-environ --no-save --no-restore --quiet CMD INSTALL  \\\n",
      "  '/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/notebook/tmp/RtmpQmCd2q/devtools55692a2bc741/Brunel-Visualization-Brunel-451378a/R'  \\\n",
      "  --library='/gpfs/global_fs01/sym_shared/YPProdSpark/user/sc3e-53554f95eddadf-4e28db014a7c/R/libs'  \\\n",
      "  --install-tests \n",
      "\n",
      "Loading required package: NLP\n",
      "\n",
      "Attaching package: ‘httr’\n",
      "\n",
      "The following object is masked from ‘package:NLP’:\n",
      "\n",
      "    content\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This notebook uses version 2.3 of Brunel. If the version changes in the future, the visualization may not work and you will need \n",
    "# to update the version number in the code. \n",
    " \n",
    "install.packages('tm')\n",
    "install.packages(\"devtools\")\n",
    "devtools::install_github(\"Brunel-Visualization/Brunel\", subdir=\"R\", ref=\"v2.3\", force=TRUE)\n",
    "library(brunel)\n",
    "library(tm)\n",
    "library(httr)\n",
    "library(jsonlite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to retrieve DataFrames from the Watson API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watsonNLUtoDF <- function(data, username, password, verbose = F, language = 'en') {\n",
    "  \n",
    "  ## Url for Watson NLU service on Bluemix used to POST (send) content to the service to have it analyzed.  \n",
    "  ## For more details: https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#post-analyze \n",
    "  base_url <- \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze?version=2017-02-27\"\n",
    "  \n",
    "    ## Initialize Empty DataFrames\n",
    "  conceptsDF <- data.frame()\n",
    "  keywordsDF <- data.frame()\n",
    "  sentimentDF <- data.frame()\n",
    "  categoriesDF <- data.frame()\n",
    "  analyzedTextDF <- data.frame()\n",
    "  \n",
    "  ## Loop over each id, identify the type and send the value to Watson\n",
    "  for (i in 1:nrow(data)){\n",
    "    try({\n",
    "      \n",
    "      id <- data$id[i]\n",
    "      value <- data$value[i]\n",
    "      \n",
    "      ## Define the JSON payload for NLU\n",
    "      body <- list(api_endpoint = value, \n",
    "                   features = list(\n",
    "                     categories = {},\n",
    "                     concepts = {},\n",
    "                     keywords = {},\n",
    "                     sentiment = {}),\n",
    "                   language = language,\n",
    "                   return_analyzed_text = TRUE)\n",
    "      \n",
    "      ## Provide the correct type for each id\n",
    "      names(body)[1] <- data$type[i]\n",
    "      \n",
    "      if(verbose == T){\n",
    "      print(paste(\"Sending\", data$type[i], \"for\", id, \"to Watson NLU...\"))\n",
    "      }\n",
    "      \n",
    "      ## Hit the API and return JSON\n",
    "      watsonResponse <- POST(base_url,\n",
    "                             content_type_json(),\n",
    "                             authenticate(username, password, type = \"basic\"),\n",
    "                             body = toJSON(body, auto_unbox = T)) \n",
    "\n",
    "        ## Parse JSON into DataFrames\n",
    "      concepts <- data.frame(id = id, \n",
    "                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$concepts,\n",
    "                             stringsAsFactors = F)\n",
    "\n",
    "      keywords <- data.frame(id = id, \n",
    "                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$keywords,\n",
    "                             stringsAsFactors = F)\n",
    "      \n",
    "      sentiment <- data.frame(id = id, \n",
    "                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$sentiment,\n",
    "                             stringsAsFactors = F)\n",
    "      \n",
    "      categories <- data.frame(id = id,\n",
    "                               fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$categories,\n",
    "                               stringsAsFactors = F)\n",
    "      \n",
    "      analyzedText <- data.frame(id = id,\n",
    "                                 fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$analyzed_text,\n",
    "                                 stringsAsFactors = F)\n",
    "      \n",
    "      \n",
    "      ## Append results to output DataFrames\n",
    "      conceptsDF <- rbind(conceptsDF, concepts)\n",
    "      keywordsDF <- rbind(keywordsDF, keywords)\n",
    "      sentimentDF <- rbind(sentimentDF, sentiment)\n",
    "      categoriesDF <- rbind(categoriesDF, categories)\n",
    "      analyzedTextDF <- rbind(analyzedTextDF, analyzedText)\n",
    "      \n",
    "      if(verbose == T) {\n",
    "      print(paste(\"Iteration\", i, \"of\", nrow(data), \"complete.\"))\n",
    "      }\n",
    "    })\n",
    "  }\n",
    "  resultsList <- list(conceptsDF, keywordsDF, sentimentDF, categoriesDF, analyzedTextDF, watsonResponse)\n",
    "  names(resultsList) <- c(\"conceptsDF\", \"keywordsDF\", \"sentimentDF\", \"categoriesDF\", \"analyzedTextDF\", \"response\")\n",
    "  return(resultsList)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='watsonnlutodf'></a>\n",
    "### 2.3 Understand the `watsonNLUtoDF()` function\n",
    "\n",
    "#### Usage\n",
    " > `watsonNLUtoDF(data, username, password, verbose = F, language = 'en')`\n",
    "\n",
    "#### Arguments\n",
    " > - **data:** *DataFrame* with 3 columns: \n",
    "     - `id` *(string)* \n",
    "     - `type` *(string)*, must be one of `url` or `text` - think of this as which API endpoint you want to submit to. \n",
    "     - `value` *(string)*, contains the data you want to send.\n",
    "     \n",
    " > * **username:** *string*.  User name for the NLU service on Bluemix.\n",
    " \n",
    " > * **password:** *string*.  Password for the NLU service on Bluemix.\n",
    " \n",
    " > * **verbose**: *boolean*.  Print messages showing progress. Defaults to `F`.\n",
    " \n",
    " > * **language**: *string*.  Default is English. [See the API docs](https://www.ibm.com/watson/developercloud/doc/natural-language-understanding/#supported-languages) for available options.\n",
    " \n",
    "#### Value\n",
    "\n",
    " > A *list* of five dataframes extracted from the service:\n",
    "     1. conceptsDF\n",
    "     2. keywordsDF\n",
    "     3. sentimentDF\n",
    "     4. categoriesDF\n",
    "     5. analyzedTextDF\n",
    "  \n",
    "#### Example:\n",
    "Create a DataFrame with `id`, `type`, and `value` columns that contains a row with a URL and a row with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>type</th><th scope=col>value</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Seattle Seahawks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr>\n",
       "\t<tr><td>Seattle Sounders                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </td><td>From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n",
       "                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n",
       "                           Major League Soccer (MLS) and are the league's current defending champions, having won\n",
       "                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n",
       "                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n",
       "                           Sounders name being part of a legacy which traces back to the original team of the NASL\n",
       "                           in 1974.</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " id & type & value\\\\\n",
       "\\hline\n",
       "\t Seattle Seahawks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             & url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          & www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \\\\\n",
       "\t Seattle Sounders                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             & text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         & From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n",
       "                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n",
       "                           Major League Soccer (MLS) and are the league's current defending champions, having won\n",
       "                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n",
       "                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n",
       "                           Sounders name being part of a legacy which traces back to the original team of the NASL\n",
       "                           in 1974.\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  id               type\n",
       "1 Seattle Seahawks url \n",
       "2 Seattle Sounders text\n",
       "  value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1 www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "2 From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \\n                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \\n                           Major League Soccer (MLS) and are the league's current defending champions, having won\\n                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\\n                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \\n                           Sounders name being part of a legacy which traces back to the original team of the NASL\\n                           in 1974."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- data.frame(id = c(\"Seattle Seahawks\", \"Seattle Sounders\"), \n",
    "                 type = c(\"url\", \"text\"),\n",
    "                 value = c(\"www.seahawks.com\", \n",
    "                           \"From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n",
    "                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n",
    "                           Major League Soccer (MLS) and are the league's current defending champions, having won\n",
    "                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n",
    "                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n",
    "                           Sounders name being part of a legacy which traces back to the original team of the NASL\n",
    "                           in 1974.\"),\n",
    "                 stringsAsFactors = F)\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `watsonNLUtoDF` function on the DataFrame and specify to return a DataFrame of concepts and a DataFrame of categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Sending url for Seattle Seahawks to Watson NLU...\"\n",
      "[1] \"Iteration 1 of 2 complete.\"\n",
      "[1] \"Sending text for Seattle Sounders to Watson NLU...\"\n",
      "[1] \"Iteration 2 of 2 complete.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>text</th><th scope=col>relevance</th><th scope=col>dbpedia_resource</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Seattle Seahawks                                    </td><td>National Football League                            </td><td>0.9576                                              </td><td>http://dbpedia.org/resource/National_Football_League</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                              </td><td>Kansas City Chiefs                            </td><td>0.545                                         </td><td>http://dbpedia.org/resource/Kansas_City_Chiefs</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                            </td><td>Seattle Seahawks                            </td><td>0.5177                                      </td><td>http://dbpedia.org/resource/Seattle_Seahawks</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                        </td><td>Pete Carroll                            </td><td>0.4893                                  </td><td>http://dbpedia.org/resource/Pete_Carroll</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                                                      </td><td>National Football League exhibition season                            </td><td>0.3404                                                                </td><td>http://dbpedia.org/resource/National_Football_League_exhibition_season</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                         </td><td>Season ticket                            </td><td>0.3399                                   </td><td>http://dbpedia.org/resource/Season_ticket</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " id & text & relevance & dbpedia\\_resource\\\\\n",
       "\\hline\n",
       "\t Seattle Seahawks                                         & National Football League                                 & 0.9576                                                   & http://dbpedia.org/resource/National\\_Football\\_League\\\\\n",
       "\t Seattle Seahawks                                   & Kansas City Chiefs                                 & 0.545                                              & http://dbpedia.org/resource/Kansas\\_City\\_Chiefs\\\\\n",
       "\t Seattle Seahawks                               & Seattle Seahawks                               & 0.5177                                         & http://dbpedia.org/resource/Seattle\\_Seahawks\\\\\n",
       "\t Seattle Seahawks                           & Pete Carroll                               & 0.4893                                     & http://dbpedia.org/resource/Pete\\_Carroll\\\\\n",
       "\t Seattle Seahawks                                                               & National Football League exhibition season                                     & 0.3404                                                                         & http://dbpedia.org/resource/National\\_Football\\_League\\_exhibition\\_season\\\\\n",
       "\t Seattle Seahawks                            & Season ticket                               & 0.3399                                      & http://dbpedia.org/resource/Season\\_ticket\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  id               text                                       relevance\n",
       "1 Seattle Seahawks National Football League                   0.9576   \n",
       "2 Seattle Seahawks Kansas City Chiefs                         0.545    \n",
       "3 Seattle Seahawks Seattle Seahawks                           0.5177   \n",
       "4 Seattle Seahawks Pete Carroll                               0.4893   \n",
       "5 Seattle Seahawks National Football League exhibition season 0.3404   \n",
       "6 Seattle Seahawks Season ticket                              0.3399   \n",
       "  dbpedia_resource                                                      \n",
       "1 http://dbpedia.org/resource/National_Football_League                  \n",
       "2 http://dbpedia.org/resource/Kansas_City_Chiefs                        \n",
       "3 http://dbpedia.org/resource/Seattle_Seahawks                          \n",
       "4 http://dbpedia.org/resource/Pete_Carroll                              \n",
       "5 http://dbpedia.org/resource/National_Football_League_exhibition_season\n",
       "6 http://dbpedia.org/resource/Season_ticket                             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>$categoriesDF</strong> = <table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>score</th><th scope=col>label</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Seattle Seahawks</td><td>0.9999          </td><td>/sports/football</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                      </td><td>0.3846                                </td><td>/business and industrial/business news</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                                            </td><td>0.2957                                                      </td><td>/technology and computing/internet technology/social network</td></tr>\n",
       "\t<tr><td>Seattle Sounders</td><td>0.7794          </td><td>/sports/soccer  </td></tr>\n",
       "\t<tr><td>Seattle Sounders  </td><td>0.3538            </td><td>/sports/gymnastics</td></tr>\n",
       "\t<tr><td>Seattle Sounders</td><td>0.2107          </td><td>/real estate    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\textbf{\\$categoriesDF} = \\begin{tabular}{r|lll}\n",
       " id & score & label\\\\\n",
       "\\hline\n",
       "\t Seattle Seahawks & 0.9999           & /sports/football\\\\\n",
       "\t Seattle Seahawks                       & 0.3846                                 & /business and industrial/business news\\\\\n",
       "\t Seattle Seahawks                                             & 0.2957                                                       & /technology and computing/internet technology/social network\\\\\n",
       "\t Seattle Sounders & 0.7794           & /sports/soccer  \\\\\n",
       "\t Seattle Sounders   & 0.3538             & /sports/gymnastics\\\\\n",
       "\t Seattle Sounders & 0.2107           & /real estate    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "$categoriesDF\n",
       "                id  score\n",
       "1 Seattle Seahawks 0.9999\n",
       "2 Seattle Seahawks 0.3846\n",
       "3 Seattle Seahawks 0.2957\n",
       "4 Seattle Sounders 0.7794\n",
       "5 Seattle Sounders 0.3538\n",
       "6 Seattle Sounders 0.2107\n",
       "                                                         label\n",
       "1                                             /sports/football\n",
       "2                       /business and industrial/business news\n",
       "3 /technology and computing/internet technology/social network\n",
       "4                                               /sports/soccer\n",
       "5                                           /sports/gymnastics\n",
       "6                                                 /real estate\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Send properly formatted DataFrame with credentials to Watson\n",
    "responseList <- watsonNLUtoDF(df, username, password, verbose = T)\n",
    "\n",
    "head(responseList$conceptsDF)\n",
    "head(responseList[4]) ## 'categories'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first returned DataFrame shows which concepts are most important. The second returned DataFrame shows which categories best describe the text. Watson is very confident that the text is about football! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize'></a>\n",
    "\n",
    "## 3. Visualize a customer base with Watson NLU\n",
    "\n",
    "At this point, you should have a good idea of what the NLU service provides and how you've accessed it in R. Now have a little fun and visualize some output.\n",
    "\n",
    "The data science goal of this notebook is understanding market segmentation across a customer base.  **Can you use an AI engine to better understand and classify both existing and potential customers?  Watson is well suited for this task!**  Use the `watsonNLUtoDF` function to send Watson a DataFrame full of company names and a mix of their URLs and text descriptions. Then  build a word cloud with the concepts and keywords that are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='visualize1'></a>\n",
    "### 3.1  Load the customer data\n",
    "Download the data set from the DSX community and load it into a DataFrame.\n",
    "\n",
    "To load the data:\n",
    "1. Go to the [Fortune 100 companies data set](https://apsportal.ibm.com/exchange/public/entry/view/4d26cd0dd964734bc23c6475a8dc454b) on the DSX Community. \n",
    "2. Click the download icon and save the data set as .csv file to your computer.  \n",
    "3. Load the `fortune100.csv` file into your notebook. Click the **Find and Add Data** icon on the notebook action bar. Drop the file into the box or browse to select the file. The file is loaded to your object storage and appears in the Data Assets section of the project. For more information, see <a href=\"https://datascience.ibm.com/docs/content/analyze-data/load-and-access-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">Load and access data</a>.\n",
    "4. To load the data from the `fortune100.csv` file into a R DataFrame, click in the next code cell and select **Insert to code > Insert R DataFrame** under the file name.\n",
    "5. Rename the two instances of `df.data.x` to `customersDF` in the last two lines.\n",
    "6. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: RCurl\n",
      "Loading required package: bitops\n",
      "\n",
      "Attaching package: ‘RCurl’\n",
      "\n",
      "The following object is masked from ‘package:SparkR’:\n",
      "\n",
      "    base64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>type</th><th scope=col>value</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Walmart                         </td><td>url                             </td><td>http://www.walmart.com          </td></tr>\n",
       "\t<tr><td>Exxon Mobil                     </td><td>url                             </td><td>http://www.exxonmobil.com       </td></tr>\n",
       "\t<tr><td>Apple                           </td><td>url                             </td><td>http://www.apple.com            </td></tr>\n",
       "\t<tr><td>Berkshire Hathaway              </td><td>url                             </td><td>http://www.berkshirehathaway.com</td></tr>\n",
       "\t<tr><td>McKesson                        </td><td>url                             </td><td>http://www.mckesson.com         </td></tr>\n",
       "\t<tr><td>UnitedHealth Group              </td><td>url                             </td><td>http://www.unitedhealthgroup.com</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " id & type & value\\\\\n",
       "\\hline\n",
       "\t Walmart                          & url                              & http://www.walmart.com          \\\\\n",
       "\t Exxon Mobil                      & url                              & http://www.exxonmobil.com       \\\\\n",
       "\t Apple                            & url                              & http://www.apple.com            \\\\\n",
       "\t Berkshire Hathaway               & url                              & http://www.berkshirehathaway.com\\\\\n",
       "\t McKesson                         & url                              & http://www.mckesson.com         \\\\\n",
       "\t UnitedHealth Group               & url                              & http://www.unitedhealthgroup.com\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  id                 type value                           \n",
       "1 Walmart            url  http://www.walmart.com          \n",
       "2 Exxon Mobil        url  http://www.exxonmobil.com       \n",
       "3 Apple              url  http://www.apple.com            \n",
       "4 Berkshire Hathaway url  http://www.berkshirehathaway.com\n",
       "5 McKesson           url  http://www.mckesson.com         \n",
       "6 UnitedHealth Group url  http://www.unitedhealthgroup.com"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data using Insert to code > Insert R DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize2'></a>\n",
    "### 3.2 Shape the data for the NLU function\n",
    "\n",
    "The DataFrame already has correctly named columns of `id`, `type`, and `value`. Make sure that all the column types are strings:\n",
    "\n",
    "1. Copy the value of the `file` argument from the `read.csv` function in the previous cell and replace the text `YOUR_VALUE`. For example: <br>\n",
    "    `file = getObjectStorageFileWithCredentials_xxxxxxxxx(\"<your project>\", \"fortune100.csv\")`\n",
    "1. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t100 obs. of  3 variables:\n",
      " $ id   : chr  \"Walmart\" \"Exxon Mobil\" \"Apple\" \"Berkshire Hathaway\" ...\n",
      " $ type : chr  \"url\" \"url\" \"url\" \"url\" ...\n",
      " $ value: chr  \"http://www.walmart.com\" \"http://www.exxonmobil.com\" \"http://www.apple.com\" \"http://www.berkshirehathaway.com\" ...\n"
     ]
    }
   ],
   "source": [
    "# Copy and past the read.csv command from the cell above, adding 'stringsAsFactors = F' as an additional parameter \n",
    "# to ensure that column types are returned as strings\n",
    "#   ex: customersDF <-  read.csv(file = getObjectStorageFileWithCredentials_xxxxxxxxx(\"<your project>\", \"fortune100.csv\"), stringsAsFactors = F)\n",
    "\n",
    "customersDF <-  read.csv(file = YOUR VALUE), stringsAsFactors = F)\n",
    "\n",
    "str(customersDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Looks good!  \n",
    "\n",
    "<a id='visualize3'></a>\n",
    "### 3.3 Send `customersDF`  to Watson \n",
    "Run the `watsonNLUtoDF` function to send the customersDF DataFrame to Watson NLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "responseList <- watsonNLUtoDF(customersDF, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize4'></a>\n",
    "### 3.4 Concatenate the concepts and keywords extracted from Watson \n",
    "Now concatenate the resulting concepts and keywords lists into a customerDocument DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "customerDocument <- paste(responseList$concepts$text, responseList$keywords$text, sep = \" \", collapse = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize5'></a>\n",
    "### 3.5 Format the Text for a Word Cloud\n",
    "Use functions from the R tm package to format the text so that you can create a word cloud:\n",
    "\n",
    "- Remove punctuation, numbers, and spaces\n",
    "- Remove very short words and very long words\n",
    "- Calculate the frequency of each word\n",
    "- Drop words that appear 8 or fewer times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create Corpus from concatenated text\n",
    "customerCorpus <- Corpus(VectorSource(customerDocument))\n",
    "\n",
    "## Scrub text\n",
    "customerCorpus <- tm_map(customerCorpus, removePunctuation)\n",
    "customerCorpus <- tm_map(customerCorpus, removeNumbers)\n",
    "customerCorpus <- tm_map(customerCorpus, stripWhitespace)\n",
    "\n",
    "## Remove words less than 4 characters or greater than 20\n",
    "customerTDM <- TermDocumentMatrix(customerCorpus, control = list(wordLengths = c(4, 20)))\n",
    "\n",
    "## Calculate word frequencies\n",
    "wordFreqDF <- data.frame(word = row.names(as.matrix(customerTDM)), freq = as.vector(customerTDM))\n",
    "\n",
    "## Drop words with a count less than 8\n",
    "wordFreqDF <- subset(wordFreqDF, freq >= 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the resulting wordFreDF DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>word</th><th scope=col>freq</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>6</th><td>access     </td><td> 9         </td></tr>\n",
       "\t<tr><th scope=row>56</th><td>airlines   </td><td>21         </td></tr>\n",
       "\t<tr><th scope=row>57</th><td>airport    </td><td> 8         </td></tr>\n",
       "\t<tr><th scope=row>67</th><td>amazon     </td><td>22         </td></tr>\n",
       "\t<tr><th scope=row>69</th><td>america    </td><td>16         </td></tr>\n",
       "\t<tr><th scope=row>71</th><td>american   </td><td>23         </td></tr>\n",
       "\t<tr><th scope=row>80</th><td>annual     </td><td> 8         </td></tr>\n",
       "\t<tr><th scope=row>82</th><td>annuity    </td><td> 9         </td></tr>\n",
       "\t<tr><th scope=row>90</th><td>apple      </td><td>19         </td></tr>\n",
       "\t<tr><th scope=row>92</th><td>appliance  </td><td>13         </td></tr>\n",
       "\t<tr><th scope=row>115</th><td>artificial </td><td>11         </td></tr>\n",
       "\t<tr><th scope=row>126</th><td>association</td><td> 8         </td></tr>\n",
       "\t<tr><th scope=row>132</th><td>attachments</td><td> 8         </td></tr>\n",
       "\t<tr><th scope=row>159</th><td>bank       </td><td>26         </td></tr>\n",
       "\t<tr><th scope=row>169</th><td>battery    </td><td>24         </td></tr>\n",
       "\t<tr><th scope=row>181</th><td>best       </td><td>23         </td></tr>\n",
       "\t<tr><th scope=row>214</th><td>bond       </td><td> 9         </td></tr>\n",
       "\t<tr><th scope=row>221</th><td>brands     </td><td>15         </td></tr>\n",
       "\t<tr><th scope=row>234</th><td>browser    </td><td>10         </td></tr>\n",
       "\t<tr><th scope=row>237</th><td>building   </td><td> 8         </td></tr>\n",
       "\t<tr><th scope=row>243</th><td>business   </td><td>49         </td></tr>\n",
       "\t<tr><th scope=row>269</th><td>carbon     </td><td>11         </td></tr>\n",
       "\t<tr><th scope=row>271</th><td>card       </td><td>16         </td></tr>\n",
       "\t<tr><th scope=row>274</th><td>cards      </td><td>19         </td></tr>\n",
       "\t<tr><th scope=row>275</th><td>care       </td><td>81         </td></tr>\n",
       "\t<tr><th scope=row>293</th><td>center     </td><td> 9         </td></tr>\n",
       "\t<tr><th scope=row>307</th><td>change     </td><td>11         </td></tr>\n",
       "\t<tr><th scope=row>315</th><td>chase      </td><td>12         </td></tr>\n",
       "\t<tr><th scope=row>322</th><td>chief      </td><td> 9         </td></tr>\n",
       "\t<tr><th scope=row>336</th><td>city       </td><td>15         </td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>230</th><td>states      </td><td>33          </td></tr>\n",
       "\t<tr><th scope=row>231</th><td>stock       </td><td>17          </td></tr>\n",
       "\t<tr><th scope=row>232</th><td>storage     </td><td>13          </td></tr>\n",
       "\t<tr><th scope=row>233</th><td>store       </td><td>25          </td></tr>\n",
       "\t<tr><th scope=row>234</th><td>supply      </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>235</th><td>system      </td><td>13          </td></tr>\n",
       "\t<tr><th scope=row>236</th><td>systems     </td><td>28          </td></tr>\n",
       "\t<tr><th scope=row>237</th><td>technologies</td><td>14          </td></tr>\n",
       "\t<tr><th scope=row>238</th><td>technology  </td><td>30          </td></tr>\n",
       "\t<tr><th scope=row>239</th><td>television  </td><td>12          </td></tr>\n",
       "\t<tr><th scope=row>240</th><td>term        </td><td>16          </td></tr>\n",
       "\t<tr><th scope=row>241</th><td>time        </td><td>24          </td></tr>\n",
       "\t<tr><th scope=row>242</th><td>trademark   </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>243</th><td>transport   </td><td>23          </td></tr>\n",
       "\t<tr><th scope=row>244</th><td>travel      </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>245</th><td>types       </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>246</th><td>underwriting</td><td>18          </td></tr>\n",
       "\t<tr><th scope=row>247</th><td>united      </td><td>57          </td></tr>\n",
       "\t<tr><th scope=row>248</th><td>universe    </td><td>13          </td></tr>\n",
       "\t<tr><th scope=row>249</th><td>vehicles    </td><td> 9          </td></tr>\n",
       "\t<tr><th scope=row>250</th><td>verizon     </td><td>11          </td></tr>\n",
       "\t<tr><th scope=row>251</th><td>video       </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>252</th><td>walt        </td><td>21          </td></tr>\n",
       "\t<tr><th scope=row>253</th><td>want        </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>254</th><td>washington  </td><td>15          </td></tr>\n",
       "\t<tr><th scope=row>255</th><td>website     </td><td>11          </td></tr>\n",
       "\t<tr><th scope=row>256</th><td>wells       </td><td>15          </td></tr>\n",
       "\t<tr><th scope=row>257</th><td>wholesale   </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>258</th><td>world       </td><td>59          </td></tr>\n",
       "\t<tr><th scope=row>259</th><td>york        </td><td>13          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & word & freq\\\\\n",
       "\\hline\n",
       "\t6 & access      &  9         \\\\\n",
       "\t56 & airlines    & 21         \\\\\n",
       "\t57 & airport     &  8         \\\\\n",
       "\t67 & amazon      & 22         \\\\\n",
       "\t69 & america     & 16         \\\\\n",
       "\t71 & american    & 23         \\\\\n",
       "\t80 & annual      &  8         \\\\\n",
       "\t82 & annuity     &  9         \\\\\n",
       "\t90 & apple       & 19         \\\\\n",
       "\t92 & appliance   & 13         \\\\\n",
       "\t115 & artificial  & 11         \\\\\n",
       "\t126 & association &  8         \\\\\n",
       "\t132 & attachments &  8         \\\\\n",
       "\t159 & bank        & 26         \\\\\n",
       "\t169 & battery     & 24         \\\\\n",
       "\t181 & best        & 23         \\\\\n",
       "\t214 & bond        &  9         \\\\\n",
       "\t221 & brands      & 15         \\\\\n",
       "\t234 & browser     & 10         \\\\\n",
       "\t237 & building    &  8         \\\\\n",
       "\t243 & business    & 49         \\\\\n",
       "\t269 & carbon      & 11         \\\\\n",
       "\t271 & card        & 16         \\\\\n",
       "\t274 & cards       & 19         \\\\\n",
       "\t275 & care        & 81         \\\\\n",
       "\t293 & center      &  9         \\\\\n",
       "\t307 & change      & 11         \\\\\n",
       "\t315 & chase       & 12         \\\\\n",
       "\t322 & chief       &  9         \\\\\n",
       "\t336 & city        & 15         \\\\\n",
       "\t... & ... & ...\\\\\n",
       "\t230 & states       & 33          \\\\\n",
       "\t231 & stock        & 17          \\\\\n",
       "\t232 & storage      & 13          \\\\\n",
       "\t233 & store        & 25          \\\\\n",
       "\t234 & supply       &  8          \\\\\n",
       "\t235 & system       & 13          \\\\\n",
       "\t236 & systems      & 28          \\\\\n",
       "\t237 & technologies & 14          \\\\\n",
       "\t238 & technology   & 30          \\\\\n",
       "\t239 & television   & 12          \\\\\n",
       "\t240 & term         & 16          \\\\\n",
       "\t241 & time         & 24          \\\\\n",
       "\t242 & trademark    & 10          \\\\\n",
       "\t243 & transport    & 23          \\\\\n",
       "\t244 & travel       &  8          \\\\\n",
       "\t245 & types        &  8          \\\\\n",
       "\t246 & underwriting & 18          \\\\\n",
       "\t247 & united       & 57          \\\\\n",
       "\t248 & universe     & 13          \\\\\n",
       "\t249 & vehicles     &  9          \\\\\n",
       "\t250 & verizon      & 11          \\\\\n",
       "\t251 & video        & 10          \\\\\n",
       "\t252 & walt         & 21          \\\\\n",
       "\t253 & want         &  8          \\\\\n",
       "\t254 & washington   & 15          \\\\\n",
       "\t255 & website      & 11          \\\\\n",
       "\t256 & wells        & 15          \\\\\n",
       "\t257 & wholesale    &  8          \\\\\n",
       "\t258 & world        & 59          \\\\\n",
       "\t259 & york         & 13          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "    word         freq\n",
       "6   access        9  \n",
       "56  airlines     21  \n",
       "57  airport       8  \n",
       "67  amazon       22  \n",
       "69  america      16  \n",
       "71  american     23  \n",
       "80  annual        8  \n",
       "82  annuity       9  \n",
       "90  apple        19  \n",
       "92  appliance    13  \n",
       "115 artificial   11  \n",
       "126 association   8  \n",
       "132 attachments   8  \n",
       "159 bank         26  \n",
       "169 battery      24  \n",
       "181 best         23  \n",
       "214 bond          9  \n",
       "221 brands       15  \n",
       "234 browser      10  \n",
       "237 building      8  \n",
       "243 business     49  \n",
       "269 carbon       11  \n",
       "271 card         16  \n",
       "274 cards        19  \n",
       "275 care         81  \n",
       "293 center        9  \n",
       "307 change       11  \n",
       "315 chase        12  \n",
       "322 chief         9  \n",
       "336 city         15  \n",
       "... ...          ... \n",
       "230 states       33  \n",
       "231 stock        17  \n",
       "232 storage      13  \n",
       "233 store        25  \n",
       "234 supply        8  \n",
       "235 system       13  \n",
       "236 systems      28  \n",
       "237 technologies 14  \n",
       "238 technology   30  \n",
       "239 television   12  \n",
       "240 term         16  \n",
       "241 time         24  \n",
       "242 trademark    10  \n",
       "243 transport    23  \n",
       "244 travel        8  \n",
       "245 types         8  \n",
       "246 underwriting 18  \n",
       "247 united       57  \n",
       "248 universe     13  \n",
       "249 vehicles      9  \n",
       "250 verizon      11  \n",
       "251 video        10  \n",
       "252 walt         21  \n",
       "253 want          8  \n",
       "254 washington   15  \n",
       "255 website      11  \n",
       "256 wells        15  \n",
       "257 wholesale     8  \n",
       "258 world        59  \n",
       "259 york         13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordFreqDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize6'></a>\n",
    "### 3.6 Visualize with the Brunel library\n",
    "Finally, use the Brunel library to visualize the word cloud to see themes amoung Fortune 100 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--   ~ Copyright (c) 2015 IBM Corporation and others.   ~   ~ Licensed under the Apache License, Version 2.0 (the \"License\");   ~ You may not use this file except in compliance with the License.   ~ You may obtain a copy of the License at   ~   ~     http://www.apache.org/licenses/LICENSE-2.0   ~   ~ Unless required by applicable law or agreed to in writing, software   ~ distributed under the License is distributed on an \"AS IS\" BASIS,   ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   ~ See the License for the specific language governing permissions and   ~ limitations under the License.   -->  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/brunel.2.3.css\"> <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/sumoselect.css\"> <style>      </style>  <div id=\"controlsb1f3001b-7f74-4085-956b-17a8c761ceaf\" class=\"brunel\"/> <svg id=\"vis3b86dc71-901d-4035-b469-d05d69baa129\" width=\"800\" height=\"600\"></svg>  <script>     require.config({         waitSeconds: 60,         paths: {             'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',             'topojson': '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',             'brunel' : 'https://brunelvis.org/js/brunel.2.3.min',             'brunelControls' : 'https://brunelvis.org/js/brunel.controls.2.3.min'         },         shim: {             'brunel' : {                  exports: 'BrunelD3',                  deps: ['d3', 'topojson'],                  init: function() {                     return {                       BrunelD3 : BrunelD3,                       BrunelData : BrunelData                    }                  }              },             'brunelControls' : {                  exports: 'BrunelEventHandlers',                  init: function() {                     return {                       BrunelEventHandlers: BrunelEventHandlers,                       BrunelJQueryControlFactory: BrunelJQueryControlFactory                    }                  }              }           }      });      require([\"d3\"], function(d3) {         require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {             function  BrunelVis(visId) {\n",
       "  \"use strict\";                                                                       // strict mode\n",
       "  var datasets = [],                                      // array of datasets for the original data\n",
       "      pre = function(d, i) { return d },                         // default pre-process does nothing\n",
       "      post = function(d, i) { return d },                       // default post-process does nothing\n",
       "      transitionTime = 200,                                        // transition time for animations\n",
       "      charts = [],                                                       // the charts in the system\n",
       "      vis = d3.select('#' + visId).attr('class', 'brunel');                     // the SVG container\n",
       "\n",
       "  BrunelD3.addDefinitions(vis);                                   // ensure standard symbols present\n",
       "\n",
       "  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n",
       "\n",
       "  charts[0] = function(parentNode, filterRows) {\n",
       "    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 0, 0, 0, 0),\n",
       "      elements = [];                                              // array of elements in this chart\n",
       "\n",
       "    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n",
       "\n",
       "    var chart =  vis.append('g').attr('class', 'chart1')\n",
       "      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n",
       "    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n",
       "    var zoom = d3.zoom().scaleExtent([1/3,3]);\n",
       "    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n",
       "      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n",
       "      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n",
       "      .style('cursor', 'default')\n",
       "      .node();\n",
       "    zoomNode.__zoom = d3.zoomIdentity;\n",
       "    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n",
       "    var interior = chart.append('g').attr('class', 'interior zoomNone')\n",
       "      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n",
       "      .attr('clip-path', 'url(#clip_vis3b86dc71-901d-4035-b469-d05d69baa129_chart1_inner)');\n",
       "    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n",
       "    var gridGroup = interior.append('g').attr('class', 'grid');\n",
       "    vis.append('clipPath').attr('id', 'clip_vis3b86dc71-901d-4035-b469-d05d69baa129_chart1_inner').append('rect')\n",
       "      .attr('x', 0).attr('y', 0)\n",
       "      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n",
       "    var scale_x = d3.scaleLinear(), scale_y = d3.scaleLinear();\n",
       "    var base_scales = [scale_x, scale_y];                           // untransformed original scales\n",
       "    zoom.on('zoom', function(t, time) {\n",
       "        t = t || d3.event.transform;\n",
       "        zoomNode.__zoom = t;\n",
       "        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n",
       "        interior.attr('transform', d3.zoomTransform(zoomNode));\n",
       "    });\n",
       "\n",
       "    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    elements[0] = function() {\n",
       "      var original, processed,                           // data sets passed in and then transformed\n",
       "        element, data,                                 // brunel element information and brunel data\n",
       "        selection, merged;                                      // d3 selection and merged selection\n",
       "      var elementGroup = interior.append('g').attr('class', 'element1')\n",
       "        .attr('transform','translate(' + geom.inner_width/2 + ',' + geom.inner_height/2 + ')'),\n",
       "        main = elementGroup.append('g').attr('class', 'main'),\n",
       "        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n",
       "\n",
       "      function makeData() {\n",
       "        original = datasets[0];\n",
       "        if (filterRows) original = original.retainRows(filterRows);\n",
       "        processed = pre(original, 0)\n",
       "          .summarize('freq=freq:mean; word=word');\n",
       "        processed = post(processed, 0);\n",
       "        var f0 = processed.field('word'),\n",
       "          f1 = processed.field('freq'),\n",
       "          f2 = processed.field('#row'),\n",
       "          f3 = processed.field('#selection');\n",
       "        var keyFunc = function(d) { return f0.value(d) };\n",
       "        data = {\n",
       "          word:         function(d) { return f0.value(d.row) },\n",
       "          freq:         function(d) { return f1.value(d.row) },\n",
       "          $row:         function(d) { return f2.value(d.row) },\n",
       "          $selection:   function(d) { return f3.value(d.row) },\n",
       "          word_f:       function(d) { return f0.valueFormatted(d.row) },\n",
       "          freq_f:       function(d) { return f1.valueFormatted(d.row) },\n",
       "          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n",
       "          $selection_f: function(d) { return f3.valueFormatted(d.row) },\n",
       "          _split:       function(d) { return f0.value(d.row)+ '|' + f1.value(d.row) },\n",
       "          _key:         keyFunc,\n",
       "          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n",
       "        };\n",
       "      }\n",
       "      // Aesthetic Functions\n",
       "      var scale_color = d3.scaleOrdinal()\n",
       "        .domain(['access', 'airlines', 'airport', 'amazon', 'america', 'american', 'annual', 'annuity', 'apple', 'appliance', 'artificial', 'association', 'attachments', 'bank', 'battery', 'best', 'bond', 'brands', 'browser', 'building', 'business', 'carbon', 'card', 'cards', 'care', 'center', 'change', 'chase', 'chief', 'city', 'click', 'clinical', 'cloud', 'club', 'cocacola', 'commission', 'community', 'companies', 'company', 'computer', 'computing', 'conglomerate', 'contact', 'content', 'contract', 'controls', 'convenience', 'cookie', 'copyright', 'corporate', 'corporation', 'costco', 'countries', 'coverage', 'creativity', 'credit', 'current', 'customer', 'customers', 'data', 'deals', 'deception', 'delivery', 'delta', 'detroit', 'development', 'digital', 'dioxide', 'direct', 'disability', 'disease', 'disney', 'disneyland', 'drug', 'earth', 'economic', 'economics', 'email', 'energy', 'engine', 'englishlanguage', 'environment', 'equipment', 'exchange', 'executive', 'experience', 'express', 'family', 'fargo', 'farm', 'federal', 'film', 'films', 'finance', 'financial', 'food', 'foodservice', 'ford', 'form', 'francisco', 'future', 'futures', 'general', 'global', 'goldman', 'governance', 'group', 'growth', 'health', 'healthcare', 'hedge', 'help', 'history', 'home', 'hospital', 'hotels', 'housing', 'human', 'humana', 'index', 'industry', 'information', 'innovation', 'innovative', 'insurance', 'interest', 'international', 'internet', 'inventory', 'investment', 'iphone', 'ipod', 'islands', 'johnson', 'knowledge', 'language', 'largest', 'lawn', 'life', 'liquefied', 'local', 'long', 'lynch', 'management', 'market', 'marketing', 'media', 'medicine', 'menu', 'merrill', 'michigan', 'mobile', 'morgan', 'mortgage', 'motor', 'motors', 'mower', 'mutual', 'national', 'nationwide', 'natural', 'network', 'neural', 'news', 'number', 'office', 'officer', 'online', 'open', 'oracle', 'page', 'parks', 'partnership', 'patient', 'pension', 'personal', 'petroleum', 'pharmaceutical', 'pharmacology', 'pharmacy', 'phillips', 'phone', 'plan', 'plans', 'policy', 'power', 'prescription', 'press', 'pricing', 'printer', 'printing', 'privacy', 'problem', 'product', 'products', 'program', 'protection', 'provider', 'public', 'quality', 'quote', 'rally', 'rate', 'research', 'reserved', 'resort', 'resorts', 'retail', 'retirement', 'rights', 'risk', 'sachs', 'sales', 'saving', 'science', 'search', 'securities', 'service', 'services', 'share', 'shop', 'site', 'small', 'solutions', 'solving', 'spanish', 'stanley', 'starwood', 'state', 'states', 'stock', 'storage', 'store', 'supply', 'system', 'systems', 'technologies', 'technology', 'television', 'term', 'time', 'trademark', 'transport', 'travel', 'types', 'underwriting', 'united', 'universe', 'vehicles', 'verizon', 'video', 'walt', 'want', 'washington', 'website', 'wells', 'wholesale', 'world', 'york'])\n",
       "        .range([ '#00538A', '#C10020', '#F4C800', '#007D34', '#803E75', '#FF6800', \n",
       "          '#817066', '#FFB300', '#F6768E', '#93AA00', '#53377A', '#FF8E00', '#B32851', \n",
       "          '#CEA262', '#FF7A5C', '#7F180D', '#593315', '#F13A13', '#232C16']);\n",
       "      var color = function(d) { return scale_color(data.word(d)) };\n",
       "      var scale_size = d3.scaleSqrt().domain([0, 138.00001])\n",
       "        .range([ 0.001, 1]);\n",
       "      var size = function(d) { return scale_size(data.freq(d)) };\n",
       "\n",
       "      // Build element from data ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "      function build(transitionMillis) {\n",
       "        element = elements[0];\n",
       "        // Build the cloud layout\n",
       "        var cloud = BrunelD3.cloudLayout(processed, [geom.inner_width, geom.inner_height], zoomNode);\n",
       "        function keyFunction(d) { return d.key };\n",
       "        main.attr('class', 'diagram cloud');\n",
       "\n",
       "        // Define selection entry operations\n",
       "        function initialState(selection) {\n",
       "          selection\n",
       "            .attr('class', 'element text filled')\n",
       "            .style('text-anchor', 'middle').classed('label', true)\n",
       "            .text(function(d) { return data.word_f(d) })\n",
       "            .style('font-size', function(d) { return (100*size(d)) + '%' })\n",
       "            .style('pointer-events', 'none')\n",
       "        }\n",
       "\n",
       "        // Define selection update operations on merged data\n",
       "        function updateState(selection) {\n",
       "          selection\n",
       "            .each(cloud.prepare).call(cloud.build)\n",
       "            .filter(BrunelD3.hasData)                     // following only performed for data items\n",
       "            .style('fill', color);\n",
       "        }\n",
       "        // Create selections, set the initial state and transition updates\n",
       "        selection = main.selectAll('.element').data(data._rows, function(d) { return d.key });\n",
       "        var added = selection.enter().append('text');\n",
       "        merged = selection.merge(added);\n",
       "        initialState(added);\n",
       "        selection.filter(BrunelD3.hasData)\n",
       "          .classed('selected', BrunelD3.isSelected(data))\n",
       "          .filter(BrunelD3.isSelected(data)).raise();\n",
       "        updateState(BrunelD3.transition(merged, transitionMillis));\n",
       "\n",
       "        BrunelD3.transition(selection.exit(), transitionMillis/3)\n",
       "          .style('opacity', 0.5).each( function() {\n",
       "            this.remove(); BrunelD3.removeLabels(this); \n",
       "        });\n",
       "      }\n",
       "\n",
       "      return {\n",
       "        data:           function() { return processed },\n",
       "        original:       function() { return original },\n",
       "        internal:       function() { return data },\n",
       "        selection:      function() { return merged },\n",
       "        makeData:       makeData,\n",
       "        build:          build,\n",
       "        chart:          function() { return charts[0] },\n",
       "        group:          function() { return elementGroup },\n",
       "        fields: {\n",
       "          key:          ['word'],\n",
       "          color:        ['word'],\n",
       "          size:         ['freq']\n",
       "        }\n",
       "      };\n",
       "    }();\n",
       "\n",
       "    function build(time, noData) {\n",
       "      var first = elements[0].data() == null;\n",
       "      if (first) time = 0;                                           // no transition for first call\n",
       "      if ((first || time > -1) && !noData) {\n",
       "        elements[0].makeData();\n",
       "      }\n",
       "      elements[0].build(time);\n",
       "    }\n",
       "\n",
       "    // Expose the following components of the chart\n",
       "    return {\n",
       "      elements : elements,\n",
       "      interior : interior,\n",
       "      zoom: function(params, time) {\n",
       "          if (params) zoom.on('zoom').call(zoomNode, params, time);\n",
       "          return d3.zoomTransform(zoomNode);\n",
       "      },\n",
       "      build : build\n",
       "    };\n",
       "    }();\n",
       "\n",
       "  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n",
       "  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n",
       "  function buildAll() {\n",
       "    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n",
       "    updateAll(transitionTime);\n",
       "  }\n",
       "\n",
       "  return {\n",
       "    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n",
       "    dataPostProcess:    function(f) { if (f) post = f; return post },\n",
       "    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n",
       "    visId:              visId,\n",
       "    build:              buildAll,\n",
       "    rebuild:            updateAll,\n",
       "    charts:             charts\n",
       "  }\n",
       "}\n",
       "\n",
       "// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "var table1 = {\n",
       "   summarized: true,\n",
       "   names: ['word', 'freq'], \n",
       "   options: ['string', 'numeric'], \n",
       "   rows: [['access', 9], ['airlines', 21], ['airport', 8], ['amazon', 22], ['america', 16],\n",
       "  ['american', 23], ['annual', 8], ['annuity', 9], ['apple', 19], ['appliance', 13],\n",
       "  ['artificial', 11], ['association', 8], ['attachments', 8], ['bank', 26], ['battery', 24],\n",
       "  ['best', 23], ['bond', 9], ['brands', 15], ['browser', 10], ['building', 8], ['business', 49],\n",
       "  ['carbon', 11], ['card', 16], ['cards', 19], ['care', 81], ['center', 9], ['change', 11],\n",
       "  ['chase', 12], ['chief', 9], ['city', 15], ['click', 11], ['clinical', 8], ['cloud', 24],\n",
       "  ['club', 16], ['cocacola', 11], ['commission', 11], ['community', 9], ['companies', 20],\n",
       "  ['company', 56], ['computer', 15], ['computing', 20], ['conglomerate', 9], ['contact', 11],\n",
       "  ['content', 10], ['contract', 14], ['controls', 8], ['convenience', 9], ['cookie', 9],\n",
       "  ['copyright', 13], ['corporate', 26], ['corporation', 39], ['costco', 13], ['countries', 13],\n",
       "  ['coverage', 9], ['creativity', 12], ['credit', 29], ['current', 13], ['customer', 38],\n",
       "  ['customers', 9], ['data', 15], ['deals', 18], ['deception', 10], ['delivery', 9], ['delta', 8],\n",
       "  ['detroit', 10], ['development', 8], ['digital', 21], ['dioxide', 10], ['direct', 9],\n",
       "  ['disability', 11], ['disease', 9], ['disney', 36], ['disneyland', 11], ['drug', 17], ['earth', 9],\n",
       "  ['economic', 17], ['economics', 24], ['email', 9], ['energy', 47], ['engine', 10],\n",
       "  ['englishlanguage', 17], ['environment', 18], ['equipment', 8], ['exchange', 16],\n",
       "  ['executive', 11], ['experience', 24], ['express', 23], ['family', 8], ['fargo', 16], ['farm', 9],\n",
       "  ['federal', 8], ['film', 11], ['films', 21], ['finance', 40], ['financial', 66], ['food', 18],\n",
       "  ['foodservice', 8], ['ford', 18], ['form', 12], ['francisco', 10], ['future', 18], ['futures', 16],\n",
       "  ['general', 21], ['global', 36], ['goldman', 15], ['governance', 14], ['group', 10],\n",
       "  ['growth', 14], ['health', 137], ['healthcare', 8], ['hedge', 10], ['help', 8], ['history', 8],\n",
       "  ['home', 37], ['hospital', 13], ['hotels', 9], ['housing', 8], ['human', 12], ['humana', 18],\n",
       "  ['index', 10], ['industry', 9], ['information', 33], ['innovation', 24], ['innovative', 8],\n",
       "  ['insurance', 138], ['interest', 10], ['international', 14], ['internet', 20], ['inventory', 12],\n",
       "  ['investment', 51], ['iphone', 11], ['ipod', 12], ['islands', 17], ['johnson', 8],\n",
       "  ['knowledge', 14], ['language', 14], ['largest', 10], ['lawn', 10], ['life', 32],\n",
       "  ['liquefied', 15], ['local', 20], ['long', 8], ['lynch', 8], ['management', 61], ['market', 21],\n",
       "  ['marketing', 21], ['media', 9], ['medicine', 38], ['menu', 10], ['merrill', 12], ['michigan', 10],\n",
       "  ['mobile', 29], ['morgan', 16], ['mortgage', 14], ['motor', 10], ['motors', 11], ['mower', 9],\n",
       "  ['mutual', 32], ['national', 11], ['nationwide', 14], ['natural', 35], ['network', 17],\n",
       "  ['neural', 12], ['news', 8], ['number', 8], ['office', 10], ['officer', 9], ['online', 11],\n",
       "  ['open', 8], ['oracle', 10], ['page', 8], ['parks', 8], ['partnership', 9], ['patient', 10],\n",
       "  ['pension', 10], ['personal', 30], ['petroleum', 29], ['pharmaceutical', 15], ['pharmacology', 15],\n",
       "  ['pharmacy', 24], ['phillips', 11], ['phone', 14], ['plan', 15], ['plans', 12], ['policy', 37],\n",
       "  ['power', 8], ['prescription', 9], ['press', 8], ['pricing', 9], ['printer', 10], ['printing', 8],\n",
       "  ['privacy', 35], ['problem', 10], ['product', 8], ['products', 43], ['program', 10],\n",
       "  ['protection', 10], ['provider', 17], ['public', 21], ['quality', 8], ['quote', 9], ['rally', 10],\n",
       "  ['rate', 8], ['research', 16], ['reserved', 13], ['resort', 11], ['resorts', 15], ['retail', 8],\n",
       "  ['retirement', 8], ['rights', 41], ['risk', 33], ['sachs', 10], ['sales', 25], ['saving', 8],\n",
       "  ['science', 10], ['search', 13], ['securities', 17], ['service', 28], ['services', 80],\n",
       "  ['share', 12], ['shop', 15], ['site', 14], ['small', 11], ['solutions', 13], ['solving', 10],\n",
       "  ['spanish', 9], ['stanley', 10], ['starwood', 9], ['state', 10], ['states', 33], ['stock', 17],\n",
       "  ['storage', 13], ['store', 25], ['supply', 8], ['system', 13], ['systems', 28],\n",
       "  ['technologies', 14], ['technology', 30], ['television', 12], ['term', 16], ['time', 24],\n",
       "  ['trademark', 10], ['transport', 23], ['travel', 8], ['types', 8], ['underwriting', 18],\n",
       "  ['united', 57], ['universe', 13], ['vehicles', 9], ['verizon', 11], ['video', 10], ['walt', 21],\n",
       "  ['want', 8], ['washington', 15], ['website', 11], ['wells', 15], ['wholesale', 8], ['world', 59],\n",
       "  ['york', 13]]\n",
       "};\n",
       "\n",
       "// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "var v  = new BrunelVis('vis3b86dc71-901d-4035-b469-d05d69baa129');\n",
       "v.build(table1);\n",
       "         });     });  </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brunel (\" data('wordFreqDF') cloud color(word) size(freq) label(word) mean(freq) legends(none)\",\n",
    "        width = 800, height = 600, online_js = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## Summary and next steps\n",
    "\n",
    "Congratulations! In this notebook you learned about the Watson Natural Language Understanding API and how to access it in a programmatic way by using the R programming language.  \n",
    "\n",
    "Try substituting your own client list for the Fortune 100 data and creating a word cloud.\n",
    "\n",
    "### Author\n",
    "\n",
    "**Rafi Kurlansik** is an Open Source Solutions Engineer specializing in big data technologies, such as Hadoop and Spark. He's responsible for developing and delivering demonstrations of IBM tech to both enterprise clients and the larger analytics community. Kurlansik has hands-on experience with machine learning, natural language processing, data visualization, and dashboard development. If you're wondering where he comes down on the biggest data science debate of our day, Rafi is, in his own words, \"an avid R fan, especially RStudio!\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R with Spark 2.1",
   "language": "R",
   "name": "r-spark21"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
