{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<table style=\"border: none\" align=\"left\">\n",
    "   <tr style=\"border: none\">\n",
    "      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Use Spark and Scala to predict Equipment Purchase</b></th>\n",
    "      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n",
    "   </tr>\n",
    "   <tr style=\"border: none\">\n",
    "       <th style=\"border: none\"><img src=\"https://github.com/pmservice/wml-sample-models/blob/master/spark/product-line-prediction/images/products_graphics.png?raw=true\" alt=\"Icon\" width=\"800\"> </th>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook how to perform data analysis on classification problem using <a href=\"http://spark.apache.org/docs/2.3.0/ml-guide.html\" target=\"_blank\" rel=\"noopener no referrer\">Spark ML package</a>.\n",
    "\n",
    "Some familiarity with Scala is helpful. This notebook uses Scala 2.11 with Spark.\n",
    "\n",
    "You will use a publicly available data set, **GoSales Transactions for Naive Bayes Model**, which details anonymous outdoor equipment purchases. This data set will be used to predict clients' interests in terms of product line, such as golf accessories, camping equipment, and so forth.\n",
    "\n",
    "**Note**: In this notebook, we use the GoSales data available to the <a  href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/8044492073eb964f46597b4be06ff5ea\" target=\"_blank\" rel=\"noopener no referrer\">Watson Studio Community</a>.\n",
    " \n",
    "## Learning goals\n",
    "\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "-  Load a CSV file into a Spark DataFrame.\n",
    "-  Explore data.\n",
    "-  Prepare data for training and evaluation.\n",
    "-  Create a Spark machine learning pipeline.\n",
    "-  Train and evaluate a model.\n",
    "-  Store a pipeline and model in the Watson Machine Learning (WML) repository.\n",
    "-  Deploy a model for online scoring via the Watson Machine Learning (WML) API.\n",
    "-  Score the model using sample data via the Watson Machine Learning (WML) API.\n",
    "\n",
    "\n",
    "## Contents\n",
    "\n",
    "This notebook contains the following parts:\n",
    "\n",
    "1.\t[Set up the environment](#setup)\n",
    "2.\t[Load and explore the data](#load)\n",
    "3.\t[Build a Spark machine learning model](#model)\n",
    "4.\t[Store the model in the WML repository](#persistence)\n",
    "5.\t[Deploy and score in the WML repository](#scoring)\n",
    "6.\t[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Set up the environment\n",
    "\n",
    "Before you use the sample code in this notebook, you must perform the following setup tasks:\n",
    "\n",
    "- Create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a free plan is offered and information about how to create the instance can be found <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)\n",
    "-  Make sure that you are using a Spark 2.x kernel.\n",
    "-  Download **GoSales Transactions** from the Watson Studio Community (steps provided below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 2. Load and explore data\n",
    "\n",
    "In this section, you will load the data into a SparkSession DataFrame and perform basic exploratory data analysis.\n",
    "\n",
    "- Download <a href=\"https://dataplatform.cloud.ibm.com/data/exchange-api/v1/entries/8044492073eb964f46597b4be06ff5ea/data?accessKey=d1bec8d606656afaa378d73205093b10\" target=\"_blank\" rel=\"noopener no referrer\">GoSales_Tx_NaiveBayes.csv</a> from the Watson Studio community. \n",
    "- Load the .csv file into your notebook. Click the Data icon on the notebook action bar. Drop the file into the box or browse to select the file. The file is loaded to your object storage and appears in the Data Assets section of the project.\n",
    "- To load the data into a Spark DataFrame, click in the next code cell and select **Insert to code > Insert SparkSession DataFrame** under the file name.\n",
    "- Rename `dfDatax` to `dfData` if needed.\n",
    "- Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// The code was removed by Watson Studio for sharing.\n",
    "import com.ibm.ibmos2spark.CloudObjectStorage\n",
    "\n",
    "// @hidden_cell\n",
    "var credentials = scala.collection.mutable.HashMap[String, String](\n",
    "    \"endPoint\"->\"***\",\n",
    "    \"apiKey\"->\"***\",\n",
    "    \"serviceId\"->\"***\",\n",
    "    \"iamServiceEndpoint\" -> \"***\")\n",
    "\n",
    "var configurationName = \"os_985f24d93a7243aeb65f8aba59f75706_configs\"\n",
    "var cos = new CloudObjectStorage(sc, credentials, configurationName, \"bluemix_cos\")\n",
    "\n",
    "import org.apache.spark.sql.SparkSession\n",
    "\n",
    "val spark = SparkSession.\n",
    "    builder().\n",
    "    getOrCreate()\n",
    "val dfData = spark.\n",
    "    read.format(\"org.apache.spark.sql.execution.datasources.csv.CSVFileFormat\").\n",
    "    option(\"header\", \"true\").\n",
    "    option(\"inferSchema\", \"true\").\n",
    "    load(cos.url(\"wastonmachinelearningcommunitynot-donotdelete-pr-pnbylejs5jpqwu\", \"GoSales_Tx_NaiveBayes.csv\"))\n",
    "dfData.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the loaded data by using the following Spark DataFrame methods:\n",
    "-  print schema\n",
    "-  print top ten records\n",
    "-  count all records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PRODUCT_LINE: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfData.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data contains five fields. PRODUCT_LINE field is the one you would like to predict (label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+---+--------------+------------+\n",
      "|        PRODUCT_LINE|GENDER|AGE|MARITAL_STATUS|  PROFESSION|\n",
      "+--------------------+------+---+--------------+------------+\n",
      "|Personal Accessories|     M| 27|        Single|Professional|\n",
      "|Personal Accessories|     F| 39|       Married|       Other|\n",
      "|Mountaineering Eq...|     F| 39|       Married|       Other|\n",
      "|Personal Accessories|     F| 56|   Unspecified| Hospitality|\n",
      "|      Golf Equipment|     M| 45|       Married|     Retired|\n",
      "|      Golf Equipment|     M| 45|       Married|     Retired|\n",
      "|   Camping Equipment|     F| 39|       Married|       Other|\n",
      "|   Camping Equipment|     F| 49|       Married|       Other|\n",
      "|  Outdoor Protection|     F| 49|       Married|       Other|\n",
      "|      Golf Equipment|     M| 47|       Married|     Retired|\n",
      "+--------------------+------+---+--------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfData.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 60252"
     ]
    }
   ],
   "source": [
    "print(\"Total number of records: \" + dfData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data set contains 60252 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 3. Build a Spark machine learning model\n",
    "\n",
    "In this section, you will learn how to:\n",
    "\n",
    "- [3.1 Split data](#prep)\n",
    "- [3.2 Create a Spark machine learning pipeline](#pipe)\n",
    "- [3.3 Train a model](#train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Split data<a id=\"prep\"></a>\n",
    "\n",
    "In this subsection, you will split your data into: \n",
    "- Train data set\n",
    "- Test data set\n",
    "- Prediction data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training records: 48176\n",
      "Number of testing records: 10860\n",
      "Number of prediction records: 1216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "splits = Array([PRODUCT_LINE: string, GENDER: string ... 3 more fields], [PRODUCT_LINE: string, GENDER: string ... 3 more fields], [PRODUCT_LINE: string, GENDER: string ... 3 more fields])\n",
       "trainingData = [PRODUCT_LINE: string, GENDER: string ... 3 more fields]\n",
       "testData = [PRODUCT_LINE: string, GENDER: string ... 3 more fields]\n",
       "predictionData = [PRODUCT_LINE: string, GENDER: string ... 3 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[PRODUCT_LINE: string, GENDER: string ... 3 more fields]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val splits = dfData.randomSplit(Array(0.8, 0.18, 0.02), seed = 24L)\n",
    "val trainingData = splits(0).cache()\n",
    "val testData = splits(1)\n",
    "val predictionData = splits(2)\n",
    "\n",
    "println(\"Number of training records: \" + trainingData.count())\n",
    "println(\"Number of testing records: \" + testData.count())\n",
    "println(\"Number of prediction records: \" + predictionData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, your data has been successfully split into three data sets: \n",
    "\n",
    "-  The train data set which is the largest group is used for training.\n",
    "-  The test data set will be used for model evaluation.\n",
    "-  The predict data set will be used for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create a Spark machine learning pipeline<a id=\"pipe\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will create a Spark machine learning pipeline and train the model.\n",
    "\n",
    "First, you need to import Spark machine learning packages that will be needed in the subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.ml.classification.RandomForestClassifier\n",
    "import org.apache.spark.ml.feature.{OneHotEncoder, StringIndexer, IndexToString, VectorAssembler}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "import org.apache.spark.ml.{Model, Pipeline, PipelineStage, PipelineModel}\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, use the `StringIndexer` transformer to convert all the string fields to numeric ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stringIndexerLabel = strIdx_001dfe13aa6f\n",
       "stringIndexerProf = strIdx_4aa8c2de7416\n",
       "stringIndexerGend = strIdx_243db3762e73\n",
       "stringIndexerMar = strIdx_c12bee13515e\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "strIdx_c12bee13515e"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stringIndexerLabel = new StringIndexer().setInputCol(\"PRODUCT_LINE\").setOutputCol(\"label\").fit(dfData)\n",
    "val stringIndexerProf = new StringIndexer().setInputCol(\"PROFESSION\").setOutputCol(\"PROFESSION_IX\")\n",
    "val stringIndexerGend = new StringIndexer().setInputCol(\"GENDER\").setOutputCol(\"GENDER_IX\")\n",
    "val stringIndexerMar = new StringIndexer().setInputCol(\"MARITAL_STATUS\").setOutputCol(\"MARITAL_STATUS_IX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following step, create a feature vector by combining all the features together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vectorAssemblerFeatures = vecAssembler_cc7f2a432eeb\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vecAssembler_cc7f2a432eeb"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val vectorAssemblerFeatures = new VectorAssembler().setInputCols(Array(\"GENDER_IX\", \"AGE\", \"MARITAL_STATUS_IX\", \"PROFESSION_IX\")).setOutputCol(\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, select the estimator you want to use for classification. `Random Forest` is used in the this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rf = rfc_36e8569c94a6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "rfc_36e8569c94a6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rf = new RandomForestClassifier().setLabelCol(\"label\").setFeaturesCol(\"features\").setNumTrees(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, convert the indexed labels back to original labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labelConverter = idxToStr_57ae1bc4e090\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "idxToStr_57ae1bc4e090"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelConverter = new IndexToString().setInputCol(\"prediction\").setOutputCol(\"predictedLabel\").setLabels(stringIndexerLabel.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the pipeline. A pipeline consists of transformers and an estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pipelineRf = pipeline_89e65091252c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_89e65091252c"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val pipelineRf = new Pipeline().setStages(Array(stringIndexerLabel, stringIndexerProf, stringIndexerGend, stringIndexerMar, vectorAssemblerFeatures, rf, labelConverter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Train a model<a id=\"train\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can train your Random Forest model by using the previously defined **pipeline** and **training data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PRODUCT_LINE: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- PROFESSION: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelRf = pipeline_89e65091252c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pipeline_89e65091252c"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelRf = pipelineRf.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your **model accuracy** now. Use **test data** to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 58.21%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predictions = [PRODUCT_LINE: string, GENDER: string ... 12 more fields]\n",
       "evaluatorRF = mcEval_ad3ef501c6bd\n",
       "accuracy = 0.5821362799263352\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5821362799263352"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val predictions = modelRf.transform(testData)\n",
    "val evaluatorRF = new MulticlassClassificationEvaluator().setLabelCol(\"label\").setPredictionCol(\"prediction\").setMetricName(\"accuracy\")\n",
    "val accuracy = evaluatorRF.evaluate(predictions)\n",
    "\n",
    "println(f\"Accuracy = ${accuracy*100}%.2f%%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can tune your model now to achieve better accuracy. For simplicity, the tuning example is omitted in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"persistence\"></a>\n",
    "## 4. Store the model in the WML repository\n",
    "\n",
    "In this section, you will learn how to use Scala libraries to store your pipeline and model in the WML repository and make predictions.\n",
    "\n",
    "- [4.1 Import required libraries](#lib)\n",
    "- [4.2 Save the pipeline and model](#save)\n",
    "- [4.3 Load the model](#load)\n",
    "- [4.4 Make predictions](#make)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Import required libraries<a id=\"lib\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you must import required libraries.\n",
    "\n",
    "**Note**: Spark 2.3 or higher is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "// WML client library\n",
    "import com.ibm.analytics.ngp.repository_v3._\n",
    "\n",
    "// Helper libraries\n",
    "\n",
    "import scalaj.http.{Http, HttpOptions}\n",
    "import scala.util.{Success, Failure}\n",
    "import java.util.Base64\n",
    "import java.nio.charset.StandardCharsets\n",
    "import play.api.libs.json._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate the Watson Machine Learning service on the IBM Cloud.\n",
    "\n",
    "**Tip**: Authentication information (your credentials) can be found in the <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-get-wml-credentials.html\" target=\"_blank\" rel=\"noopener no referrer\">Service credentials</a> tab of the service instance that you created on the IBM Cloud. <BR>If you cannot find the **instance_id** field in **Service Credentials**, click **New credential (+)** to generate new authentication information. \n",
    "\n",
    "**Action**: Enter your Watson Machine Learning service instance credentials here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wmlCredentials = Map(instance_id -> ***, username -> ***, apikey -> ***, url -> https://ibm-watson-ml.mybluemix.net, password -> ***)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map(instance_id -> ***, username -> ***, apikey -> ***, url -> https://ibm-watson-ml.mybluemix.net, password -> ***)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scala.collection.mutable.HashMap\n",
    "val wmlCredentials: HashMap[String, String] = HashMap(\n",
    "    \"url\"->\"https://ibm-watson-ml.mybluemix.net\",\n",
    "    \"username\"->\"***\",\n",
    "    \"password\"->\"***\",\n",
    "    \"instance_id\"->\"***\",\n",
    "    \"apikey\"->\"***\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val wmlServicePath = wmlCredentials(\"url\")\n",
    "val wmlInstanceId = wmlCredentials(\"instance_id\")\n",
    "val wmlUsername = wmlCredentials(\"username\")\n",
    "val wmlPassword = wmlCredentials(\"password\")\n",
    "val wmlAPI = wmlCredentials(\"apikey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client = com.ibm.analytics.ngp.repository_v3.MLRepositoryClient@d3332a5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Success(())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val client = MLRepositoryClient(wmlServicePath)\n",
    "client.authorize(wmlUsername, wmlPassword)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model artifact (abstraction layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelArtifact = com.ibm.analytics.ngp.repository_v3.SparkPipelineModelArtifact@73aa5f1c\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "com.ibm.analytics.ngp.repository_v3.SparkPipelineModelArtifact@73aa5f1c"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelArtifact = MLRepositoryArtifact(modelRf, trainingData, \"WML Product Line Prediction Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: The MLRepositoryArtifact method expects a trained model object, training data, and a model name. (It is this model name that is displayed by the WML service)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Save the pipeline and model<a id=\"save\"></a>\n",
    "\n",
    "In this subsection, you will learn how to save the pipeline and model artifacts in your WML repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "savedModel = com.ibm.analytics.ngp.repository_v3.MLRepositoryClient$ModelAdapter$$anon$14@24b63292\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "com.ibm.analytics.ngp.repository_v3.MLRepositoryClient$ModelAdapter$$anon$14@24b63292"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val savedModel = client.models.save(modelArtifact).get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the saved model metadata from WML.\n",
    "\n",
    "**Tip**: Use *meta.availableProps* to get the list of available props."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector(trainingDataSchema, modelUrl, trainingDefinitionVersionUrl, label, inputDataSchema, content_status, framework_runtimes, modelType, version, modelVersionUrl, artifactPath, modelInMemorySize, contentUrl, frameworkName, runtime, creationTime, frameworkVersion)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savedModel.meta.availableProps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelType: standard\n",
      "trainingDataSchema: {\"type\":\"struct\",\"fields\":[{\"name\":\"PRODUCT_LINE\",\"type\":\"string\",\"nullable\":true,\"metadata\":{\"modeling_role\":\"target\"}},{\"name\":\"GENDER\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"AGE\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"MARITAL_STATUS\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}},{\"name\":\"PROFESSION\",\"type\":\"string\",\"nullable\":true,\"metadata\":{}}]}\n",
      "creationTime: 2019-07-16T16:04:33.080Z\n",
      "modelVersionUrl: https://us-south.ml.cloud.ibm.com/v3/ml_assets/models/4f5c3428-3983-4463-bd0a-86a3480124e7/versions/346ee803-2519-4323-a4ea-bf68b057f1b0\n",
      "label: PRODUCT_LINE\n"
     ]
    }
   ],
   "source": [
    "println(\"modelType: \" + savedModel.meta.prop(\"modelType\").get)\n",
    "println(\"trainingDataSchema: \" + savedModel.meta.prop(\"trainingDataSchema\").get)\n",
    "println(\"creationTime: \" + savedModel.meta.prop(\"creationTime\").get)\n",
    "println(\"modelVersionUrl: \" + savedModel.meta.prop(\"modelVersionUrl\").get)\n",
    "println(\"label: \" + savedModel.meta.prop(\"label\").get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip**: **modelVersionUrl** is the model unique indentifier in the WML repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Load the model<a id=\"load\"></a>\n",
    "\n",
    "In this subsection, you will learn how to load a saved model from a specified WML instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modelVersionUrl = https://us-south.ml.cloud.ibm.com/v3/ml_assets/models/4f5c3428-3983-4463-bd0a-86a3480124e7/versions/346ee803-2519-4323-a4ea-bf68b057f1b0\n",
       "loadedModelArtifact = com.ibm.analytics.ngp.repository_v3.MLRepositoryClient$ModelAdapter$$anon$14@195ca98f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "com.ibm.analytics.ngp.repository_v3.MLRepositoryClient$ModelAdapter$$anon$14@195ca98f"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelVersionUrl = savedModel.meta.prop(\"modelVersionUrl\").get\n",
    "val loadedModelArtifact = client.models.version(modelVersionUrl).get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the model name to make sure that model artifact has been loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WML Product Line Prediction Model"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedModelArtifact.name.mkString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the name is correct. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Make predictions<a id=\"make\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+--------------+-----------+--------------------+\n",
      "|GENDER|AGE|MARITAL_STATUS| PROFESSION|      predictedLabel|\n",
      "+------+---+--------------+-----------+--------------------+\n",
      "|     F| 18|        Single|      Other|Personal Accessories|\n",
      "|     F| 18|        Single|     Retail|Personal Accessories|\n",
      "|     F| 19|        Single|Hospitality|   Camping Equipment|\n",
      "|     F| 19|        Single|Hospitality|   Camping Equipment|\n",
      "|     F| 19|        Single|Hospitality|   Camping Equipment|\n",
      "|     F| 19|        Single|Hospitality|   Camping Equipment|\n",
      "|     F| 19|        Single|      Other|Personal Accessories|\n",
      "|     F| 19|        Single|      Other|Personal Accessories|\n",
      "|     F| 19|        Single|      Other|Personal Accessories|\n",
      "|     F| 19|        Single|      Other|Personal Accessories|\n",
      "+------+---+--------------+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loadedModelArtifact match {\n",
    "    case SparkPipelineModelLoader(Success(model)) => {\n",
    "        val predictions = model.transform(predictionData)\n",
    "    }\n",
    "    case SparkPipelineModelLoader(Failure(e)) => \"Loading failed.\"\n",
    "    case _ => println(s\"Unexpected artifact class: ${loadedModelArtifact.getClass}\")\n",
    "}\n",
    "\n",
    "predictions.select(\"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", \"predictedLabel\").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tabulating the `predictedLabel` column and count the frequencies of `predictedLabel` classes, you can see which product line is the most popular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|      predictedLabel|count|\n",
      "+--------------------+-----+\n",
      "|   Camping Equipment| 6356|\n",
      "|      Golf Equipment|  631|\n",
      "|Mountaineering Eq...|  699|\n",
      "|Personal Accessories| 3174|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"predictedLabel\").groupBy(\"predictedLabel\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now learned how to save and load a model from the WML repository and make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"scoring\"></a>\n",
    "## 5. Deploy and score in the WML repository\n",
    "\n",
    "In this section, you will learn how to create online scoring and to score a test data record by using the WML REST API. \n",
    "For more information about REST APIs, see the <a href=\"http://watson-ml-api.mybluemix.net/\" target=\"_blank\" rel=\"noopener no referrer\">Swagger Documentation</a>.\n",
    "\n",
    "To work with the WML REST API you must generate an access token. To do this, use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Get IAM token\n",
    "val wmlUrl = \"https://iam.bluemix.net/oidc/token\"\n",
    "val data = \"apikey=\" + wmlAPI + \"&grant_type=urn:ibm:params:oauth:grant-type:apikey\"\n",
    "val IBM_cloud_IAM_uid = \"bx\"\n",
    "val IBM_cloud_IAM_pwd = \"bx\"\n",
    "val wmlAuthHeader = \"Basic \" + Base64.getEncoder.encodeToString((IBM_cloud_IAM_uid + \":\" + IBM_cloud_IAM_pwd).getBytes(StandardCharsets.UTF_8))\n",
    "val wmlResponse = Http(wmlUrl).postData(data).header(\"Content-Type\", \"application/x-www-form-urlencoded\").header(\"Authorization\", wmlAuthHeader).asString\n",
    "val iamTokenJson = Json.parse(wmlResponse.body)\n",
    "val iamToken = (iamTokenJson \\ \"access_token\").as[String]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the published model urls from instance details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "endpointInstance = https://ibm-watson-ml.mybluemix.net/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9\n",
       "wmlResponseInstance = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HttpResponse({\n",
       "  \"metadata\": {\n",
       "    \"guid\": \"b4b6c696-172c-4164-8049-c0b621dbf3c9\",\n",
       "    \"url\": \"https://ibm-watson-ml.mybluemix.net/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9\",\n",
       "    \"created_at\": \"2018-12-10T08:05:26.901Z\",\n",
       "    \"modified_at\": \"2019-07-16T16:04:33.975Z\"\n",
       "  },\n",
       "  \"entity\": {\n",
       "    \"source\": \"Bluemix\",\n",
       "    \"published_models\": {\n",
       "      \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models\"\n",
       "    },\n",
       "    \"usage\": {\n",
       "      \"expiration_date\": \"2019-08-01T00:00:00.000Z\",\n",
       "      \"computation_time\": {\n",
       "        \"current\": 0\n",
       "      },\n",
       "      \"gpu_count_k80\":...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val endpointInstance = wmlServicePath + \"/v3/wml_instances/\" + wmlInstanceId\n",
    "val wmlResponseInstance = Http(endpointInstance).\n",
    "                          header(\"Content-Type\", \"application/json\").\n",
    "                          header(\"Authorization\", \"Bearer \" + iamToken).\n",
    "                          option(HttpOptions.connTimeout(10000)).\n",
    "                          option(HttpOptions.readTimeout(50000)).asString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HttpResponse({\n",
       "  \"metadata\": {\n",
       "    \"guid\": \"b4b6c696-172c-4164-8049-c0b621dbf3c9\",\n",
       "    \"url\": \"https://ibm-watson-ml.mybluemix.net/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9\",\n",
       "    \"created_at\": \"2018-12-10T08:05:26.901Z\",\n",
       "    \"modified_at\": \"2019-07-16T16:04:33.975Z\"\n",
       "  },\n",
       "  \"entity\": {\n",
       "    \"source\": \"Bluemix\",\n",
       "    \"published_models\": {\n",
       "      \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models\"\n",
       "    },\n",
       "    \"usage\": {\n",
       "      \"expiration_date\": \"2019-08-01T00:00:00.000Z\",\n",
       "      \"computation_time\": {\n",
       "        \"current\": 0\n",
       "      },\n",
       "      \"gpu_count_k80\": {\n",
       "        \"limit\": 48,\n",
       "        \"current\": 0\n",
       "      },\n",
       "      \"model_count\": {\n",
       "        \"limit\": 1000,\n",
       "        \"current\": 68\n",
       "      },...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wmlResponseInstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Create an online scoring endpoint.\n",
    "Run the following code that uses the `publishedModelId` value to create an online scoring endpoint ino the WML repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val publishedModelsJson: JsValue = Json.parse(wmlResponseInstance.body)\n",
    "val publishedModelsUrl = (((publishedModelsJson \\ \"entity\") \\\\ \"published_models\")(0) \\ \"url\").as[JsString].value\n",
    "publishedModelsUrl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the list of published models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wmlModels = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HttpResponse({\n",
       "  \"limit\": 1000,\n",
       "  \"resources\": [{\n",
       "    \"metadata\": {\n",
       "      \"guid\": \"f5eb38e5-2b04-4da0-bf14-3edafe554be8\",\n",
       "      \"url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/f5eb38e5-2b04-4da0-bf14-3edafe554be8\",\n",
       "      \"created_at\": \"2019-01-18T02:18:45.291Z\",\n",
       "      \"modified_at\": \"2019-01-18T02:18:45.351Z\"\n",
       "    },\n",
       "    \"entity\": {\n",
       "      \"runtime_environment\": \"spark-2.3\",\n",
       "      \"learning_configuration_url\": \"https://us-south.ml.cloud.ibm.com/v3/wml_instances/b4b6c696-172c-4164-8049-c0b621dbf3c9/published_models/f5eb38e5-2b04-4da0-bf14-3edafe554be8/learning_configuration\",\n",
       "      \"name\": \"Customer churn Spark model\",\n",
       "      \"label_col\": \"Churn\",\n",
       "      \"tags\": [],\n",
       "      \"learning_...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val wmlModels = Http(publishedModelsUrl).\n",
    "                header(\"Content-Type\", \"application/json\").\n",
    "                header(\"Authorization\", \"Bearer \" + iamToken).\n",
    "                option(HttpOptions.connTimeout(10000)).\n",
    "                option(HttpOptions.readTimeout(50000)).asString\n",
    "wmlModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var deploymentEndpoint: String = _\n",
    "\n",
    "wmlModels.body.split(\"\\\"\").map{ \n",
    "    s => {\n",
    "        if ((s contains \"deployments\") & (s contains savedModel.uid.mkString)) {\n",
    "            deploymentEndpoint = s\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "deploymentEndpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an online deployment for published model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payloadName = Online scoring\n",
       "payloadDataOnline = {\"type\":\"online\",\"name\":\"Online scoring\"}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\"type\":\"online\",\"name\":\"Online scoring\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val payloadName = \"Online scoring\"\n",
    "val payloadDataOnline = Json.stringify(Json.toJson(Map(\"type\" -> \"online\", \"name\" -> payloadName)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val responseOnline = Http(deploymentEndpoint).\n",
    "                     postData(payloadDataOnline).\n",
    "                     header(\"Content-Type\", \"application/json\").\n",
    "                     header(\"Authorization\", \"Bearer \" + iamToken).\n",
    "                     option(HttpOptions.connTimeout(50000)).\n",
    "                     option(HttpOptions.readTimeout(50000)).asString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val scoringUrlJson: JsValue = Json.parse(responseOnline.body)\n",
    "val scoringUrl = (scoringUrlJson \\ \"entity\" \\ \"scoring_url\").asOpt[String] match {\n",
    "    case Some(x) => x\n",
    "    case None => \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scoringUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "payloadScoring = {\"fields\":[\"GENDER\",\"AGE\",\"MARITAL_STATUS\",\"PROFESSION\"],\"values\":[[\"M\",55,\"Single\",\"Executive\"]]}\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\"fields\":[\"GENDER\",\"AGE\",\"MARITAL_STATUS\",\"PROFESSION\"],\"values\":[[\"M\",55,\"Single\",\"Executive\"]]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val payloadScoring = Json.stringify(\n",
    "    Json.toJson(\n",
    "        Map(\n",
    "            \"fields\" -> Json.toJson(List(Json.toJson(\"GENDER\"), Json.toJson(\"AGE\"), Json.toJson(\"MARITAL_STATUS\"), Json.toJson(\"PROFESSION\"))),\n",
    "            \"values\" -> Json.toJson(List(List(Json.toJson(\"M\"), Json.toJson(55), Json.toJson(\"Single\"), Json.toJson(\"Executive\"))))\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"fields\":[\"GENDER\",\"AGE\",\"MARITAL_STATUS\",\"PROFESSION\"],\"values\":[[\"M\",55,\"Single\",\"Executive\"]]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "payloadScoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can send (POST) new scoring records (new data) for predictions. To do that, run the following sample code: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "responseScoring = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "HttpResponse({\n",
       "  \"fields\": [\"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", \"PRODUCT_LINE\", \"label\", \"PROFESSION_IX\", \"GENDER_IX\", \"MARITAL_STATUS_IX\", \"features\", \"rawPrediction\", \"probability\", \"prediction\", \"predictedLabel\"],\n",
       "  \"values\": [[\"M\", 55, \"Single\", \"Executive\", \"Camping Equipment\", 0.0, 3.0, 0.0, 1.0, [0.0, 55.0, 1.0, 3.0], [2.5050408694752604, 1.8771700964659068, 2.338808434620882, 3.1481331680893025, 0.13084743134864898], [0.250504086947526, 0.1877170096465907, 0.2338808434620882, 0.31481331680893027, 0.013084743134864898], 3.0, \"Golf Equipment\"]]\n",
       "},200,Map(cache-control -> Vector(private, no-cache, no-store, must-revalidate), Connection -> Vector(keep-alive), Content-Length -> Vector(558), Content-Type -> Vector(applic...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val responseScoring = Http(scoringUrl).\n",
    "                      postData(payloadScoring).\n",
    "                      header(\"Content-Type\", \"application/json\").\n",
    "                      header(\"Authorization\", \"Bearer \" + iamToken).\n",
    "                      option(HttpOptions.method(\"POST\")).\n",
    "                      option(HttpOptions.connTimeout(10000)).\n",
    "                      option(HttpOptions.readTimeout(50000)).asString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HttpResponse({\n",
      "  \"fields\": [\"GENDER\", \"AGE\", \"MARITAL_STATUS\", \"PROFESSION\", \"PRODUCT_LINE\", \"label\", \"PROFESSION_IX\", \"GENDER_IX\", \"MARITAL_STATUS_IX\", \"features\", \"rawPrediction\", \"probability\", \"prediction\", \"predictedLabel\"],\n",
      "  \"values\": [[\"M\", 55, \"Single\", \"Executive\", \"Camping Equipment\", 0.0, 3.0, 0.0, 1.0, [0.0, 55.0, 1.0, 3.0], [2.5050408694752604, 1.8771700964659068, 2.338808434620882, 3.1481331680893025, 0.13084743134864898], [0.250504086947526, 0.1877170096465907, 0.2338808434620882, 0.31481331680893027, 0.013084743134864898], 3.0, \"Golf Equipment\"]]\n",
      "},200,Map(cache-control -> Vector(private, no-cache, no-store, must-revalidate), Connection -> Vector(keep-alive), Content-Length -> Vector(558), Content-Type -> Vector(application/json), Date -> Vector(Tue, 16 Jul 2019 16:05:13 GMT), pragma -> Vector(no-cache), Server -> Vector(nginx), Status -> Vector(HTTP/1.1 200 OK), Strict-Transport-Security -> Vector(max-age=31536000; includeSubDomains), x-content-type-options -> Vector(nosniff), x-envoy-upstream-service-time -> Vector(431), x-frame-options -> Vector(DENY), x-xss-protection -> Vector(1)))"
     ]
    }
   ],
   "source": [
    "print(responseScoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you can predict that a 55-year-old single male executive is interested in Golf Equipment (prediction: 3.0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 6. Summary and next steps \n",
    "\n",
    "You successfully completed this notebook! \n",
    "\n",
    "You learned how to use Spark machine learning as well as Watson Machine Learning for model creation and deployment. \n",
    "\n",
    "Check out our <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts. \n",
    " \n",
    "### Authors\n",
    "\n",
    "**Umit Mert Cakmak** is a Data Scientist at IBM with a track record of developing enterprise-level applications that substantially increases clients' ability to turn data into actionable insights.  \n",
    "**Jihyoung Kim**, Ph.D., is a Data Scientist at IBM who strives to make data science easy for everyone through Watson Studio.\n",
    "\n",
    "Copyright Â© 2017-2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11 with Spark",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
