{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigning Panel Data to Training, Testing and Validation Groups for Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-Sectional data includes individual entities measured in one time period.   For example, if you have 10,000 people measured once, you have cross-sectional data.\n",
    "\n",
    "Time series includes one entity measured over multiple time periods.  For example, if you have a single machine measured every day for ten years, you have a time-series.\n",
    "\n",
    "Panel data includes multiple entities measured over multiple time periods.  For example, if you have 1,000 consumers measured over ten years, you have panel data. Or, if you have 100 machines measured over 100 months, you have panel data.\n",
    "\n",
    "Panel data is quite common in data science. Sometimes, it is called cross-sectional time-series data. I have also heard it referred to as pooled time series data. Whatever you want to call it, as a practicing data scientist, you'll more than likely have to deal with it.\n",
    "\n",
    "It is standard procedure when building machine learning models that you assign your data to modeling groups. Typically, we randomly sub-set the data into Training, Testing and Validation groups. Random, in this case, means that each record in the data set has an equal chance of being assigned to one of the three groups.\n",
    "\n",
    "When you are working with Panel Data, however, you will need to alter the normal process a little.\n",
    "\n",
    "In this notebook, I walk through a simple example on how to do this.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Getting Set Up](#setup1)<br>\n",
    " \n",
    "2. [Data Exploration](#explore)<br>\n",
    " \n",
    "3. [Create the Testing, Training and Validation Groupings by Entity (machine id)](#groups)<br>\n",
    "\n",
    "4. [Conclusions](#conc)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting Set Up <a id=\"setup1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all of the relevant Python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.dual as dual\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the data if you run this notebook more than once\n",
    "!rm equipment_failure_data_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import first half from github\n",
    "!wget https://raw.githubusercontent.com/shadgriffin/panelsampling/main/equipment_failure_data_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert csv to pandas dataframe\n",
    "pd_data_1 = pd.read_csv(\"equipment_failure_data_1.csv\", sep=\",\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove the data if you run this notebook more than once\n",
    "!rm equipment_failure_data_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import the second half from github\n",
    "!wget https://raw.githubusercontent.com/shadgriffin/panelsampling/main/equipment_failure_data_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas dataframe\n",
    "pd_data_2 = pd.read_csv(\"equipment_failure_data_2.csv\", sep=\",\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the two data files into one dataframe\n",
    "pd_data = pd.concat([pd_data_1, pd_data_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration <a id=\"explore\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the first rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>REGION_CLUSTER</th>\n",
       "      <th>MAINTENANCE_VENDOR</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>WELL_GROUP</th>\n",
       "      <th>S15</th>\n",
       "      <th>S17</th>\n",
       "      <th>S13</th>\n",
       "      <th>S5</th>\n",
       "      <th>S16</th>\n",
       "      <th>S19</th>\n",
       "      <th>S18</th>\n",
       "      <th>EQUIPMENT_FAILURE</th>\n",
       "      <th>S8</th>\n",
       "      <th>AGE_OF_EQUIPMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>12/2/14</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>11.088000</td>\n",
       "      <td>145.223448</td>\n",
       "      <td>39.34</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>8.426869</td>\n",
       "      <td>1.9</td>\n",
       "      <td>24.610345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>12/3/14</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>8.877943</td>\n",
       "      <td>187.573214</td>\n",
       "      <td>39.20</td>\n",
       "      <td>3489.0</td>\n",
       "      <td>6.483714</td>\n",
       "      <td>1.9</td>\n",
       "      <td>24.671429</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>12/4/14</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>8.676444</td>\n",
       "      <td>148.363704</td>\n",
       "      <td>38.87</td>\n",
       "      <td>3459.0</td>\n",
       "      <td>6.159659</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.733333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>12/5/14</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>9.988338</td>\n",
       "      <td>133.660000</td>\n",
       "      <td>39.47</td>\n",
       "      <td>3513.0</td>\n",
       "      <td>9.320308</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.773077</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>12/6/14</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>8.475264</td>\n",
       "      <td>197.181600</td>\n",
       "      <td>40.33</td>\n",
       "      <td>3589.0</td>\n",
       "      <td>8.022960</td>\n",
       "      <td>1.5</td>\n",
       "      <td>24.808000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  WELL_GROUP  \\\n",
       "0  100001  12/2/14              G                  O            Y           1   \n",
       "1  100001  12/3/14              G                  O            Y           1   \n",
       "2  100001  12/4/14              G                  O            Y           1   \n",
       "3  100001  12/5/14              G                  O            Y           1   \n",
       "4  100001  12/6/14              G                  O            Y           1   \n",
       "\n",
       "         S15         S17    S13      S5       S16  S19        S18  \\\n",
       "0  11.088000  145.223448  39.34  3501.0  8.426869  1.9  24.610345   \n",
       "1   8.877943  187.573214  39.20  3489.0  6.483714  1.9  24.671429   \n",
       "2   8.676444  148.363704  38.87  3459.0  6.159659  2.0  24.733333   \n",
       "3   9.988338  133.660000  39.47  3513.0  9.320308  2.0  24.773077   \n",
       "4   8.475264  197.181600  40.33  3589.0  8.022960  1.5  24.808000   \n",
       "\n",
       "   EQUIPMENT_FAILURE   S8  AGE_OF_EQUIPMENT  \n",
       "0                  0  0.0               880  \n",
       "1                  0  0.0               881  \n",
       "2                  0  0.0               882  \n",
       "3                  0  0.0               883  \n",
       "4                  0  0.0               884  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID - machine ID\n",
    "\n",
    "DATE - date of observation\n",
    "\n",
    "REGION_CLUSTER - region in which the machine is located\n",
    "\n",
    "MAINTENANCE_VENDOR - company that provides machine maintenance and service\n",
    "\n",
    "MANUFACTURER - equipment manufacturer\n",
    "\n",
    "WELL_GROUP - machine type\n",
    "\n",
    "EQUIPMENT_AGE - machine age, in days\n",
    "\n",
    "S15 - sensor value\n",
    "\n",
    "S17 - sensor value\n",
    "\n",
    "S13 - sensor value\n",
    "\n",
    "S16 - sensor value\n",
    "\n",
    "S19 - sensor value\n",
    "\n",
    "S18 - sensor value\n",
    "\n",
    "S8  - sensor value\n",
    "\n",
    "EQUIPMENT_FAILURE - '1' means that the equipment failed. '0' means the equipment did not fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this data represents a panel data set.  We have multiple machines measured over mulitple time periods.  ID represents the machine and DATE represents the date.  Now, let's examine how many machines and how many dates we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the number of rows and columns.  The data has 307,751 rows and 16 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307751, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 421 machines in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxxx = pd.DataFrame(pd_data.groupby(['ID']).agg(['count']))\n",
    "xxxx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "There are 731 unique dates in the data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(731, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxxx = pd.DataFrame(pd_data.groupby(['DATE']).agg(['count']))\n",
    "xxxx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if we have 421 machines and 731 unique dates..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create the Testing, Training and Validation Groupings by Entity (machine id) <a id=\"groups\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could just randomly assign each record to one of the three groups.  While that could work, I wouldn't recommend it.  I would recommend assigning the group at an entity level (machine in this case).  \n",
    "\n",
    "Why?  \n",
    "\n",
    "Well, I could use some multi-syllabic words (like auto-correlation or mayonnaise) to describe why, but let's just think about it.\n",
    "\n",
    "Why do we separate the data into training, testing and validation groups? \n",
    "\n",
    "We want to ensure that our model is not over-fit.  In other words, we want to make sure that our model applies to new data as it comes available. \n",
    "\n",
    "For example, let's pretend that we built a model that predicts what happened last year with 100% accuracy. Good job, right?  Well, it really doesn't matter how well the model predicts last year.  We need it to predict today, tomorrow and the day after that.  So, if a model predicts last year with 100% accuracy but fails to predict tomorrow, it's no good.\n",
    "\n",
    "Building a model on the training data and verifying the accuracy on the testing and validation data set keeps this from happening.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prevent over-fitting we need our training, testing and validation groups to be independent.  That is, we need to ensure that the data in the training group is different from the testing and validation groups.  Or, at least as different as possible.\n",
    "\n",
    "So what happens if we just randomly assign each record to each of the groups in question?  We end up with records from each entity in each group.  For example with a simple random selection method, if we are dealing with machines, it is probable that machine 123 will appear in your training, testing and validation groups.  If you are dealing with individuals, it is probable that Steve Wakahookie will appear in all three groups.  \n",
    "\n",
    "In other words, your training, testing and validation groups ARE NOT as independent because good ol' Steve and machine 123 are present in all three groups.  \n",
    "\n",
    "Now, if you assign group membership based on entity, all of the Steve's records will be in either the training, testing or validation group.  Likewise, all of the records associated with machine 123 will be in only one of the three groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a unique list of all IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = pd_data\n",
    "\n",
    "pd_id = aa.drop_duplicates(subset='ID')\n",
    "pd_id = pd_id[['ID']]\n",
    "pd_id.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new variable with a random number between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "pd_id['wookie'] = (np.random.randint(0, 10000, pd_id.shape[0]))/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_id = pd_id[['ID', 'wookie']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give each record a 30% chance of being in the validation, a 35% chance of being in the testing and a 35% chance of being in the training data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_id['MODELING_GROUP'] = np.where(((pd_id.wookie <= 0.35)), 'TRAINING', np.where(((pd_id.wookie <= 0.65)), 'VALIDATION', 'TESTING'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how many machines fall in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODELING_GROUP\n",
       "TESTING       149\n",
       "TRAINING      146\n",
       "VALIDATION    126\n",
       "Name: wookie, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_summed = pd_id.groupby(['MODELING_GROUP'])['wookie'].count()\n",
    "tips_summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append the Group of each id to each individual record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_data = pd_data.sort_values(by=['ID'], ascending=[True])\n",
    "pd_id = pd_id.sort_values(by=['ID'], ascending=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>DATE</th>\n",
       "      <th>REGION_CLUSTER</th>\n",
       "      <th>MAINTENANCE_VENDOR</th>\n",
       "      <th>MANUFACTURER</th>\n",
       "      <th>WELL_GROUP</th>\n",
       "      <th>S15</th>\n",
       "      <th>S17</th>\n",
       "      <th>S13</th>\n",
       "      <th>S5</th>\n",
       "      <th>S16</th>\n",
       "      <th>S19</th>\n",
       "      <th>S18</th>\n",
       "      <th>EQUIPMENT_FAILURE</th>\n",
       "      <th>S8</th>\n",
       "      <th>AGE_OF_EQUIPMENT</th>\n",
       "      <th>wookie</th>\n",
       "      <th>MODELING_GROUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>12/2/14</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>11.088</td>\n",
       "      <td>145.223448</td>\n",
       "      <td>39.34</td>\n",
       "      <td>3501.0</td>\n",
       "      <td>8.426869</td>\n",
       "      <td>1.9</td>\n",
       "      <td>24.610345</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>880</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>3/29/16</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>18.960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.87</td>\n",
       "      <td>3459.0</td>\n",
       "      <td>10.047300</td>\n",
       "      <td>1.3</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>34.37</td>\n",
       "      <td>1363</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100001</td>\n",
       "      <td>3/30/16</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>29.040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.36</td>\n",
       "      <td>3325.0</td>\n",
       "      <td>10.235100</td>\n",
       "      <td>1.4</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>32.37</td>\n",
       "      <td>1364</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100001</td>\n",
       "      <td>3/31/16</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.81</td>\n",
       "      <td>3454.0</td>\n",
       "      <td>8.544900</td>\n",
       "      <td>1.4</td>\n",
       "      <td>36.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>34.44</td>\n",
       "      <td>1365</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100001</td>\n",
       "      <td>4/1/16</td>\n",
       "      <td>G</td>\n",
       "      <td>O</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>26.160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.47</td>\n",
       "      <td>3513.0</td>\n",
       "      <td>10.986300</td>\n",
       "      <td>1.4</td>\n",
       "      <td>36.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>33.26</td>\n",
       "      <td>1366</td>\n",
       "      <td>0.727</td>\n",
       "      <td>TESTING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID     DATE REGION_CLUSTER MAINTENANCE_VENDOR MANUFACTURER  WELL_GROUP  \\\n",
       "0  100001  12/2/14              G                  O            Y           1   \n",
       "1  100001  3/29/16              G                  O            Y           1   \n",
       "2  100001  3/30/16              G                  O            Y           1   \n",
       "3  100001  3/31/16              G                  O            Y           1   \n",
       "4  100001   4/1/16              G                  O            Y           1   \n",
       "\n",
       "      S15         S17    S13      S5        S16  S19        S18  \\\n",
       "0  11.088  145.223448  39.34  3501.0   8.426869  1.9  24.610345   \n",
       "1  18.960    0.000000  38.87  3459.0  10.047300  1.3  36.600000   \n",
       "2  29.040    0.000000  37.36  3325.0  10.235100  1.4  36.000000   \n",
       "3  18.000    0.000000  38.81  3454.0   8.544900  1.4  36.100000   \n",
       "4  26.160    0.000000  39.47  3513.0  10.986300  1.4  36.300000   \n",
       "\n",
       "   EQUIPMENT_FAILURE     S8  AGE_OF_EQUIPMENT  wookie MODELING_GROUP  \n",
       "0                  0   0.00               880   0.727        TESTING  \n",
       "1                  0  34.37              1363   0.727        TESTING  \n",
       "2                  0  32.37              1364   0.727        TESTING  \n",
       "3                  0  34.44              1365   0.727        TESTING  \n",
       "4                  0  33.26              1366   0.727        TESTING  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_data = pd_data.merge(pd_id, on=['ID'], how='inner')\n",
    "\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how many records are in each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MODELING_GROUP\n",
       "TESTING       108919\n",
       "TRAINING      106726\n",
       "VALIDATION     92106\n",
       "Name: wookie, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips_summed = pd_data.groupby(['MODELING_GROUP'])['wookie'].count()\n",
    "tips_summed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Conclusion <a id=\"conc\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there you go.  Now, we are ready to build a machine learning model.  By using the placing entities and not records into your training, testing and validation groups you can ensure independence between the groups and build models that work yesterday, today and tomorrow.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Shad Griffin** is a Certified Thought Leader and a Data Scientist at IBM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2021 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
