{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build and deploy an SMS spam classifier with Watson Machine Learning\n",
    "**An Introduction to the Watson Machine Learning Python Client** <br> <br>\n",
    "This notebook will show you how to build and deploy an SMS Spam Classifer with Watson Machine Learning and IBM Watson Studio. <br> We will use the new <a href=\"http://wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning API Client for Python</a> which is available on `PyPi`. \n",
    "______\n",
    "This notebook can be used as a companion to another <a href=\"https://medium.com/@adammassachi/dsx-hybrid-mode-91b580450c5b\" target=\"_blank\" rel=\"noopener noreferrer\">tutorial on our blog</a>.  <br>\n",
    "\n",
    "This notebook runs on Python.",
    "\n",
    "## Table of Contents\n",
    "1. [Load data](#load)\n",
    "2. [Build model](#build)\n",
    "3. [Save and deploy](#save)\n",
    "4. [Make API requests](#api)\n",
    "\n",
    "_____\n",
    "\n",
    "## 1. Load data <a id=\"load\"></a>\n",
    "First, install the Watson Machine Learning library via `pip` if you have not yet installed it. <br> We will use this library to communicate with Watson Machine Learning. The `python client` allows anyone with a Watson Machine Learning instance to programmatically save, load, and deploy models, among other tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are looking to classify are SMS Messages which have been labeled `spam` or `ham`. You can find the data in the community. You can either download the data set to your environment and add it to your project, or you can read the data directly into a data frame as shown below. For more details on loading and accessing data, see <a href=\"https://datascience.ibm.com/docs/content/analyze-data/load-and-access-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">Load and access data in a notebook</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--comment: Simon, here you need to tell them how to access data. They can either (1) go to the community and download the csv with the 'add data' link above, \n",
    "or (2) import the csv directly as in the cell below. Either way, we should be explicit...  I'm trying to find a good example, and frankly, we don't have a really good one.\n",
    "Having said that, you can have a look at https://github.com/IBMDataScience/sample-notebooks/blob/ec37c3f56f33cf8aa85c00e9081f13012ffd8fd5/Cloud/IPYNB/Watson%2Bconversation%2Bservice.ipynb\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://dataplatform.ibm.com/exchange-api/v1/entries/e39fb7848165baca7fc0395025ba4e48/data?accessKey=36100ef896c27e41fdfc4a3029071d50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step will be converting the string label into a numeric representation. <br> \n",
    "We can use a `pandas.Series method`,  `factorize()[0]`, to convert strings into numeric factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[:2]]\n",
    "df.columns = ['ham', 'text']\n",
    "df['label'] = df.ham.factorize()[0]\n",
    "df['text'] = df.text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point, crazy.. available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor... u c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ham                                               text  label\n",
       "0   ham  go until jurong point, crazy.. available only ...      0\n",
       "1   ham                      ok lar... joking wif u oni...      0\n",
       "2  spam  free entry in 2 a wkly comp to win fa cup fina...      1\n",
       "3   ham  u dun say so early hor... u c already then say...      0\n",
       "4   ham  nah i don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build\"></a>\n",
    "## 2. Build a model \n",
    "We will use `scikit-learn` to create a `Naive Bayes` model. <br>We will use the `HashingVectorizer`, which converts the SMS’ text into a matrix representation suitable for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "vectorizer = HashingVectorizer(n_features=5000, stop_words='english', non_negative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to connect the output of the `vectorizer` to the input of the model. We will use `Multinomial Naive Bayes`, a Naive Bayes classifier which works well with the representation of our features  —  integer representations of the word frequencies.\n",
    "\n",
    "\n",
    "Next, we will use `train_test_split` in order to divide the data into `testing` and `training` sets so that we can evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], df['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to transform the text and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first transform the text data\n",
    "transformed_x = vectorizer.fit_transform(x_train)\n",
    "\n",
    "# import the modules and fit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "bn = MultinomialNB().fit(transformed_x, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve got a fit model in `bn`. Let’s evaluate the performance on the test data after creating the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pipe\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vectorizer, bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipe will sequentially transform the data according to the transformers specified, terminating in what scikit-learn calls an estimator. <br>Then, we can call predict or score, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.79965197, 0.20034803]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict_proba([\"URGENT! You have built a model - scroll down to see more\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9619799139167863"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`96% accuracy`, not bad. You can experiment with different numbers of features and vectorizers for your model. You can also create other features that are not captured by the vectorizer, such as the length of the message. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save\"></a>\n",
    "## 3. Save and deploy\n",
    "After creating a model, you might want to make use of its predictions later. In order to do this, we will persist models with Watson Machine Learning. With WML, you can easily `save` and `deploy` models, among other powerful features. `Saving` a model makes this model portable -- as long as you can connect to WML, you can load your saved models into your environment. `Deploying` a model exposes the predictive capacity of the model as an API endpoint, which you can consume in applications, for example. \n",
    "\n",
    "Use the client to save your model to the WML Repository. From there, you can load and deploy models as well. If you don't already have a WML account, you can get more details <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\">here</a>.\n",
    "\n",
    "First, we will import the library and specify our credentials. If you don't know where to find your credentials, they are available to you both in the Watson Studio Project and in IBM Cloud. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "\n",
    "wml_credentials = {\n",
    "    \"apikey\": \"\",\n",
    "    \"username\": \"\",\n",
    "    \"password\": \"\",\n",
    "    \"instance_id\": \"\",\n",
    "    \"url\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have connected to our WML Repository using the python package and our credentials. Publishing the model will save the model to our repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "            client.repository.ModelMetaNames.NAME: 'SPAM_MODEL',\n",
    "            client.repository.ModelMetaNames.FRAMEWORK_NAME: 'scikit-learn',\n",
    "            client.repository.ModelMetaNames.RUNTIME_NAME: 'python',\n",
    "            client.repository.ModelMetaNames.RUNTIME_VERSION: '3.6'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# publish model \n",
    "published_model_details = client.repository.store_model(model=pipe, meta_props=metadata, training_data=pd.DataFrame(df['text']), training_target=df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have saved the model to the repository, we can load it into a python object using it's `uid`. First, let's look at the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4bd39f73-bfff-4660-8e5a-141f18c8c196'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get my model ide\n",
    "guid = client.repository.get_model_uid(published_model_details)\n",
    "guid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model using its id and the `repository.load()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = client.repository.load(guid)\n",
    "type(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the type is an `sklearn` model, just as we created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python36/lib/python3.6/site-packages/sklearn/feature_extraction/hashing.py:94: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.79965197, 0.20034803]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that the loaded model returns the same predictions as the model we developed in our environment. \n",
    "mod.predict_proba([\"URGENT! You have built a model - scroll down to see more\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"api\"></a>\n",
    "## 4. Test the API\n",
    "Now that we have successfully saved and loaded the model, we can create an API endpoint and make requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "Synchronous deployment creation for uid: '4bd39f73-bfff-4660-8e5a-141f18c8c196' started\n",
      "\n",
      "#######################################################################################\n",
      "\n",
      "\n",
      "INITIALIZING\n",
      "DEPLOY_SUCCESS\n",
      "\n",
      "\n",
      "------------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_uid='bf6c81d1-10e4-4917-b3fb-39cdddbdeb84'\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scoring_endpoint = client.deployments.create(name=\"SPAM-NEW\", model_uid=guid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint_url = scoring_endpoint['entity']['scoring_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some JSON to send. We will use `client.deployments.score(scoring_url, payload)`. <a href=\"http://wml-api-pyclient.mybluemix.net/\" target=\"_blank\" rel=\"noopener noreferrer\">Read our docs</a> for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a payload\n",
    "my_sms = \"Send me to the API por favor\"\n",
    "# list of lists\n",
    "payload = {\"fields\": [\"text\"], \"values\": [[my_sms]]}\n",
    "\n",
    "# make a request\n",
    "response = client.deployments.score(scoring_url=scoring_endpoint_url, payload=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check out the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['prediction', 'probability'],\n",
       " 'values': [[0, [0.8211305335459812, 0.17886946645401927]]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "____________\n",
    "\n",
    "### Author\n",
    "Adam Massachi is a Data Scientist with the Watson Studio team at IBM. Before IBM, he worked on political campaigns, building and managing large volunteer operations and organizing campaign finance initiatives. Say hello <a href=\"https://twitter.com/adammassach?lang=en\" target=\"_blank\" rel=\"noopener noreferrer\">@adammassach</a>!\n",
    "\n",
    "Copyright © IBM Corp. 2018, 2019. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
