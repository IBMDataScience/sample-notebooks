{"nbformat_minor": 1, "cells": [{"source": "# Introduction to Spark lab, part 2: Querying data\nThis notebook guides you through querying data with Spark, including how to create and use DataFrames, run SQL queries, apply functions to the results of SQL queries, join data from different data sources, and visualize data in graphs.\n\nThis notebook uses pySpark, the Python API for Spark. Some knowledge of Python is recommended. This notebook runs on Python and Spark.\n\nIf you are new to Spark, see the first module in this series: <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/95811fca38af4ccbea8acf8658bedcfc\" target=\"_blank\" rel=\"noopener noreferrer\">Introduction to Spark, part 1: Basic Concepts</a>.", "cell_type": "markdown", "metadata": {}}, {"source": "## Table of contents\n\n1. [Prepare the environment and the data](#getstarted)<br>\n     1.1 [Enable SQL processing](#sqlprocessing)<br>\n     1.2 [Download the data](#download)<br>\n     1.3 [Create a DataFrame](#createdf)<br>\n     1.4 [Create a table](#createtab)<br>\n2. [Run SQL queries](#runsql)<br>\n    2.1 [Display query results with a pandas DataFrame](#pandas)<br>\n    2.2 [Run a group by query](#groupby)<br>\n    2.3 [Run a subselect query](#subselect)<br>\n    2.4 [Return nested JSON field values](#nested)<br>\n3. [Convert RDDs to DataFrames](#convertrdd)<br>\n    3.1 [Create a simple RDD](#simplerdd)<br>\n    3.2 [Apply a schema](#apply)<br>\n    3.3 [Create rows with named columns](#namedcol)<br>\n    3.4 [Join tables](#join)<br>\n4. [Create SQL functions](#sqlfuncs)<br>\n5. [Convert a pandas DataFrame to a Spark DataFrame](#sparkdf)<br>\n    5.1 [Get a new data set](#ufo)<br>\n    5.2 [Create a pandas DataFrame](#ufopandas)<br>\n    5.3 [Convert to a Spark DataFrame](#sparkufo)<br>\n    5.4 [Run an SQL statement](#runufo)<br>\n6. [Visualize data](#viz)<br>\n    6.1 [Create a chart using Pandas](#vizchart)<br>\n    6.2 [Aggregate the data](#vizagg)<br>\n    6.3 [Create a chart using Spark SQL](#vizchart2)<br>\n7. [Summary and next steps](#nextsteps)", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"getstarted\"></a>\n## 1. Prepare the environment and the data\nBefore you can run SQL queries on data in a Spark environment, you need to enable SQL processing and then move the data to the structured format of a DataFrame.", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"sqlprocessing\"></a>\n### 1.1 Enable SQL processing\nThe preferred method to enable SQL processing with Spark 2.0 is to use the new SparkSession object, but you can also create a SQLContext object. \n\nUse the predefined Spark Context, `sc`, which contains the connection information for Spark, to create an SQLContext:", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190629195823-0001\nKERNEL_ID = 4af820ce-5eb1-4825-86a2-5a56edcc7572\n"}], "execution_count": 1}, {"source": "<a id=\"download\"></a>\n### 1.2 Download the data file\n\nYou'll download a JSON file with data about world banks from GitHub. The data is adapted from this data set: <a href=\"http://data.worldbank.org/data-catalog/projects-portfolio\" target=\"_blank\" rel=\"noopener noreferrer\">http://data.worldbank.org/data-catalog/projects-portfolio</a>.\n\nRemove any files with the same name as the file that you're going to download and then download the file from a URL:", "cell_type": "markdown", "metadata": {}}, {"source": "!rm world_bank.json.gz -f\n!wget https://raw.githubusercontent.com/bradenrc/sparksql_pot/master/world_bank.json.gz", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "--2019-06-29 19:58:33--  https://raw.githubusercontent.com/bradenrc/sparksql_pot/master/world_bank.json.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 199.232.8.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|199.232.8.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 446287 (436K) [application/octet-stream]\nSaving to: 'world_bank.json.gz'\n\nworld_bank.json.gz  100%[===================>] 435.83K  --.-KB/s    in 0.02s   \n\n2019-06-29 19:58:33 (21.7 MB/s) - 'world_bank.json.gz' saved [446287/446287]\n\n"}], "execution_count": 2}, {"source": "<a id=\"createdf\"></a>\n### 1.3 Create a DataFrame \n\nInstead of creating an RDD to read the file, you'll create a Spark DataFrame. Unlike an RDD, a DataFrame creates a schema around the data, which supplies the necessary structure for SQL queries. A self-describing format like JSON is ideal for DataFrames, but many other file types are supported, including text (CSV) and Parquet.\n\nCreate a DataFrame:", "cell_type": "markdown", "metadata": {}}, {"source": "example1_df = sqlContext.read.json(\"world_bank.json.gz\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 3}, {"source": "Print the schema to see how Spark SQL inferred the shape of the data:", "cell_type": "markdown", "metadata": {}}, {"source": "print (example1_df.printSchema())", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- _id: struct (nullable = true)\n |    |-- $oid: string (nullable = true)\n |-- approvalfy: string (nullable = true)\n |-- board_approval_month: string (nullable = true)\n |-- boardapprovaldate: string (nullable = true)\n |-- borrower: string (nullable = true)\n |-- closingdate: string (nullable = true)\n |-- country_namecode: string (nullable = true)\n |-- countrycode: string (nullable = true)\n |-- countryname: string (nullable = true)\n |-- countryshortname: string (nullable = true)\n |-- docty: string (nullable = true)\n |-- envassesmentcategorycode: string (nullable = true)\n |-- grantamt: long (nullable = true)\n |-- ibrdcommamt: long (nullable = true)\n |-- id: string (nullable = true)\n |-- idacommamt: long (nullable = true)\n |-- impagency: string (nullable = true)\n |-- lendinginstr: string (nullable = true)\n |-- lendinginstrtype: string (nullable = true)\n |-- lendprojectcost: long (nullable = true)\n |-- majorsector_percent: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- Name: string (nullable = true)\n |    |    |-- Percent: long (nullable = true)\n |-- mjsector_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- mjtheme: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- mjtheme_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- mjthemecode: string (nullable = true)\n |-- prodline: string (nullable = true)\n |-- prodlinetext: string (nullable = true)\n |-- productlinetype: string (nullable = true)\n |-- project_abstract: struct (nullable = true)\n |    |-- cdata: string (nullable = true)\n |-- project_name: string (nullable = true)\n |-- projectdocs: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- DocDate: string (nullable = true)\n |    |    |-- DocType: string (nullable = true)\n |    |    |-- DocTypeDesc: string (nullable = true)\n |    |    |-- DocURL: string (nullable = true)\n |    |    |-- EntityID: string (nullable = true)\n |-- projectfinancialtype: string (nullable = true)\n |-- projectstatusdisplay: string (nullable = true)\n |-- regionname: string (nullable = true)\n |-- sector: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- Name: string (nullable = true)\n |-- sector1: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector2: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector3: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector4: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- sectorcode: string (nullable = true)\n |-- source: string (nullable = true)\n |-- status: string (nullable = true)\n |-- supplementprojectflg: string (nullable = true)\n |-- theme1: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- theme_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- themecode: string (nullable = true)\n |-- totalamt: long (nullable = true)\n |-- totalcommamt: long (nullable = true)\n |-- url: string (nullable = true)\n\nNone\n"}], "execution_count": 4}, {"source": "Now look at the first two rows of data.\n\nYou can run the simple command `print example1_df.take(2)`, however, for readability, run the following command to include a row of asterisks in between the data rows:", "cell_type": "markdown", "metadata": {}}, {"source": "for row in example1_df.take(2):\n    print (row)\n    print (\"*\" * 20)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Row(_id=Row($oid='52b213b38594d8a2be17c780'), approvalfy='1999', board_approval_month='November', boardapprovaldate='2013-11-12T00:00:00Z', borrower='FEDERAL DEMOCRATIC REPUBLIC OF ETHIOPIA', closingdate='2018-07-07T00:00:00Z', country_namecode='Federal Democratic Republic of Ethiopia!$!ET', countrycode='ET', countryname='Federal Democratic Republic of Ethiopia', countryshortname='Ethiopia', docty='Project Information Document,Indigenous Peoples Plan,Project Information Document', envassesmentcategorycode='C', grantamt=0, ibrdcommamt=0, id='P129828', idacommamt=130000000, impagency='MINISTRY OF EDUCATION', lendinginstr='Investment Project Financing', lendinginstrtype='IN', lendprojectcost=550000000, majorsector_percent=[Row(Name='Education', Percent=46), Row(Name='Education', Percent=26), Row(Name='Public Administration, Law, and Justice', Percent=16), Row(Name='Education', Percent=12)], mjsector_namecode=[Row(code='EX', name='Education'), Row(code='EX', name='Education'), Row(code='BX', name='Public Administration, Law, and Justice'), Row(code='EX', name='Education')], mjtheme=['Human development'], mjtheme_namecode=[Row(code='8', name='Human development'), Row(code='11', name='')], mjthemecode='8,11', prodline='PE', prodlinetext='IBRD/IDA', productlinetype='L', project_abstract=Row(cdata='The development objective of the Second Phase of General Education Quality Improvement Project for Ethiopia is to improve learning conditions in primary and secondary schools and strengthen institutions at different levels of educational administration. The project has six components. The first component is curriculum, textbooks, assessment, examinations, and inspection. This component will support improvement of learning conditions in grades KG-12 by providing increased access to teaching and learning materials and through improvements to the curriculum by assessing the strengths and weaknesses of the current curriculum. This component has following four sub-components: (i) curriculum reform and implementation; (ii) teaching and learning materials; (iii) assessment and examinations; and (iv) inspection. The second component is teacher development program (TDP). This component will support improvements in learning conditions in both primary and secondary schools by advancing the quality of teaching in general education through: (a) enhancing the training of pre-service teachers in teacher education institutions; and (b) improving the quality of in-service teacher training. This component has following three sub-components: (i) pre-service teacher training; (ii) in-service teacher training; and (iii) licensing and relicensing of teachers and school leaders. The third component is school improvement plan. This component will support the strengthening of school planning in order to improve learning outcomes, and to partly fund the school improvement plans through school grants. It has following two sub-components: (i) school improvement plan; and (ii) school grants. The fourth component is management and capacity building, including education management information systems (EMIS). This component will support management and capacity building aspect of the project. This component has following three sub-components: (i) capacity building for education planning and management; (ii) capacity building for school planning and management; and (iii) EMIS. The fifth component is improving the quality of learning and teaching in secondary schools and universities through the use of information and communications technology (ICT). It has following five sub-components: (i) national policy and institution for ICT in general education; (ii) national ICT infrastructure improvement plan for general education; (iii) develop an integrated monitoring, evaluation, and learning system specifically for the ICT component; (iv) teacher professional development in the use of ICT; and (v) provision of limited number of e-Braille display readers with the possibility to scale up to all secondary education schools based on the successful implementation and usage of the readers. The sixth component is program coordination, monitoring and evaluation, and communication. It will support institutional strengthening by developing capacities in all aspects of program coordination, monitoring and evaluation; a new sub-component on communications will support information sharing for better management and accountability. It has following three sub-components: (i) program coordination; (ii) monitoring and evaluation (M and E); and (iii) communication.'), project_name='Ethiopia General Education Quality Improvement Project II', projectdocs=[Row(DocDate='28-AUG-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=090224b081e545fb_1_0', EntityID='090224b081e545fb_1_0'), Row(DocDate='01-JUL-2013', DocType='IP', DocTypeDesc='Indigenous Peoples Plan (IP),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000442464_20130920111729', EntityID='000442464_20130920111729'), Row(DocDate='22-NOV-2012', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=090224b0817b19e2_1_0', EntityID='090224b0817b19e2_1_0')], projectfinancialtype='IDA', projectstatusdisplay='Active', regionname='Africa', sector=[Row(Name='Primary education'), Row(Name='Secondary education'), Row(Name='Public administration- Other social services'), Row(Name='Tertiary education')], sector1=Row(Name='Primary education', Percent=46), sector2=Row(Name='Secondary education', Percent=26), sector3=Row(Name='Public administration- Other social services', Percent=16), sector4=Row(Name='Tertiary education', Percent=12), sector_namecode=[Row(code='EP', name='Primary education'), Row(code='ES', name='Secondary education'), Row(code='BS', name='Public administration- Other social services'), Row(code='ET', name='Tertiary education')], sectorcode='ET,BS,ES,EP', source='IBRD', status='Active', supplementprojectflg='N', theme1=Row(Name='Education for all', Percent=100), theme_namecode=[Row(code='65', name='Education for all')], themecode='65', totalamt=130000000, totalcommamt=130000000, url='http://www.worldbank.org/projects/P129828/ethiopia-general-education-quality-improvement-project-ii?lang=en')\n********************\nRow(_id=Row($oid='52b213b38594d8a2be17c781'), approvalfy='2015', board_approval_month='November', boardapprovaldate='2013-11-04T00:00:00Z', borrower='GOVERNMENT OF TUNISIA', closingdate=None, country_namecode='Republic of Tunisia!$!TN', countrycode='TN', countryname='Republic of Tunisia', countryshortname='Tunisia', docty='Project Information Document,Integrated Safeguards Data Sheet,Integrated Safeguards Data Sheet,Project Information Document,Integrated Safeguards Data Sheet,Project Information Document', envassesmentcategorycode='C', grantamt=4700000, ibrdcommamt=0, id='P144674', idacommamt=0, impagency='MINISTRY OF FINANCE', lendinginstr='Specific Investment Loan', lendinginstrtype='IN', lendprojectcost=5700000, majorsector_percent=[Row(Name='Public Administration, Law, and Justice', Percent=70), Row(Name='Public Administration, Law, and Justice', Percent=30)], mjsector_namecode=[Row(code='BX', name='Public Administration, Law, and Justice'), Row(code='BX', name='Public Administration, Law, and Justice')], mjtheme=['Economic management', 'Social protection and risk management'], mjtheme_namecode=[Row(code='1', name='Economic management'), Row(code='6', name='Social protection and risk management')], mjthemecode='1,6', prodline='RE', prodlinetext='Recipient Executed Activities', productlinetype='L', project_abstract=None, project_name='TN: DTF Social Protection Reforms Support', projectdocs=[Row(DocDate='29-MAR-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000333037_20131024115616', EntityID='000333037_20131024115616'), Row(DocDate='29-MAR-2013', DocType='ISDS', DocTypeDesc='Integrated Safeguards Data Sheet (ISDS),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000356161_20131024151611', EntityID='000356161_20131024151611'), Row(DocDate='29-MAR-2013', DocType='ISDS', DocTypeDesc='Integrated Safeguards Data Sheet (ISDS),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000442464_20131031112136', EntityID='000442464_20131031112136'), Row(DocDate='29-MAR-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000333037_20131031105716', EntityID='000333037_20131031105716'), Row(DocDate='16-JAN-2013', DocType='ISDS', DocTypeDesc='Integrated Safeguards Data Sheet (ISDS),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000356161_20130305113209', EntityID='000356161_20130305113209'), Row(DocDate='16-JAN-2013', DocType='PID', DocTypeDesc='Project Information Document (PID),  Vol.1 of 1', DocURL='http://www-wds.worldbank.org/servlet/WDSServlet?pcont=details&eid=000356161_20130305113716', EntityID='000356161_20130305113716')], projectfinancialtype='OTHER', projectstatusdisplay='Active', regionname='Middle East and North Africa', sector=[Row(Name='Public administration- Other social services'), Row(Name='General public administration sector')], sector1=Row(Name='Public administration- Other social services', Percent=70), sector2=Row(Name='General public administration sector', Percent=30), sector3=None, sector4=None, sector_namecode=[Row(code='BS', name='Public administration- Other social services'), Row(code='BZ', name='General public administration sector')], sectorcode='BZ,BS', source='IBRD', status='Active', supplementprojectflg='N', theme1=Row(Name='Other economic management', Percent=30), theme_namecode=[Row(code='24', name='Other economic management'), Row(code='54', name='Social safety nets')], themecode='54,24', totalamt=0, totalcommamt=4700000, url='http://www.worldbank.org/projects/P144674?lang=en')\n********************\n"}], "execution_count": 5}, {"source": "<a id=\"createtab\"></a>\n### 1.4 Create a table \n\nSQL statements must be run against a table. Create a table that's a pointer to the DataFrame:", "cell_type": "markdown", "metadata": {}}, {"source": "example1_df.registerTempTable(\"world_bank\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 6}, {"source": "<a id=\"runsql\"></a>\n## 2. Run SQL queries\n\nYou must define a new DataFrame for the results of the SQL query and put the SQL statement inside the `sqlContext.sql()` method.\n\nRun the following cell to select all columns from the table and print information about the resulting DataFrame and schema of the data:", "cell_type": "markdown", "metadata": {}}, {"source": "temp_df =  sqlContext.sql(\"select * from world_bank\")\n\nprint (type(temp_df))\nprint (\"*\" * 20)\nprint (temp_df)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "<class 'pyspark.sql.dataframe.DataFrame'>\n********************\nDataFrame[_id: struct<$oid:string>, approvalfy: string, board_approval_month: string, boardapprovaldate: string, borrower: string, closingdate: string, country_namecode: string, countrycode: string, countryname: string, countryshortname: string, docty: string, envassesmentcategorycode: string, grantamt: bigint, ibrdcommamt: bigint, id: string, idacommamt: bigint, impagency: string, lendinginstr: string, lendinginstrtype: string, lendprojectcost: bigint, majorsector_percent: array<struct<Name:string,Percent:bigint>>, mjsector_namecode: array<struct<code:string,name:string>>, mjtheme: array<string>, mjtheme_namecode: array<struct<code:string,name:string>>, mjthemecode: string, prodline: string, prodlinetext: string, productlinetype: string, project_abstract: struct<cdata:string>, project_name: string, projectdocs: array<struct<DocDate:string,DocType:string,DocTypeDesc:string,DocURL:string,EntityID:string>>, projectfinancialtype: string, projectstatusdisplay: string, regionname: string, sector: array<struct<Name:string>>, sector1: struct<Name:string,Percent:bigint>, sector2: struct<Name:string,Percent:bigint>, sector3: struct<Name:string,Percent:bigint>, sector4: struct<Name:string,Percent:bigint>, sector_namecode: array<struct<code:string,name:string>>, sectorcode: string, source: string, status: string, supplementprojectflg: string, theme1: struct<Name:string,Percent:bigint>, theme_namecode: array<struct<code:string,name:string>>, themecode: string, totalamt: bigint, totalcommamt: bigint, url: string]\n"}], "execution_count": 7}, {"source": "The first `print` command shows that the DataFrame is a Spark DataFrame. The last `print` command shows the column names and data types of the DataFrame.", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"pandas\"></a>\n### 2.1 Display query results with a pandas DataFrame\nThe `print` command doesn't show the data in a useful format. Instead of creating a Spark DataFrame, use the pandas open-source data analytics library to create a pandas DataFrame that shows the data in a table. \n\nImport the pandas library and use the `.toPandas()` method to show the query results:", "cell_type": "markdown", "metadata": {}}, {"source": "import pandas as pd\nsqlContext.sql(\"select id, borrower from world_bank limit 2\").toPandas()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>borrower</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P129828</td>\n      <td>FEDERAL DEMOCRATIC REPUBLIC OF ETHIOPIA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P144674</td>\n      <td>GOVERNMENT OF TUNISIA</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "        id                                 borrower\n0  P129828  FEDERAL DEMOCRATIC REPUBLIC OF ETHIOPIA\n1  P144674                    GOVERNMENT OF TUNISIA"}, "execution_count": 8, "metadata": {}}], "execution_count": 8}, {"source": "<a id=\"groupby\"></a>\n### 2.2 Run a group by query\n\nYou can make your SQL queries easier to read by using the `query` keyword and surrounding the SQL query with `\"\"\"` on separate lines. \n\nCalculate a count of projects by region:", "cell_type": "markdown", "metadata": {}}, {"source": "query = \"\"\"\nselect\n    regionname ,\n    count(*) as project_count\nfrom world_bank\ngroup by regionname \norder by count(*) desc\n\"\"\"\n\nsqlContext.sql(query).toPandas()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>regionname</th>\n      <th>project_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Africa</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>East Asia and Pacific</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Europe and Central Asia</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>South Asia</td>\n      <td>65</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Middle East and North Africa</td>\n      <td>54</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Latin America and Caribbean</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Other</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "                     regionname  project_count\n0                        Africa            152\n1         East Asia and Pacific            100\n2       Europe and Central Asia             74\n3                    South Asia             65\n4  Middle East and North Africa             54\n5   Latin America and Caribbean             53\n6                         Other              2"}, "execution_count": 9, "metadata": {}}], "execution_count": 9}, {"source": "<a id=\"subselect\"></a>\n### 2.3 Run a subselect query\nYou can run subselect queries.\n\nCalculate a count of projects by region again, but this time using a subselect:", "cell_type": "markdown", "metadata": {}}, {"source": "query = \"\"\"\n\nselect * from\n    (select\n        regionname ,\n        count(*) as project_count\n    from world_bank\n    group by regionname \n    order by count(*) desc) table_alias\nlimit 2\n\"\"\"\n\nsqlContext.sql(query).toPandas()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>regionname</th>\n      <th>project_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Africa</td>\n      <td>152</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>East Asia and Pacific</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "              regionname  project_count\n0                 Africa            152\n1  East Asia and Pacific            100"}, "execution_count": 10, "metadata": {}}], "execution_count": 10}, {"source": "<a id=\"nested\"></a>\n### 2.4 Return nested JSON field values\nWith JSON data, you can select the values of nested fields with dot notation.\n\nPrint the schema so that you can see that `sector.Name` is a nested field and then select its first two values:", "cell_type": "markdown", "metadata": {}}, {"source": "example1_df.printSchema()\n\nsql = \"select sector.Name from world_bank limit 2\"\nsqlContext.sql(sql).show()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "root\n |-- _id: struct (nullable = true)\n |    |-- $oid: string (nullable = true)\n |-- approvalfy: string (nullable = true)\n |-- board_approval_month: string (nullable = true)\n |-- boardapprovaldate: string (nullable = true)\n |-- borrower: string (nullable = true)\n |-- closingdate: string (nullable = true)\n |-- country_namecode: string (nullable = true)\n |-- countrycode: string (nullable = true)\n |-- countryname: string (nullable = true)\n |-- countryshortname: string (nullable = true)\n |-- docty: string (nullable = true)\n |-- envassesmentcategorycode: string (nullable = true)\n |-- grantamt: long (nullable = true)\n |-- ibrdcommamt: long (nullable = true)\n |-- id: string (nullable = true)\n |-- idacommamt: long (nullable = true)\n |-- impagency: string (nullable = true)\n |-- lendinginstr: string (nullable = true)\n |-- lendinginstrtype: string (nullable = true)\n |-- lendprojectcost: long (nullable = true)\n |-- majorsector_percent: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- Name: string (nullable = true)\n |    |    |-- Percent: long (nullable = true)\n |-- mjsector_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- mjtheme: array (nullable = true)\n |    |-- element: string (containsNull = true)\n |-- mjtheme_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- mjthemecode: string (nullable = true)\n |-- prodline: string (nullable = true)\n |-- prodlinetext: string (nullable = true)\n |-- productlinetype: string (nullable = true)\n |-- project_abstract: struct (nullable = true)\n |    |-- cdata: string (nullable = true)\n |-- project_name: string (nullable = true)\n |-- projectdocs: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- DocDate: string (nullable = true)\n |    |    |-- DocType: string (nullable = true)\n |    |    |-- DocTypeDesc: string (nullable = true)\n |    |    |-- DocURL: string (nullable = true)\n |    |    |-- EntityID: string (nullable = true)\n |-- projectfinancialtype: string (nullable = true)\n |-- projectstatusdisplay: string (nullable = true)\n |-- regionname: string (nullable = true)\n |-- sector: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- Name: string (nullable = true)\n |-- sector1: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector2: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector3: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector4: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- sector_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- sectorcode: string (nullable = true)\n |-- source: string (nullable = true)\n |-- status: string (nullable = true)\n |-- supplementprojectflg: string (nullable = true)\n |-- theme1: struct (nullable = true)\n |    |-- Name: string (nullable = true)\n |    |-- Percent: long (nullable = true)\n |-- theme_namecode: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- code: string (nullable = true)\n |    |    |-- name: string (nullable = true)\n |-- themecode: string (nullable = true)\n |-- totalamt: long (nullable = true)\n |-- totalcommamt: long (nullable = true)\n |-- url: string (nullable = true)\n\n+--------------------+\n|                Name|\n+--------------------+\n|[Primary educatio...|\n|[Public administr...|\n+--------------------+\n\n"}], "execution_count": 11}, {"source": "<a id=\"convertrdd\"></a>\n## 3. Convert RDDs to DataFrames\nIf you want to run SQL queries on an existing RDD, you must convert the RDD to a DataFrame. The main difference between RDDs and DataFrames is whether the columns are named.\n\nYou'll create an RDD and then convert it to a DataFrame in two different ways:\n - [Apply a schema](#apply)\n - [Create rows with named columns](#namedcol)", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"simplerdd\"></a>\n### 3.1 Create a simple RDD\nYou'll create a simple RDD with an ID column and two columns of random numbers.\n\nFirst create a Python list of lists:", "cell_type": "markdown", "metadata": {}}, {"source": "import random\n\ndata_e2 = []\nfor x in range(1,6):\n    random_int = int(random.random() * 10)\n    data_e2.append([x, random_int, random_int^2])", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 12}, {"source": "Now create the RDD:", "cell_type": "markdown", "metadata": {}}, {"source": "rdd_example2 = sc.parallelize(data_e2)\nprint (rdd_example2.collect())", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[[1, 1, 3], [2, 3, 1], [3, 1, 3], [4, 8, 10], [5, 0, 2]]\n"}], "execution_count": 13}, {"source": "<a id=\"apply\"></a>\n### 3.2 Apply a schema\nYou'll use the `StructField` method to create a schema object that's based on a string, apply the schema to the RDD to create a DataFrame, and then create a table to run SQL queries on.\n\nDefine your schema columns as a string:", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.sql.types import *\n\nschemaString = \"ID VAL1 VAL2\"", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 14}, {"source": "Assign header information with the `StructField` method and create the schema with the `StructType` method:", "cell_type": "markdown", "metadata": {}}, {"source": "fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\nschema = StructType(fields)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 15}, {"source": "Apply the schema to the RDD with the `createDataFrame` method:", "cell_type": "markdown", "metadata": {}}, {"source": "schemaExample = sqlContext.createDataFrame(rdd_example2, schema)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 16}, {"source": "Register the DataFrame as a table:", "cell_type": "markdown", "metadata": {}}, {"source": "schemaExample.registerTempTable(\"example2\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 17}, {"source": "View the data:", "cell_type": "markdown", "metadata": {}}, {"source": "print (schemaExample.collect())", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(ID='1', VAL1='1', VAL2='3'), Row(ID='2', VAL1='3', VAL2='1'), Row(ID='3', VAL1='1', VAL2='3'), Row(ID='4', VAL1='8', VAL2='10'), Row(ID='5', VAL1='0', VAL2='2')]\n"}], "execution_count": 18}, {"source": "You can reference the columns names in DataFrames:", "cell_type": "markdown", "metadata": {}}, {"source": "for row in schemaExample.take(2):\n    print (row.ID, row.VAL1, row.VAL2)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "1 1 3\n2 3 1\n"}], "execution_count": 19}, {"source": "Run a simple SQL query:", "cell_type": "markdown", "metadata": {}}, {"source": "sqlContext.sql(\"select * from example2\").toPandas()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>VAL1</th>\n      <th>VAL2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  ID VAL1 VAL2\n0  1    1    3\n1  2    3    1\n2  3    1    3\n3  4    8   10\n4  5    0    2"}, "execution_count": 20, "metadata": {}}], "execution_count": 20}, {"source": "<a id=\"namedcol\"></a>\n### 3.3 Create rows with named columns\nYou'll create an RDD with named columns and then convert it to a DataFrame and a table.\n\nCreate a new RDD and specify the names of the columns with the `map` method:", "cell_type": "markdown", "metadata": {}}, {"source": "from pyspark.sql import Row\n\nrdd_example3 = rdd_example2.map(lambda x: Row(id=x[0], val1=x[1], val2=x[2]))\n\nprint (rdd_example3.collect())                                                         ", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(id=1, val1=1, val2=3), Row(id=2, val1=3, val2=1), Row(id=3, val1=1, val2=3), Row(id=4, val1=8, val2=10), Row(id=5, val1=0, val2=2)]\n"}], "execution_count": 21}, {"source": "Convert `rdd_example3` to a DataFrame and register an associated table:", "cell_type": "markdown", "metadata": {}}, {"source": "df_example3 = rdd_example3.toDF()\ndf_example3.registerTempTable(\"example3\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 22}, {"source": "Run a simple SQL query:", "cell_type": "markdown", "metadata": {}}, {"source": "sqlContext.sql(\"select * from example3\").toPandas()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>val1</th>\n      <th>val2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "   id  val1  val2\n0   1     1     3\n1   2     3     1\n2   3     1     3\n3   4     8    10\n4   5     0     2"}, "execution_count": 23, "metadata": {}}], "execution_count": 23}, {"source": "<a id=\"join\"></a>\n### 3.4 Join tables\nYou can join tables.\n\nJoin tables `example2` and `example3` on the ID column:", "cell_type": "markdown", "metadata": {}}, {"source": "query = \"\"\"\nselect\n    *\nfrom\n    example2 e2\ninner join example3 e3 on\n    e2.ID = e3.id\n\"\"\"\n\nprint (sqlContext.sql(query).toPandas())", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "  ID VAL1 VAL2  id  val1  val2\n0  5    0    2   5     0     2\n1  1    1    3   1     1     3\n2  3    1    3   3     1     3\n3  2    3    1   2     3     1\n4  4    8   10   4     8    10\n"}], "execution_count": 24}, {"source": "Alternatively, you can join DataFrames with a Python command instead of an SQL query:", "cell_type": "markdown", "metadata": {}}, {"source": "df_example4 = df_example3.join(schemaExample, schemaExample[\"ID\"] == df_example3[\"id\"] )\n\nfor row in df_example4.take(5):\n    print (row)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Row(id=5, val1=0, val2=2, ID='5', VAL1='0', VAL2='2')\nRow(id=1, val1=1, val2=3, ID='1', VAL1='1', VAL2='3')\nRow(id=3, val1=1, val2=3, ID='3', VAL1='1', VAL2='3')\nRow(id=2, val1=3, val2=1, ID='2', VAL1='3', VAL2='1')\nRow(id=4, val1=8, val2=10, ID='4', VAL1='8', VAL2='10')\n"}], "execution_count": 25}, {"source": "<a id=\"sqlfuncs\"></a>\n## 4. Create SQL functions \nYou can create functions that run in SQL queries. \n\nFirst, create a Python function and test it:", "cell_type": "markdown", "metadata": {}}, {"source": "def simple_function(v):\n    return int(v * 10)\n\n#test the function\nprint (simple_function(3))", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "30\n"}], "execution_count": 26}, {"source": "Next, register the function as an SQL function with the `registerFunction` method:", "cell_type": "markdown", "metadata": {}}, {"source": "sqlContext.registerFunction(\"simple_function\", simple_function)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "<function __main__.simple_function>"}, "execution_count": 27, "metadata": {}}], "execution_count": 27}, {"source": "Now run the function in an SQL Statement:", "cell_type": "markdown", "metadata": {}}, {"source": "query = \"\"\"\nselect\n    ID,\n    VAL1,\n    VAL2,\n    simple_function(VAL1) as s_VAL1,\n    simple_function(VAL2) as s_VAL2\nfrom\n example2\n\"\"\"\nsqlContext.sql(query).toPandas()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>VAL1</th>\n      <th>VAL2</th>\n      <th>s_VAL1</th>\n      <th>s_VAL2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1111111111</td>\n      <td>3333333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3333333333</td>\n      <td>1111111111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1111111111</td>\n      <td>3333333333</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>8</td>\n      <td>10</td>\n      <td>8888888888</td>\n      <td>10101010101010101010</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2222222222</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  ID VAL1 VAL2      s_VAL1                s_VAL2\n0  1    1    3  1111111111            3333333333\n1  2    3    1  3333333333            1111111111\n2  3    1    3  1111111111            3333333333\n3  4    8   10  8888888888  10101010101010101010\n4  5    0    2           0            2222222222"}, "execution_count": 28, "metadata": {}}], "execution_count": 28}, {"source": "The values in the VAL1 and VAL2 columns look like strings (10 characters instead of a number multiplied by 10). That's because string is the default data type for columns in Spark DataFrames.\n\nCast the values in the VAL1 and VAL2 columns to integers: ", "cell_type": "markdown", "metadata": {}}, {"source": "query = \"\"\"\nselect\n    ID,\n    VAL1,\n    VAL2,\n    simple_function(cast(VAL1 as int)) as s_VAL1,\n    simple_function(cast(VAL2 as int)) as s_VAL2\nfrom\n example2\n\"\"\"\nsqlContext.sql(query).toPandas()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>VAL1</th>\n      <th>VAL2</th>\n      <th>s_VAL1</th>\n      <th>s_VAL2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>30</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>10</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>8</td>\n      <td>10</td>\n      <td>80</td>\n      <td>100</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  ID VAL1 VAL2 s_VAL1 s_VAL2\n0  1    1    3     10     30\n1  2    3    1     30     10\n2  3    1    3     10     30\n3  4    8   10     80    100\n4  5    0    2      0     20"}, "execution_count": 29, "metadata": {}}], "execution_count": 29}, {"source": "That looks better!", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"sparkdf\"></a>\n## 5. Convert a pandas DataFrame to a Spark DataFrame\nAlthough pandas DataFrames display data in a friendlier format, Spark DataFrames can be faster and more scalable.\n\nYou'll get a new data set, create a pandas DataFrame for it, and then convert the pandas DataFrame to a Spark DataFrame.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "<a id=\"ufo\"></a>\n### 5.1 Get a new data set\nGet a data set about anonymous outdoor equipment purchase data:", "cell_type": "markdown", "metadata": {}}, {"source": "!rm GoSales_Tx.csv -f\n!wget https://raw.githubusercontent.com/pmservice/wml-sample-models/master/spark/product-line-prediction/data/GoSales_Tx.csv", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "--2019-06-29 20:02:01--  https://raw.githubusercontent.com/pmservice/wml-sample-models/master/spark/product-line-prediction/data/GoSales_Tx.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2470333 (2.4M) [text/plain]\nSaving to: 'GoSales_Tx.csv'\n\nGoSales_Tx.csv      100%[===================>]   2.36M  --.-KB/s    in 0.05s   \n\n2019-06-29 20:02:02 (47.6 MB/s) - 'GoSales_Tx.csv' saved [2470333/2470333]\n\n"}], "execution_count": 30}, {"source": "<a id=\"ufopandas\"></a>\n### 5.2 Create a pandas DataFrame\nCreate a pandas DataFrame of the data set with the `read_csv` method:", "cell_type": "markdown", "metadata": {}}, {"source": "pandas_df = pd.read_csv(\"./GoSales_Tx.csv\")\npandas_df.head()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GENDER</th>\n      <th>AGE</th>\n      <th>MARITAL_STATUS</th>\n      <th>PROFESSION</th>\n      <th>PRODUCT_LINE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>27</td>\n      <td>Single</td>\n      <td>Professional</td>\n      <td>Personal Accessories</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>39</td>\n      <td>Single</td>\n      <td>Executive</td>\n      <td>Personal Accessories</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>39</td>\n      <td>Married</td>\n      <td>Student</td>\n      <td>Mountaineering Equipment</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>F</td>\n      <td>56</td>\n      <td>Single</td>\n      <td>Hospitality</td>\n      <td>Personal Accessories</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>45</td>\n      <td>Married</td>\n      <td>Retired</td>\n      <td>Golf Equipment</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  GENDER  AGE MARITAL_STATUS    PROFESSION              PRODUCT_LINE\n0      M   27         Single  Professional      Personal Accessories\n1      F   39         Single     Executive      Personal Accessories\n2      M   39        Married       Student  Mountaineering Equipment\n3      F   56         Single   Hospitality      Personal Accessories\n4      M   45        Married       Retired            Golf Equipment"}, "execution_count": 31, "metadata": {}}], "execution_count": 31}, {"source": "<a id=\"sparkufo\"></a>\n### 5.3 Convert to a Spark DataFrame\nConvert the pandas DataFrame to a Spark DataFrame with the `createDataFrame` method. Remember using the `createDataFrame` method to convert an RDD to a Spark DataFrame?", "cell_type": "markdown", "metadata": {}}, {"source": "spark_df = sqlContext.createDataFrame(pandas_df)", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 32}, {"source": "Print the first two rows:", "cell_type": "markdown", "metadata": {}}, {"source": "spark_df.show(2)", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------+---+--------------+------------+--------------------+\n|GENDER|AGE|MARITAL_STATUS|  PROFESSION|        PRODUCT_LINE|\n+------+---+--------------+------------+--------------------+\n|     M| 27|        Single|Professional|Personal Accessories|\n|     F| 39|        Single|   Executive|Personal Accessories|\n+------+---+--------------+------------+--------------------+\nonly showing top 2 rows\n\n"}], "execution_count": 33}, {"source": "Register the Spark DataFrame as a table:", "cell_type": "markdown", "metadata": {}}, {"source": "spark_df.registerTempTable(\"gosales_tx\")", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 34}, {"source": "<a id=\"runufo\"></a>\n### 5.4 Run an SQL statement\nNow run an SQL statement to print the first 10 rows of the table:", "cell_type": "markdown", "metadata": {}}, {"source": "print(sqlContext.sql(\"select * from gosales_tx limit 10\").collect())", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "[Row(GENDER='M', AGE=27, MARITAL_STATUS='Single', PROFESSION='Professional', PRODUCT_LINE='Personal Accessories'), Row(GENDER='F', AGE=39, MARITAL_STATUS='Single', PROFESSION='Executive', PRODUCT_LINE='Personal Accessories'), Row(GENDER='M', AGE=39, MARITAL_STATUS='Married', PROFESSION='Student', PRODUCT_LINE='Mountaineering Equipment'), Row(GENDER='F', AGE=56, MARITAL_STATUS='Single', PROFESSION='Hospitality', PRODUCT_LINE='Personal Accessories'), Row(GENDER='M', AGE=45, MARITAL_STATUS='Married', PROFESSION='Retired', PRODUCT_LINE='Golf Equipment'), Row(GENDER='M', AGE=45, MARITAL_STATUS='Married', PROFESSION='Retired', PRODUCT_LINE='Golf Equipment'), Row(GENDER='M', AGE=39, MARITAL_STATUS='Married', PROFESSION='Student', PRODUCT_LINE='Camping Equipment'), Row(GENDER='M', AGE=49, MARITAL_STATUS='Married', PROFESSION='Student', PRODUCT_LINE='Camping Equipment'), Row(GENDER='F', AGE=49, MARITAL_STATUS='Married', PROFESSION='Retired', PRODUCT_LINE='Outdoor Protection'), Row(GENDER='M', AGE=47, MARITAL_STATUS='Married', PROFESSION='Retired', PRODUCT_LINE='Golf Equipment')]\n"}], "execution_count": 35}, {"source": "<a id=\"viz\"></a>\n## 6. Visualize data\nIt's easy to create charts from pandas DataFrames. You'll use the matplotlib library to create graphs and the NumPy package for computing.\n\nImport the libraries and specify to show graphs inline:", "cell_type": "markdown", "metadata": {}}, {"source": "%matplotlib inline \nimport matplotlib.pyplot as plt\nimport numpy as np", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 36}, {"source": "Convert the Spark DataFrame with outdoor equipment purchase data to a pandas DataFrame: ", "cell_type": "markdown", "metadata": {}}, {"source": "sales_df = spark_df.toPandas()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 37}, {"source": "<a id=\"vizchart\"></a>\n### 6.1 Create a chart using Pandas\n\nTo create a chart, you call the `plot()` method and specify the type of chart, the columns for the X and Y axes, and, optionally, the size of the chart. \n\nFor more information about plotting pandas DataFrames, see <a href=\"http://pandas.pydata.org/pandas-docs/stable/visualization.html\" target=\"_blank\" rel=\"noopener noreferrer\">Visualization</a>.\n\nCreate a bar chart 12\" wide by 5\" high that shows the number of each gender:", "cell_type": "markdown", "metadata": {}}, {"source": "sales_df.head()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GENDER</th>\n      <th>AGE</th>\n      <th>MARITAL_STATUS</th>\n      <th>PROFESSION</th>\n      <th>PRODUCT_LINE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>27</td>\n      <td>Single</td>\n      <td>Professional</td>\n      <td>Personal Accessories</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>39</td>\n      <td>Single</td>\n      <td>Executive</td>\n      <td>Personal Accessories</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>M</td>\n      <td>39</td>\n      <td>Married</td>\n      <td>Student</td>\n      <td>Mountaineering Equipment</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>F</td>\n      <td>56</td>\n      <td>Single</td>\n      <td>Hospitality</td>\n      <td>Personal Accessories</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>M</td>\n      <td>45</td>\n      <td>Married</td>\n      <td>Retired</td>\n      <td>Golf Equipment</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  GENDER  AGE MARITAL_STATUS    PROFESSION              PRODUCT_LINE\n0      M   27         Single  Professional      Personal Accessories\n1      F   39         Single     Executive      Personal Accessories\n2      M   39        Married       Student  Mountaineering Equipment\n3      F   56         Single   Hospitality      Personal Accessories\n4      M   45        Married       Retired            Golf Equipment"}, "execution_count": 38, "metadata": {}}], "execution_count": 38}, {"source": "sales_df_plot = (sales_df[\"GENDER\"]     # Select the \"GENDER\" column.\n                .value_counts()         # Count the number of each gender.\n                .to_frame(\"Count\")      # Since value_counts() returns a Pandas Series, convert it into a Pandas DataFrame. Also, rename the \"GENDER\" column as \"Count\".\n                .rename_axis(\"GENDER\")  # Rename the \"index\" of the DataFrame - M/F - as \"GENDER\".\n                .reset_index())         # Create the \"GENDER\" column.\nsales_df_plot", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GENDER</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>M</td>\n      <td>35748</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>F</td>\n      <td>24504</td>\n    </tr>\n  </tbody>\n</table>\n</div>", "text/plain": "  GENDER  Count\n0      M  35748\n1      F  24504"}, "execution_count": 39, "metadata": {}}], "execution_count": 39}, {"source": "sales_df_plot.plot.bar(x=\"GENDER\", y=\"Count\", rot=0, figsize=(12, 5))  # Set the rot as 0 if you don't want the x ticks be 90 degrees rotated.", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "execute_result", "data": {"text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x7f4961bc86d8>"}, "execution_count": 40, "metadata": {}}, {"output_type": "display_data", "data": {"image/png": "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\n", "text/plain": "<Figure size 864x360 with 1 Axes>"}, "metadata": {"needs_background": "light"}}], "execution_count": 40}, {"source": "<a id=\"vizagg\"></a>\n### 6.2 Aggregate the data\n\nYou can do the equivalent job in the previous subsection in Spark by aggregating the data by `GENDER`. Here are a few of the ways that you can do that:\n\n - Run an SQL query on the GENDER column to output the count of the GENDER, and then run a group by operation on the GENDER.\n - Create a simple Python function to aggregate by GENDER, and then run the function in an SQL query.\n - Run the `map()` method on the Spark Dataframe to append a new column that contains the aggregated count by GENDER. \n - Run the `groupBy()` and `count()` methods on the Spark Dataframe. This is the method you'll use.", "cell_type": "markdown", "metadata": {}}, {"source": "gender_df = spark_df.groupBy(\"GENDER\").count()", "cell_type": "code", "metadata": {}, "outputs": [], "execution_count": 41}, {"source": "Check to verify that you get the expected results:", "cell_type": "markdown", "metadata": {}}, {"source": "gender_df.show()", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "stream", "name": "stdout", "text": "+------+-----+\n|GENDER|count|\n+------+-----+\n|     F|24504|\n|     M|35748|\n+------+-----+\n\n"}], "execution_count": 42}, {"source": "<a id=\"vizchart2\"></a>\n### 6.3 Create a chart using Spark SQL\n\nNow, run an SQL query to group by `GENDER` and order by `GENDER`. Then, create a pandas DataFrame for the results and create a chart of the count of each gender.", "cell_type": "markdown", "metadata": {}}, {"source": "query = \"\"\"\nselect\n    GENDER,\n    count(GENDER) as Count\nfrom gosales_tx\ngroup by GENDER\norder by GENDER desc\n\"\"\"\nspark_gender_df = sqlContext.sql(query).toPandas()\nspark_gender_df.plot.bar(x=\"GENDER\", y=\"Count\", rot=0, figsize=(12, 5));", "cell_type": "code", "metadata": {}, "outputs": [{"output_type": "display_data", "data": {"image/png": "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\n", "text/plain": "<Figure size 864x360 with 1 Axes>"}, "metadata": {"needs_background": "light"}}], "execution_count": 43}, {"source": "Now you have a chart that is equivalent of the one in section [6.1 Create a chart](#vizchart).", "cell_type": "markdown", "metadata": {}}, {"source": "<a id=\"nextsteps\"></a>\n## 7. Summary and next steps\nYou've learned how to create DataFrames, convert between DataFrame types, and convert from RDDs. You know how to run SQL queries and create SQL functions. And you can visualize the data in charts. \n\nGo to the next notebook in this series: <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/5ad1c820f57809ddec9a040e37b4af08\" target=\"_blank\" rel=\"noopener noreferrer\">Introduction to Spark lab, part 3: Machine learning</a>.\n\nDig deeper:\n - <a href=\"http://spark.apache.org/documentation.html\" target=\"_blank\" rel=\"noopener noreferrer\">Apache Spark documentation</a>\n - <a href=\"http://spark.apache.org/docs/latest/api/python/pyspark.html\" target=\"_blank\" rel=\"noopener noreferrer\">PySpark documentation</a>\n - <a href=\"http://pandas.pydata.org/pandas-docs/stable/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">pandas</a>\n - <a href=\"http://matplotlib.org/\" target=\"_blank\" rel=\"noopener noreferrer\">matplotlib</a>\n - <a href=\"http://www.numpy.org/\" target=\"_blank\" rel=\"noopener noreferrer\">NumPy</a>", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "### Authors\nCarlo Appugliese is a Spark and Hadoop evangelist at IBM.<br>\nBraden Callahan is a Big Data Technical Specialist for IBM.<br>\nRoss Lewis is a Big Data Technical Sales Specialist for IBM.<br>\nMokhtar Kandil is a World Wide Big Data Technical Specialist for IBM.\n\n### Data citation\n\nThe World Bank: Projects & Operations ", "cell_type": "markdown", "metadata": {}}, {"source": "<hr>\nCopyright &copy; IBM Corp. 2017-2019. This notebook and its source code are released under the terms of the MIT License.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n</div>", "cell_type": "markdown", "metadata": {}}], "metadata": {"kernelspec": {"display_name": "Python 3.6 with Spark", "name": "python36", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.6.8", "name": "python", "pygments_lexer": "ipython3", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4}
