{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Draw insights from car accident reports\n",
    "This notebook shows you how to analyze car vehicle accidents based on accident reports for New York. The analysis steps in the notebook show how you can use the information about accidents to learn more about the possible causes for collisions. You will learn how to install additional Python packages, how to add external PySpark modules, and how to perform descriptive data analysis.\n",
    "\n",
    "This notebook runs on Python 3 with Spark.\n",
    "\n",
    "## Table of contents\n",
    "- [Get data](#get_data)\n",
    "- [Access data](#access_data)\n",
    "- [Load visualization packages](#load_visualization_packages)\n",
    "- [Explore data](#explore_data)\n",
    "- [Clean and shape the data](#data_cleaning)\n",
    "- [Summary](#summary)\n",
    "\n",
    "<a id=\"get_data\"></a>\n",
    "## Get data\n",
    "\n",
    "Begin by getting the data about car accidents in the New York area. \n",
    "1. Click <a href=\"https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95\" target=\"_blank\" rel=\"noopener noreferrer\">NYPD Motor Vehicle Collisions</a> to access the data set. \n",
    "2. Click **Export** to download the data as a CSV file. \n",
    "\n",
    "This data set covers all reported vehicle collisions in New York starting in July 2012 until today  and contains detailed information about the incidents.\n",
    "\n",
    "After you download the file, load the data file to the notebook: \n",
    "\n",
    "3. Click the **Data** icon on the notebook action bar. \n",
    "4. Select the **Files** tab and browse to select the `NYPD_Motor_Vehicle_Collisions.csv` data file. The file is loaded to the object storage that is associated with your project and is displayed in the **Data Assets** section of the project. For more information, see <a href=\"https://datascience.ibm.com/docs/content/analyze-data/load-and-access-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">Load and access data</a>.\n",
    "\n",
    "**Note**: Because the CSV file is relatively large, it may take a few minutes until the data file is loaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"access_data\"></a>\n",
    "## Load data\n",
    "\n",
    "Before you can access data in the data file in Object Storage, you must set the Hadoop configuration with the Object Storage credentials.\n",
    "\n",
    "**Note**: You will not be using Hadoop in this sample; however Spark leverages some Hadoop components.\n",
    "\n",
    "To add the code to access the data file which is stored in Object Storage and set the Hadoop configuration:\n",
    "1. Click in the next code cell and select **Insert to code > Insert SparkSession DataFrame** under the csv file name. This function inserts the setup code for the preconfigured <a href=\"https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html?highlight=sparksession#pyspark.sql.SparkSession\" target=\"_blank\" rel=\"noopener noreferrer\">SparkSession</a>. Then the data is loaded into a `Spark DataFrame` which is created by using `SparkContext`.\n",
    "\n",
    "2. Change the name of the object from `df_data_1` to `collisions` in the last two lines of the Insert to Code block.\n",
    "3. Run the cell.\n",
    "\n",
    "The credentials for accessing the CSV file are included in the generated code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Records: {}\".format(collisions.count()))\n",
    "collisions.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_visualization_packages\"></a> \n",
    "## Load visualization packages\n",
    "\n",
    "To plot data, this notebook will use the following two packages, which you need to import or install:\n",
    "\n",
    "- <a href=\"http://matplotlib.org/\" target=\"_blank\" rel=\"noopener noreferrer\">Matplotlib</a>, a basic plotting library for Python\n",
    "- <a href=\"http://stanford.edu/~mwaskom/software/seaborn/\" target=\"_blank\" rel=\"noopener noreferrer\">Seaborn</a> a statistical data visualization library\n",
    "\n",
    "The `seaborn` package is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics. You must install the `seaborn` package by using `!pip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.patches allows us create colored patches, we can use for legends in plots\n",
    "import matplotlib.patches as mpatches\n",
    "# seaborn also builds on matplotlib and adds graphical features and new plot types\n",
    "#adjust settings\n",
    "%matplotlib inline\n",
    "sns.set_style(\"white\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_df = collisions\n",
    "collisions_pd = collisions_df[collisions_df['LATITUDE'] != 0][['LATITUDE', 'LONGITUDE', 'CRASH DATE', 'CRASH TIME',\n",
    "                                                               'BOROUGH', 'ON STREET NAME', 'CROSS STREET NAME',\n",
    "                                                               'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED',\n",
    "                                                               'CONTRIBUTING FACTOR VEHICLE 1']].toPandas()\n",
    "\n",
    "collisions_pd.columns = ['Latitude', 'Longitude', 'Crash Date', 'Crash Time', 'Borough', 'On Street',\n",
    "                         'Cross Street', 'Persons Injured', 'Persons Killed', 'Contributing Factor']\n",
    "\n",
    "collisions_pd['Latitude'] = collisions_pd['Latitude'].astype(float)\n",
    "collisions_pd['Longitude'] = collisions_pd['Longitude'].astype(float)\n",
    "collisions_pd['Persons Killed'] = collisions_pd['Persons Killed'].astype(float)\n",
    "collisions_pd['Persons Injured'] = collisions_pd['Persons Injured'].astype(float)\n",
    "\n",
    "\n",
    "\n",
    "#divide dataset in accidents which are: fatal, non-lethal but with person damage, non of the above\n",
    "killed_pd = collisions_pd[collisions_pd['Persons Killed']!=0]\n",
    "injured_pd = collisions_pd[np.logical_and(collisions_pd['Persons Injured']!=0, collisions_pd['Persons Killed']==0)]\n",
    "nothing_pd = collisions_pd[np.logical_and(collisions_pd['Persons Killed']==0, collisions_pd['Persons Injured']==0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an explorative scatter plot of the data\n",
    "\n",
    "Using an explorative scatter plot is a way to analyze certain characteristics of the data set. \n",
    "\n",
    "Create an intial explorative scatter plot of all collisions by using the latitude and longitude information in the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create scatterplots\n",
    "plt.scatter(collisions_pd.Longitude, collisions_pd.Latitude, alpha=0.05, s=4, color='darkseagreen')\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Motor Vehicle Collisions in New York City', size=25)\n",
    "plt.xlim((-74.26,-73.7))\n",
    "plt.ylim((40.5,40.92))\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although this scatter plot is not a street map of New York City, the scatter plot dots roughly correspond to the street map of New York City. You see very few collisions in Central Park or on bridges, as opposed to street crossings and curves, where there is a noticeably higher density of collisions.\n",
    "\n",
    "### Enhance the scatter plot with information about city boroughs\n",
    "\n",
    "Now add information about the city boroughs and use a different color to depict each borough on the scatter plot:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manhattan = collisions_pd[collisions_pd['Borough']=='MANHATTAN']\n",
    "bronx = collisions_pd[collisions_pd['Borough']=='BRONX']\n",
    "brooklyn = collisions_pd[collisions_pd['Borough']=='BROOKLYN']\n",
    "staten = collisions_pd[collisions_pd['Borough']=='STATEN ISLAND']\n",
    "queens = collisions_pd[collisions_pd['Borough']=='QUEENS']\n",
    "\n",
    "\n",
    "#create scatterplots\n",
    "plt.scatter(manhattan.Longitude, manhattan.Latitude, s=1, color='blue', marker ='.')\n",
    "plt.scatter(bronx.Longitude, bronx.Latitude, s=1, color='yellow', marker ='.')\n",
    "plt.scatter(brooklyn.Longitude, brooklyn.Latitude, color='red', s=1, marker ='.')\n",
    "plt.scatter(staten.Longitude, staten.Latitude, s=1, color='green', marker ='.')\n",
    "plt.scatter(queens.Longitude, queens.Latitude, s=1, color='black', marker ='.')\n",
    "\n",
    "#create legend\n",
    "blue_patch = mpatches.Patch(label='Manhattan', color='blue')\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='Bronx')\n",
    "red_patch = mpatches.Patch(color='red', label='Brooklyn')\n",
    "green_patch = mpatches.Patch(color='green', label='Staten Island')\n",
    "black_patch = mpatches.Patch(color='black', label='Queens')\n",
    "plt.legend([blue_patch, yellow_patch, red_patch, green_patch, black_patch],\n",
    "           ('Manhattan', 'Bronx', 'Brooklyn', 'Staten Island', 'Queens'), \n",
    "           loc='upper left', prop={'size':20})\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Motor Vehicle Collisions in New York City by borough', size=20)\n",
    "plt.xlim((-74.26,-73.7))\n",
    "plt.ylim((40.5,40.92))\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust settings\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "#create scatterplots\n",
    "plt.scatter(nothing_pd.Longitude, nothing_pd.Latitude, alpha=0.04, s=1, color='blue')\n",
    "plt.scatter(injured_pd.Longitude, injured_pd.Latitude, alpha=0.1, s=1, color='yellow')\n",
    "plt.scatter(killed_pd.Longitude, killed_pd.Latitude, color='red', s=5)\n",
    "\n",
    "#create legend\n",
    "blue_patch = mpatches.Patch( label='car body damage', alpha=0.2, color='blue')\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='personal injury', alpha=0.5)\n",
    "red_patch = mpatches.Patch(color='red', label='lethal accidents')\n",
    "plt.legend([blue_patch, yellow_patch, red_patch],('car body damage', 'personal injury', 'fatal accidents'), \n",
    "           loc='upper left', prop={'size':20})\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Severity of Motor Vehicle Collisions in New York City', size=20)\n",
    "plt.xlim((-74.26,-73.7))\n",
    "plt.ylim((40.5,40.92))\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "plt.savefig('anothertry.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting scatter plot shows that there are fatal accident hot spots throughout the city. You can see that in some areas car body damage is prevalent, while in other areas personal injuries happen more often.\n",
    "\n",
    "<a id=\"data_cleaning\"></a> \n",
    "## Clean and shape the data\n",
    "\n",
    "After using scatter plots to analyze certain characteristics of the raw data set, you will now learn how to clean and shape the data set to enable more plotting and further analysis. \n",
    "\n",
    "Begin by looking at the column names again to better assess which information you can use:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_header_list = collisions.columns[:-4]\n",
    "collisions_header_list.remove(\"CONTRIBUTING FACTOR VEHICLE 4\")\n",
    "collisions_header_list.remove(\"CONTRIBUTING FACTOR VEHICLE 3\")\n",
    "collisions_header_list.remove(\"CONTRIBUTING FACTOR VEHICLE 5\")\n",
    "collisions_df = collisions_df.dropna(how='any', subset=['ON STREET NAME', 'BOROUGH','LONGITUDE','LATITUDE'])[collisions_header_list]\n",
    "collisions_df.toPandas().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial and temporal normalization by using Spark\n",
    "\n",
    "To obtain a consistent representation of the spatial and temporal information about collisions, you have to normalize the data. Normalization is the process of organizing the columns (attributes) and tables (relations) to minimize data redundancy. This step will help you in future analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_code = {\n",
    "    'avenue':'av',\n",
    "    'ave':'av',\n",
    "    'avnue': 'av',\n",
    "    'street': 'st',\n",
    "    'road': 'rd',\n",
    "    'boulevard': 'blvd',\n",
    "    'place': 'pl',\n",
    "    'plaza': 'pl',\n",
    "    'square': 'sq',\n",
    "    'drive': 'dr',\n",
    "    'lane': 'ln',\n",
    "    'parkway': 'pkwy',\n",
    "    'turnpike': 'tp',\n",
    "    'terrace': 'ter',\n",
    "    '1st': '1',\n",
    "    '2nd':'2',\n",
    "    '3rd': '3',\n",
    "    '1th': '1',\n",
    "    '2th': '2',\n",
    "    '3th': '3',\n",
    "    '4th': '4',\n",
    "    '5th': '5',\n",
    "    '6th': '6',\n",
    "    '7th': '7', \n",
    "    '8th': '8',\n",
    "    '9th': '9',\n",
    "    '0th': '0',\n",
    "    'west ': 'w ',\n",
    "    'north ': 'n ',\n",
    "    'east ': 'e ',\n",
    "    'south ': 's ',\n",
    "}\n",
    "def normalize_street(s):\n",
    "    # Lowercase\n",
    "    s = s.lower()\n",
    "\n",
    "    # Delete all non-alphanumeric characters\n",
    "    s = \"\".join(filter(str.isalnum, s))\n",
    "\n",
    "    # Replace common abbreviations\n",
    "    for k in sorted(normalization_code.keys()):\n",
    "        s = s.replace(k, normalization_code[k])\n",
    "\n",
    "    # Only keep ascii chars\n",
    "    s = s.encode('ascii', errors='ignore').decode()\n",
    "\n",
    "    return s\n",
    "\n",
    "def row_parser(row):\n",
    "    from datetime import datetime\n",
    "    \n",
    "    \"\"\"\n",
    "    Spatial and Temporal Normalization\n",
    "    Returns the location, borough, year, month, day, hour; removes nonalphanumeric characters\n",
    "    \"\"\"\n",
    "    # create a row dictionary\n",
    "    row_dict = row.asDict()\n",
    "    \n",
    "    # temporal\n",
    "    ## date\n",
    "    temp = row_dict['CRASH DATE']\n",
    "    hr = row_dict['CRASH TIME'].split(\":\")[0]\n",
    "    try:\n",
    "        a = datetime.strptime(temp+\" \"+hr, '%m/%d/%Y %H')\n",
    "        dates =  [a]\n",
    "    except:\n",
    "        a = datetime.now()\n",
    "        dates = [a]\n",
    "    \n",
    "    # location and borough\n",
    "    location = normalize_street(row_dict['ON STREET NAME'])\n",
    "    borough = row_dict['BOROUGH'].lower()\n",
    "    \n",
    "    \n",
    "    # other cols\n",
    "    others = [row_dict[column] for column in collisions_header_list\n",
    "             if column not in [\"ON STREET NAME\", \"OFF STREET NAME\", \"CROSS STREET NAME\", \"BOROUGH\", \"CRASH DATE\", \"CRASH TIME\"]]\n",
    "\n",
    "       \n",
    "\n",
    "    # return everything together\n",
    "    return dates + [location] + [borough] + others\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "collisions_out_row = Row(*([\"Time\", \"Street\", \"Borough\"] + [c for c in collisions_header_list\n",
    "                      if c not in [\"ON STREET NAME\", \"OFF STREET NAME\", \"CROSS STREET NAME\", \"BOROUGH\", \"CRASH DATE\", \"CRASH TIME\"]]))\n",
    "collisions_out_index = list(collisions_out_row)\n",
    "\n",
    "collisions_out = collisions_df.rdd.map(\n",
    "    lambda row: collisions_out_row(*(row_parser(row)))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_out.toPandas().info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating data attributes\n",
    "\n",
    "You can draw information from your data by examining the attributes in the data set and finding out how useful they are. \n",
    "\n",
    "Begin by plotting the contributing factors of an accident:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "collisions_out_df = collisions_out\n",
    "\n",
    "factor = collisions_out_df.groupBy('CONTRIBUTING FACTOR VEHICLE 1').count().sort(desc('count')).toPandas()\n",
    "factor = factor[0:20].sort_index(ascending=False)\n",
    "factor.plot(kind='barh', legend=False, color='blue', figsize=(14,10))\n",
    "plt.title('Composition of: ' + 'CONTRIBUTING FACTOR VEHICLE 1', size=20)\n",
    "plt.xlabel('Count')\n",
    "plt.yticks(range(len(factor))[::-1], factor['CONTRIBUTING FACTOR VEHICLE 1'][::-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code cell above shows you that the contributing factor can't be specified in most cases. However, factors like distraction, failure to yield right-of-way, and fatigue could have an influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting accidents by vehicle type\n",
    "The data set has entries for a large number of car types. To avoid inconclusive results because the  number of car types is too large, regroup the car types into main categories like auto, bus, truck, taxi or other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "groups = [\"Auto\", \"Taxi\", \"Bus\", \"Truck\", \"Other\"]\n",
    "groupings = {\n",
    "    '18 w':'Truck',\n",
    "    'acura':'Auto',\n",
    "    'buick':'Auto',\n",
    "    'cadi':'Auto',\n",
    "    'box': 'Truck',\n",
    "    'benz':'Auto',\n",
    "    'car': 'Auto',\n",
    "    'cab': 'Taxi',\n",
    "    'chev':'Auto',\n",
    "    'convertible':'Auto',\n",
    "    'dump': 'Truck',\n",
    "    'dodge':'Auto',\n",
    "    'fire':'Truck',\n",
    "    'ford':'Auto',\n",
    "    'garba': 'Truck',\n",
    "    'gmc':'Auto',\n",
    "    'honda':'Auto',\n",
    "    'hyund':'Auto',\n",
    "    'infinit':'Auto',\n",
    "    'jeep':'Auto',\n",
    "    'kia':'Auto',\n",
    "    'limo':'Auto',\n",
    "    'lincoln':'Auto',\n",
    "    'livery vehicle':'Taxi',\n",
    "    'miniv':'Auto',\n",
    "    'mercedes':'Auto',\n",
    "    'nissan':'Auto',\n",
    "    'passenger vehicle':'Auto',\n",
    "    'ram':'Auto',\n",
    "    'sedan': 'Auto', \n",
    "    'schoo' : 'Bus',\n",
    "    'sprinter v':'Auto',\n",
    "    'subn':'Auto',\n",
    "    'subur':'Auto',\n",
    "    'suv':'Auto',\n",
    "    'sport':'Auto',\n",
    "    'slingshot':'Auto',\n",
    "    'tesla':'Auto',\n",
    "    'trk':'Truck',\n",
    "    'tk':'Truck',\n",
    "    'tow':'Truck',\n",
    "    'toyo':'Auto',\n",
    "    'u hau':'Truck',\n",
    "    'u-hau':'Truck',\n",
    "    'uhaul':'Truck',\n",
    "    '4d':'Auto',\n",
    "    '3-door': 'Auto',\n",
    "    '5x8 t':'Truck',\n",
    "    'van': 'Auto',\n",
    "    'vav':'Auto',\n",
    "    'wagon':'Auto',\n",
    "    'yello':'Taxi',\n",
    "}\n",
    "\n",
    "def groupVehicle(s):\n",
    "    if s is None: return 'Other'\n",
    "    \n",
    "    if s.isnumeric(): return 'Other'\n",
    "\n",
    "    slowStr = s.lower()\n",
    "    # does the vehicle contain any of the known categories\n",
    "    for aGroup in groups:\n",
    "        if aGroup.lower() in slowStr:\n",
    "            return aGroup\n",
    "        \n",
    "    # lookup the full vehicle type\n",
    "    if slowStr in groupings:\n",
    "        return groupings[slowStr]\n",
    "\n",
    "    # does any of the know mappings is part of the vehicle desc\n",
    "    for aGroup in groupings:\n",
    "        if aGroup.lower() in slowStr:\n",
    "            return groupings[aGroup]\n",
    "\n",
    "    return 'Other'\n",
    "\n",
    "\n",
    "collisions_out_categories = collisions_out.rdd.map(lambda row:\n",
    "                   collisions_out_row(*[groupVehicle(row[i]) if collisions_out_index[i].startswith(\"VEHICLE TYPE CODE\")\n",
    "                                                    else row[i] for i in range(len(row))])\n",
    "                  ).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_transformed_row = Row(*([\"Time\", \"Street\", \"Borough\", \"Injured\",\n",
    "                                                \"Killed\", \"Auto\", \"Bus\",\n",
    "                                                \"Truck\", \"Taxi\", \"Other\", ]))\n",
    "\n",
    "def transform_involved(row):\n",
    "    counts = Counter([row[i] for i in range(len(row)) if collisions_out_index[i].startswith(\"VEHICLE TYPE CODE\")])\n",
    "    return collisions_transformed_row(*([row.asDict()[c] for c in [\"Time\", \"Street\", \"Borough\",\n",
    "                                                                      \"NUMBER OF PERSONS INJURED\",\n",
    "                                                                      \"NUMBER OF PERSONS KILLED\"]] + \n",
    "                                       [counts[x] if x in counts else 0\n",
    "                                           for x in ['Auto', 'Bus', 'Truck', 'Taxi', 'Other']]))\n",
    "\n",
    "collisions_transformed = collisions_out_categories.rdd.map(transform_involved).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_transformed_boolean_row = Row(*([\"Time\", \"Street\", \"Borough\",\n",
    "                                                        \"AccidentsWithInjuries\",\n",
    "                                                        \"AccidentswithDeaths\", \"Auto\", \"Bus\",\n",
    "                                                        \"Truck\", \"Taxi\", \"Other\",\n",
    "                                                        \"Injured\", \"Killed\"]))\n",
    "\n",
    "collisions_transformed_boolean = collisions_transformed.rdd.map(\n",
    "    lambda row: collisions_transformed_boolean_row(*([int(int(row.asDict()[c] if row.asDict()[c] is not None and row.asDict()[c].isdigit() else 0) > 0) if c in [\"Injured\",\"Killed\"] else row.asDict()[c] for c in list(collisions_transformed_row)]\n",
    "        + [row.Injured, row.Killed])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_transformed_boolean.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation_columns = {x:\"sum\" for x in [\"AccidentsWithInjuries\", \"AccidentswithDeaths\",\n",
    "                                    \"Auto\", \"Bus\", \"Truck\", \"Taxi\", \"Other\", \"Injured\", \"Killed\"]}\n",
    "aggregation_columns.update({\"*\":\"count\"})\n",
    "\n",
    "collisions_grouped = collisions_transformed_boolean.toDF().groupBy(\n",
    "    \"Time\", \"Street\", \"Borough\").agg(aggregation_columns)\n",
    "\n",
    "# rename columns names\n",
    "for c in collisions_grouped.columns:\n",
    "    if c.startswith(\"sum\") or c.startswith(\"SUM\"):\n",
    "        collisions_grouped = collisions_grouped.withColumnRenamed(c, c[4:-1])\n",
    "    elif c.startswith(\"count\") or c.startswith(\"COUNT\"):\n",
    "        collisions_grouped = collisions_grouped.withColumnRenamed(c, \"NumberOfAccidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_grouped.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_final_row = Row(*([\"Year\", \"Month\", \"Day\", \"Hour\"] + collisions_grouped.columns[1:]))\n",
    "collisions_final = collisions_grouped.rdd.map(lambda row: collisions_final_row(*([row.Time.year, row.Time.month,\n",
    "                                                                              row.Time.day, row.Time.hour] +\n",
    "                                                                             [row.asDict()[x]\n",
    "                                                                              for x in collisions_final_row[4:]]))).toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_final.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the streets with the most collisions\n",
    "\n",
    "Find the top ten streets in New York where the most vehicle collisions occurred. Display the results in a bar graph and as a scatter plot (ignore any deprecation warnings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "collisions_final_df = collisions_final\n",
    "plottingdf = collisions_final_df.groupBy(\"Borough\", \"Street\").agg(F.sum(\"NumberOfAccidents\").alias(\"sum(NumberOfAccidents)\")).\\\n",
    "sort(F.desc('sum(NumberOfAccidents)')).limit(10).toPandas()\n",
    "plottingdf[['sum(NumberOfAccidents)']].plot(kind='barh', figsize=(11,7), legend=False)\n",
    "plt.title('Top 10 Streets with the most accidents', size=20)\n",
    "plt.xlabel('Count')\n",
    "plt.yticks(range(10), plottingdf['Street'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can add the information about the top 10 streets into the scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = collisions_out_df[['Borough', 'Street', 'LATITUDE', 'LONGITUDE']].toPandas()\n",
    "data1[\"LATITUDE\"] = pd.to_numeric(data1[\"LATITUDE\"], downcast=\"float\")\n",
    "data1[\"LONGITUDE\"] = pd.to_numeric(data1[\"LONGITUDE\"], downcast=\"float\")\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "collisions1 = data1[np.logical_and(data1['Street']=='atlanticav', data1['Borough']=='brooklyn')]\n",
    "collisions2 = data1[np.logical_and(data1['Street']=='northernblvd', data1['Borough']=='queens')]\n",
    "collisions3 = data1[np.logical_and(data1['Street']=='brdway', data1['Borough']=='manhattan')]\n",
    "collisions4 = data1[np.logical_and(data1['Street']=='flatbushav', data1['Borough']=='brooklyn')]\n",
    "collisions5 = data1[np.logical_and(data1['Street']=='queensblvd', data1['Borough']=='queens')]\n",
    "collisions6 = data1[np.logical_and(data1['Street']=='2av', data1['Borough']=='manhattan')]\n",
    "collisions7 = data1[np.logical_and(data1['Street']=='lindenblvd', data1['Borough']=='brooklyn')]\n",
    "collisions8 = data1[np.logical_and(data1['Street']=='3av', data1['Borough']=='manhattan')]\n",
    "collisions9 = data1[np.logical_and(data1['Street']=='hylanblvd', data1['Borough']=='staten island')]\n",
    "collisions10 = data1[np.logical_and(data1['Street']=='1av', data1['Borough']=='manhattan')]\n",
    "\n",
    "#create scatterplots\n",
    "plt.scatter(data1.LONGITUDE, data1.LATITUDE, s=1, color='darkseagreen')\n",
    "plt.scatter(collisions1.LONGITUDE, collisions1.LATITUDE, color='red', s=2)\n",
    "plt.scatter(collisions2.LONGITUDE, collisions2.LATITUDE, color='blue', s=2)\n",
    "plt.scatter(collisions3.LONGITUDE, collisions3.LATITUDE, s=2, color='magenta')\n",
    "plt.scatter(collisions4.LONGITUDE, collisions4.LATITUDE, color='orange', s=2)\n",
    "plt.scatter(collisions5.LONGITUDE, collisions5.LATITUDE, s=2, color='yellow')\n",
    "plt.scatter(collisions6.LONGITUDE, collisions6.LATITUDE, color='purple', s=2)\n",
    "plt.scatter(collisions7.LONGITUDE, collisions7.LATITUDE, s=2, color='black')\n",
    "plt.scatter(collisions8.LONGITUDE, collisions8.LATITUDE, color='chartreuse', s=2)\n",
    "plt.scatter(collisions9.LONGITUDE, collisions9.LATITUDE, s=2, color='brown')\n",
    "plt.scatter(collisions10.LONGITUDE, collisions10.LATITUDE, color='darkgreen', s=2)\n",
    "\n",
    "\n",
    "#create legend\n",
    "a_patch = mpatches.Patch(color='red', label='Atlantic Avenue')\n",
    "b_patch = mpatches.Patch(color='blue', label='Northern Boulevard')\n",
    "c_patch = mpatches.Patch(color='magenta', label='Broadway')\n",
    "d_patch = mpatches.Patch(color='orange', label='Flatbush Avenue')\n",
    "e_patch = mpatches.Patch(color='yellow', label='Queens Boulevard')\n",
    "f_patch = mpatches.Patch(color='purple', label='2nd Avenue')\n",
    "g_patch = mpatches.Patch(color='black', label='Linden Boulevard')\n",
    "h_patch = mpatches.Patch(color='chartreuse', label='3rd Avenue')\n",
    "i_patch = mpatches.Patch(color='brown', label='Hylan Boulevard')\n",
    "j_patch = mpatches.Patch(color='darkgreen', label='1st Avenue')\n",
    "\n",
    "plt.legend([a_patch, b_patch, c_patch, d_patch, e_patch, f_patch, g_patch, h_patch, i_patch, j_patch],\n",
    "           ('Atlantic Avenue', 'Northern Boulevard', 'Broadway', 'Flatbush Avenue', 'Queens Boulevard', '2nd Avenue',\n",
    "            'Linden Boulevard', '3rd Avenue', 'Hylan Boulevard', '1st Avenue'), \n",
    "           loc='upper left', prop={'size':20})\n",
    "\n",
    "#adjust more settings\n",
    "plt.title('Vehicle Collisions in New York City', size=25)\n",
    "plt.xlim(-74.26,-73.7)\n",
    "plt.ylim(40.5 , 40.92)\n",
    "plt.xlabel('Longitude',size=20)\n",
    "plt.ylabel('Latitude',size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining when the most collisions occurred\n",
    "\n",
    "Now find out at what time of the day the most accidents occurred and see if you can detect any interesting patterns by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "hourplot = collisions_final_df[['Bus','Truck','Taxi','Other','Hour','Auto']].groupBy('Hour')\\\n",
    ".agg(F.sum(\"Bus\").alias(\"Bus\"), F.sum(\"Truck\").alias(\"Truck\"), F.sum(\"Taxi\").alias(\"Taxi\"),\\\n",
    "F.sum(\"Other\").alias(\"Other\"),F.sum(\"Auto\").alias(\"Auto\")).toPandas()\n",
    "\n",
    "hourplot[['Bus', 'Truck', 'Taxi', 'Auto']].plot(stacked=True, kind='bar',figsize=(12,8), alpha=1)\n",
    "#'SUM(Other)',\n",
    "plt.xlabel('Hour', size=17)\n",
    "plt.ylabel('Vehicles', size=17)\n",
    "plt.legend(loc='best', prop={'size':20}, framealpha=0) \n",
    "plt.title('Collisions on Road per Hour', size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows collisions spread across a day, with peaks during the morning and afternoon rush hours. You can see that significantly more collisions occurred during the afternoon rush hour than during the morning rush hour. Also, the most collisions involve cars by far, while buses, taxis, and trucks are involved in accidents a lot less frequently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## Summary\n",
    "\n",
    "This notebook showed you how to analyze car vehicle accidents based on accident reports for New York and how you can use this information to learn more about the causes for collisions. If you extract  this type of information from the data, you can use it to help develop measures for preventing  vehicle accidents in accident hotspots.\n",
    "\n",
    "Copyright Â© IBM Corp. 2016, 2020. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 with Spark",
   "language": "python3",
   "name": "python39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
