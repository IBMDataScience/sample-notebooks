{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance Optimization \n",
    "\n",
    "This notebook illustrates how to combine predictive and decision optimization techniques.\n",
    "\n",
    "While predictive models can be trained to accurately predict the failure distribution for assets, in practice this does not enable you to plan the predictive maintenance of these assets, especially if there are some operational constraints to consider, such as the availability of parts or limited maintenance crew size.\n",
    "\n",
    "The combination of machine learning and decision optimization is essential in helping you solve this problem.\n",
    "\n",
    "A complete description of the problem can be found in the article <a href=\"https://towardsdatascience.com/predictive-maintenance-scheduling-with-ibm-data-science-experience-and-decision-optimization-25bc5f1b1b99\" target=\"_blank\" rel=\"noopener noreferrer\">Predictive Maintenance Scheduling with IBM Watson Studio Local and Decision Optimization</a>.\n",
    "\n",
    "In this notebooks, you can use sample data to:\n",
    "\n",
    "1. load, transform and clean historical data\n",
    "1. train a predictive model to predict failure\n",
    "1. load new data and apply the predictive model\n",
    "1. use model predictions as input for an optimization model, along with a description of the business constraints and objective in order to find an optimal maintenance plan\n",
    "1. display the final optimal maintenance plan using brunel visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This notebook requires the Commercial Edition of CPLEX engines. This notebook runs on Python and DO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import some of the packages you need to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "!pip install altair\n",
    "import altair as alt\n",
    "\n",
    "def __iter__(self): return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Data\n",
    "\n",
    "Load historical data, remove irrelevant data, and merge it to be used for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the machine data frame from historical data.\n",
    "\n",
    "Machines have different characteristics such as:\n",
    "* capacity (how much they can produce per period),\n",
    "* remaining life is the number of period before recommended maintenance according to venfor,\n",
    "* cost and loss for maintenance and repair (in general the impact of repairing after failure is higher than the impact of maintaining before failure),\n",
    "* etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historical_machine = pd.read_csv('https://raw.githubusercontent.com/achabrier/data/master/historical-machine.csv')\n",
    "df_historical_machine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the predictive algorithm training you only need a subset of these columns, so first do some cleaning.\n",
    "\n",
    "The column 'life' represents the number of days before failure, according to the vendor's specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historical_machine = df_historical_machine[['id', 'remaining life']];\n",
    "df_historical_machine.columns = ['id', 'life']\n",
    "df_historical_machine = df_historical_machine.set_index(['id'])\n",
    "df_historical_machine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the production for these machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historical_production = pd.read_csv('https://raw.githubusercontent.com/achabrier/data/master/historical-production.csv')\n",
    "df_historical_production.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a chart representing the historical production for machine M-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production_m01 = df_historical_production[df_historical_production.machine == 'M-01']\n",
    "\n",
    "alt.Chart(df_production_m01).mark_trail().encode(\n",
    "    x='day',\n",
    "    y='production:T',\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the data so that it can be used in training the predictive model.\n",
    "\n",
    "Production will also be used as input for the predictive model as the level of production is certainly having an impact on possible failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historical_production.columns = ['id', 'day', 'production']\n",
    "df_historical_production = df_historical_production.pivot(index='id', columns='day', values='production')\n",
    "df_historical_production['total'] = df_historical_production.values[:, 1:].sum(1)\n",
    "df_historical_production.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next load the historical failure data for these machines.\n",
    "\n",
    "The column 'mid' represents the number of days before failure, according to historical records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historical_mid = pd.read_csv('https://raw.githubusercontent.com/achabrier/data/master/historical-mid.csv')\n",
    "df_historical_mid.columns = ['id', 'mid']\n",
    "df_historical_mid = df_historical_mid.set_index(['id'])\n",
    "df_historical_mid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge all data required for model training into one data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all\n",
    "\n",
    "df_historical = df_historical_machine.join(df_historical_production).join(df_historical_mid)\n",
    "df_historical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the remaining life given by the vendor with the historical failure, you can see that there is indeed a significant difference which would be valuable to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(1,5):\n",
    "    id = \"M-0\" + str(m);\n",
    "    print (id)\n",
    "    print (\"Remaining life for \", id, \": \" , df_historical.life[id])\n",
    "    print (\"Historical failure for \", id, \": \" , df_historical.mid[id])\n",
    "    \n",
    "df_historical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a chart that represents the deviation between the remaining life prediction from the vendor and the real failure, due to production trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "brush = alt.selection(type='interval')\n",
    "alt.Chart(df_historical).mark_point(filled=True).encode(\n",
    "    x='life:O',\n",
    "    y='mid:Q'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failure prediction model training\n",
    "\n",
    "You now can train a simple linear regression model to predict the failure using vendor's remaining life indication and the planned production for the machine as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X_train = df_historical.iloc[: , :-1]\n",
    "y_train = df_historical.iloc[: , -1]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply trained predictive model on new operational data\n",
    "\n",
    "Now load new machines, with known characteristics, including the remaining life prediction from the vendor, and predict their failure using the linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the machine table and perform some transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_machine = pd.read_csv('https://raw.githubusercontent.com/achabrier/data/master/machine.csv')\n",
    "df_machine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only useful columns\n",
    "df_machine_x = df_machine[['id', 'remaining life']];\n",
    "df_machine_x.columns = ['id', 'life']\n",
    "df_machine_x = df_machine_x.set_index(['id'])\n",
    "df_machine_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the planned production and perform a simple transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planned_production = pd.read_csv('https://raw.githubusercontent.com/achabrier/data/master/planned_production.csv')\n",
    "df_planned_production.columns = ['id', 'day', 'production']\n",
    "df_planned_production.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_planned_production_x = df_planned_production.pivot(index='id', columns='day', values='production')\n",
    "df_planned_production_x['total'] = df_planned_production_x.values[:, 1:].sum(1)\n",
    "df_planned_production_x.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge both data frames to get the structure that can be used with a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_machine_x.join(df_planned_production_x)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the 'mid' column corresponding to most probable failure day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['mid'] = y_pred\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brush = alt.selection(type='interval')\n",
    "alt.Chart(X_test).mark_point(filled=True).encode(\n",
    "    x='life:O',\n",
    "    y='mid:Q'\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare predictions for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = pd.read_csv('https://raw.githubusercontent.com/achabrier/data/master/day.csv')\n",
    "df_day.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the 'mid' most probable failure day into a failure probability distribution over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "n_days = df_day['id'].count()\n",
    "\n",
    "data_failure = []\n",
    "for machine in df_machine['id']:\n",
    "    life = int(df_machine[df_machine.id==machine]['remaining life'])\n",
    "    capacity = int(df_machine[df_machine.id==machine]['capacity'])\n",
    "    base = random.randint(int(0.7*capacity), capacity)    \n",
    "    x = [life]\n",
    "    \n",
    "    mid = int(X_test.mid[machine])\n",
    "\n",
    "    #print (str(x) + \" --> \" + str(mid))\n",
    "    \n",
    "    spread = random.randint(2, 6)\n",
    "    #print spread\n",
    "    n = 1000\n",
    "    #s = np.random.poisson(mid, n)\n",
    "    s = np.random.normal(mid, spread/4., n)\n",
    "\n",
    "    #print s\n",
    "    data = [0 for i in range(n_days)]\n",
    "    for i, day in np.ndenumerate(df_day['id']):\n",
    "        t = 0\n",
    "        for j in range(1000):\n",
    "            if int(s[j])==i[0]:\n",
    "                t = t+1                    \n",
    "        data_failure.append((machine, day, int (100.*t/n)))       \n",
    "        \n",
    "df_predicted_failure = pd.DataFrame(data=data_failure, columns=['machine', 'day', 'failure'])\n",
    "df_predicted_failure.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And display, for example, the predicted failure for each period for machine  M-01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_failure_m01 = df_predicted_failure[df_predicted_failure.machine == 'M-01']\n",
    "\n",
    "alt.Chart(df_failure_m01).mark_trail().encode(\n",
    "    x='day',\n",
    "    y='failure',\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform some transformation, for example creating a structure with the cumulative probability to fail before some given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_failure.reset_index(inplace=True)\n",
    "df_predicted_failure = df_predicted_failure.set_index(['machine', 'day'])\n",
    "\n",
    "df_planned_production.rename(columns={'id':'machine'}, inplace=True)\n",
    "df_planned_production.reset_index(inplace=True)\n",
    "df_planned_production = df_planned_production.set_index(['machine', 'day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first global collections to iterate upon\n",
    "all_machines = df_machine['id'].values\n",
    "all_days = df_day['id'].values\n",
    "\n",
    "data_cumul_failure = []\n",
    "for machine in all_machines:\n",
    "    for i, d in np.ndenumerate(all_days):\n",
    "        cumul = 0\n",
    "        for i2, d2 in np.ndenumerate(all_days):\n",
    "            if i2==i:\n",
    "                break\n",
    "            cumul += int(df_predicted_failure.failure[machine, d2])\n",
    "        data_cumul_failure.append((machine, d, cumul))\n",
    "\n",
    "df_cumul_failure = pd.DataFrame(data_cumul_failure, columns=['machine', 'day', 'cumul_failure'])\n",
    "df_cumul_failure=df_cumul_failure.set_index(['machine', 'day'])\n",
    "df_cumul_failure.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display this cumulative failure for the same M-01 machine.\n",
    "\n",
    "Taken individually, the machine M-01 must certainly be maintained shortly before Day-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cumul = df_cumul_failure.reset_index()\n",
    "df_cumul_m01 = df_cumul[df_cumul.machine == 'M-01']\n",
    "\n",
    "alt.Chart(df_cumul_m01).mark_trail().encode(\n",
    "    x='day',\n",
    "    y='cumul_failure',\n",
    ").properties(\n",
    "    width=800,\n",
    "    height=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization of maintenance\n",
    "\n",
    "Now you will create an optimization model to create the optimal maintenance plan, taking into account some constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last input data frame you need are the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parameters = pd.read_csv('https://raw.githubusercontent.com/achabrier/data/master/parameters.csv')\n",
    "df_parameters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the **docplex** Python package to formulate the optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.environment import Environment\n",
    "env = Environment()\n",
    "env.print_information()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docplex.mp.model import Model\n",
    "mdl = Model(name=\"PredictiveMaintenance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create decision variables:\n",
    "* (real) production (taking into account maintenance or failures) per machine and day\n",
    "* maintenance per machine and day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production = mdl.continuous_var_matrix(keys1=all_machines, keys2=all_days, name=lambda ns: \"Production_%s_%s\" % (ns[0],ns[1]))\n",
    "df_production = pd.DataFrame({'production': production})\n",
    "df_production.index.names=['all_machines', 'all_days']\n",
    "\n",
    "maintenance = mdl.binary_var_matrix(keys1=all_machines, keys2=all_days, name=lambda ns: \"Maintenance_%s_%s\" % (ns[0],ns[1]))\n",
    "df_maintenance = pd.DataFrame({'maintenance': maintenance})\n",
    "df_maintenance.index.names=['all_machines', 'all_days']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add some constraints linking real production with planned production and maintenance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for machine in all_machines:       \n",
    "    maintenance_loss = int(df_machine[df_machine.id==machine]['maintenance loss'])/100.\n",
    "    capacity = int(df_machine[df_machine.id==machine]['capacity'])\n",
    "    for day in all_days:   \n",
    "        prod = df_planned_production.production[machine, day]\n",
    "        #mdl.add_if_then( maintenance[machine, day] == 1, production[machine, day]== 0 )\n",
    "        #mdl.add_if_then( maintenance[machine, day] == 0, production[machine, day]== df_production[df_production.machine==machine][df_production.day==day] )\n",
    "        if (prod <= capacity*(1-maintenance_loss)):\n",
    "            mdl.add_constraint( production[machine, day] == prod )\n",
    "        else:\n",
    "            mdl.add_constraint( production[machine, day] == prod - (prod-capacity*(1-maintenance_loss))*maintenance[machine, day])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other constraints:\n",
    "* Perform exactly one maintenance per machine\n",
    "* The number of maintenance jobs possible on the same day is limited by the crew size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One maintenance per machine\n",
    "for machine in all_machines:       \n",
    "    mdl.add_constraint( mdl.sum(maintenance[machine, day] for day in all_days) == 1)\n",
    "    \n",
    "maintenance_crew_size = int(df_parameters[df_parameters.id=='maintenance crew size']['value'])\n",
    "\n",
    "# One maintenance at a time\n",
    "for day in all_days:       \n",
    "    mdl.add_constraint( mdl.sum(maintenance[machine, day] for machine in all_machines) <= maintenance_crew_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some cost structures to be used for objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cost_maintenance = []\n",
    "cost_kpis = []\n",
    "# Cost of repair\n",
    "for machine in all_machines:           \n",
    "    #print machine\n",
    "    life = int(df_machine[df_machine.id==machine]['remaining life'])\n",
    "    capacity = int(df_machine[df_machine.id==machine]['capacity'])\n",
    "    cost_of_maintenance = int(df_machine[df_machine.id==machine]['cost of maintenance'])\n",
    "    maintenance_loss = int(df_machine[df_machine.id==machine]['maintenance loss'])/100.\n",
    "    cost_of_repair = int(df_machine[df_machine.id==machine]['cost of repair'])\n",
    "    repair_loss = int(df_machine[df_machine.id==machine]['repair loss'])/100.\n",
    "    loss_per_life_day = int(df_machine[df_machine.id==machine]['loss per life day'])\n",
    "    production_value_unit = int(df_machine[df_machine.id==machine]['production value unit'])\n",
    "    \n",
    "    previous_day = None\n",
    "    for i, day in np.ndenumerate(all_days):\n",
    "        cost = 0;\n",
    "        prob_break_before = 0\n",
    "        if (previous_day != None):\n",
    "            prob_break_before = int(df_cumul_failure.cumul_failure[machine, previous_day])/100.\n",
    "        previous_day = day\n",
    "        \n",
    "        #print prob_break_before\n",
    "        \n",
    "        # Cost of lost production if failure before maintenance\n",
    "        for i2, day2 in np.ndenumerate(all_days):\n",
    "            if (i2==i):\n",
    "                break\n",
    "            prob_break_day2 = int(df_predicted_failure.failure[machine, day2])/100.\n",
    "            production_day2 = int(df_planned_production.production[machine, day2])\n",
    "            if (production_day2 > capacity*(1-repair_loss)):\n",
    "                cost += production_value_unit*prob_break_day2*(production_day2 - capacity*(1-repair_loss))\n",
    "            \n",
    "        # Cost of repair if breaking before maintenance\n",
    "        cost += cost_of_repair*prob_break_before\n",
    "        \n",
    "        # Cost of maintenance\n",
    "        cost += cost_of_maintenance*(1-prob_break_before)\n",
    "        \n",
    "        # Cost of lost production for maintenance\n",
    "        production_day = int(df_planned_production.production[machine, day])\n",
    "        if (production_day > capacity*(1-maintenance_loss)):\n",
    "            cost += production_value_unit*(production_day - capacity*(1-maintenance_loss))\n",
    "        \n",
    "        # Cost of maintenance too early\n",
    "        cost += loss_per_life_day*max(life-i[0], 0)\n",
    "        \n",
    "        #print cost\n",
    "        data_cost_maintenance.append((machine, day, cost))\n",
    "        \n",
    "        cost_kpis.append(cost*maintenance[machine, day])\n",
    "        \n",
    "cost_kpi = mdl.sum(cost_kpis)\n",
    "mdl.add_kpi(cost_kpi, \"Cost\")\n",
    "\n",
    "df_cost_maintenance = pd.DataFrame(data_cost_maintenance, columns=['machine', 'day', 'cost_maintenance'])\n",
    "#print df_cost_maintenance\n",
    "\n",
    "total_planned_production = mdl.sum(df_planned_production.production)\n",
    "mdl.add_kpi(total_planned_production, \"Total Planned Production\")\n",
    "total_production = mdl.sum(df_production.production)\n",
    "mdl.add_kpi(total_production, \"Total Production\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective is depending of the strategy.\n",
    "* with strategy 1, the expected cost is directly minimized\n",
    "* with strategy 2, emulating some human decision-making, the maintenance are simply pushed near to the peak of failure probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = int(df_parameters[df_parameters.id=='strategy']['value'])\n",
    "\n",
    "if (strategy == 1):\n",
    "    mdl.minimize(cost_kpi)\n",
    "else:\n",
    "    early = 10\n",
    "    late = 1000\n",
    "    temp = []     \n",
    "    for machine in all_machines:           \n",
    "        \n",
    "        last_day = None\n",
    "        for i, day in np.ndenumerate(all_days):\n",
    "            last_day = day;\n",
    "            cumul_failure = int(df_cumul_failure.cumul_failure[machine, day])\n",
    "            if (cumul_failure > 0):                            \n",
    "                temp.append(late * maintenance[machine, day] )\n",
    "            else:\n",
    "                temp.append(early * i[0] * maintenance[machine, day] )\n",
    "        \n",
    "    late_kpi = mdl.sum(temp)\n",
    "    mdl.minimize(late_kpi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information on the model.\n",
    "\n",
    "Even with this small didactic data set, the number of variables is higher than 1000 and hence the Commercial Edition of CPLEX needs to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.print_information()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now can solve the model.\n",
    "\n",
    "The engine log shows how fast the model is solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = mdl.solve(log_output=True)\n",
    "assert s, \"solve failed\"\n",
    "mdl.report()\n",
    "\n",
    "all_kpis = [(kp.name, kp.compute()) for kp in mdl.iter_kpis()]\n",
    "df_kpis = pd.DataFrame(all_kpis, columns=['kpi', 'value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now access the solution value and create useful pandas data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_production = df_production.production.apply(lambda v: v.solution_value)\n",
    "df_production.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maintenance = df_maintenance.maintenance.apply(lambda v: int(v.solution_value))\n",
    "df_maintenance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_production = df_production.to_frame()\n",
    "df_production['machine'] = df_production.index.get_level_values('all_machines') \n",
    "df_production['day'] = df_production.index.get_level_values('all_days') \n",
    "df_production.columns = ['production', 'machine', 'day'] \n",
    "df_production = df_production.reset_index(drop=True)\n",
    "\n",
    "df_maintenance = df_maintenance.to_frame()\n",
    "df_maintenance['machine'] = df_maintenance.index.get_level_values('all_machines') \n",
    "df_maintenance['day'] = df_maintenance.index.get_level_values('all_days') \n",
    "df_maintenance.columns = ['maintenance', 'machine', 'day'] \n",
    "df_maintenance = df_maintenance.reset_index(drop=True)\n",
    "\n",
    "df_maintenance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the maintenance plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_maintenance).mark_rect().encode(\n",
    "    x='day:O',\n",
    "    y='machine:O',\n",
    "    color='maintenance:Q'\n",
    ").properties(\n",
    "    width=1200,\n",
    "    height=500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "* <a href=\"https://rawgit.com/IBMDecisionOptimization/docplex-doc/master/docs/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">CPLEX Modeling for Python documentation</a>\n",
    "* <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/welcome-main.html\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Studio documentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authors\n",
    "\n",
    "**Alain Chabrier**  IBM, France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright Â© 2017-2021. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
