{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style='border: none' align='left'>\n",
    "   <tr style='border: none'>\n",
    "      <th style='border: none'><font size='5' face='verdana' color='black'><b>Deploy a custom model to the Watson Machine Learning repository using scikit-learn</b></th>\n",
    "      <th style='border: none'><img src='https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true' alt='Watson Machine Learning icon' height='40' width='40'></th>\n",
    "   </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to deploy a custom model that uses a non-supported framework to the `Watson Machine Learning (WML)` using a `scikit-learn estimator`. For supported model types (frameworks), refer to this <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\" target=\"_blank\" rel=\"noopener no referrer\">link</a>.\n",
    "\n",
    "You will deploy the model from the <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/1835c567cd309d54fc797900f79a60f9\" target=\"_blank\" rel=\"noopener no referrer\">Use statsmodels to forecast the Consumer Price Index (time series)</a> notebook to the `Watson Machine Learning (WML)` repository. The notebook is in the `Watson Studio` community.\n",
    "\n",
    "You will learn how to write a `scikit-learn custom estimator`, then deploy it to the `Watson Machine Learning` repository.\n",
    "\n",
    "The data set, <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/304ff4a1704b967dd29693a4d32ba626\" target=\"_blank\" rel=\"noopener no referrer\">Consumer Prices</a>, which is originally sourced from the <a href=\"http://www.ilo.org/stat/\" target=\"_blank\" rel=\"noopener no referrer\">International Labour Organization</a> measures the Consumer Price Index of different countries over a period of time. The **Consumer Price Index (CPI)** is defined as a measure of the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. Forecasting this value is useful because it's a valuable economic indicator used to predict the rate of inflation. It also affects decision making pertaining to income payments.\n",
    "\n",
    "This notebook uses Python 3.6, the `statsmodels`, and the `watson-machine-learning-client` packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals\n",
    "- Load data as a dataframe\n",
    "    - Create a time series object\n",
    "- Explore data\n",
    "    - Check the stationarity of the time series\n",
    "        - Seasonal decomposition\n",
    "        - Dicky-Fuller test\n",
    "- Prepare data - stationarizing the series\n",
    "- Optimize the ARIMA parameters and create the model\n",
    "    - ACF and PACF plots to identify parameters\n",
    "    - Use grid search for ARIMA\n",
    "- Train the model\n",
    "- Deploy the model\n",
    "- Score the deployed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Load data](#load)\n",
    "2. [Explore data](#explore)\n",
    "3. [Prepare data](#prepare)\n",
    "4. [Model selection](#modelselection)\n",
    "5. [Deploy the model](#deploy)\n",
    "6. [Score the model](#score)\n",
    "7. [Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 1. Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will load the time series data as a dataframe and modify it so that the index is a datetime variable.\n",
    "\n",
    "The data set contains records of the Consumer Price Indices (CPI) of various countries over time, from 1969 to 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, install the `numpy` and `scipy` packages required for interacting with data and modeling. The `wget` package will be used to download the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install packages.\n",
    "!pip install --upgrade numpy\n",
    "!pip install --upgrade scipy==1.2.1\n",
    "!pip install --upgrade wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the [Consumer Prices](https://dataplatform.cloud.ibm.com/exchange/public/entry/view/304ff4a1704b967dd29693a4d32ba626) from the [Gallery](https://dataplatform.cloud.ibm.com/community?context=analytics) using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data set.\n",
    "import wget\n",
    "import os\n",
    "\n",
    "price_data = 'Consumer prices.csv' \n",
    "\n",
    "if not os.path.isfile(price_data):\n",
    "    link_to_data = 'https://api.dataplatform.cloud.ibm.com/v2/gallery-assets/entries/304ff4a1704b967dd29693a4d32ba626/data?accessKey=d1bec8d606656afaa378d73205c1e649'\n",
    "    price_data = wget.download(link_to_data)\n",
    "\n",
    "print(price_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data as a dataframe\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "dateparse = lambda dates: datetime.datetime.strptime(dates, '%Y')\n",
    "consumer_prices = pd.read_csv(price_data, parse_dates=['Year'], index_col = 'Year', date_parser=dateparse, engine='python')\n",
    "consumer_prices.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the data set is loaded as a dataframe, the *Year* column is converted into a datetime type variable. Each date is unique, which allows the *Year* column to be made the index of the data set so that the dataframe can be used as a time series object.\n",
    "\n",
    "Now, when you list the dataframe information, you can see the DatatimeIndex and the rest of the columns in the data set. The *Value* column represents the value of the country's Consumer Price Index that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_prices.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Distribution of columns.\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    for col in consumer_prices:\n",
    "        print(col, len(consumer_prices[col].value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary data visualization packages and plot the time series object to observe the several plotted values by country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import register_matplotlib_converters\n",
    "import matplotlib.pyplot as plt\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the data by country.\n",
    "plt.figure(figsize=(15, 40))\n",
    "for country in (consumer_prices['Country or Area'].unique()[-30:-1]):    \n",
    "    plt.plot(consumer_prices.loc[(consumer_prices['Country or Area'] == country)].index.to_pydatetime(), consumer_prices['Value'].loc[consumer_prices['Country or Area'] == country], label=country)\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Consumer Price Index')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, filter the data to obtain the CPI values for the United States. You can then observe the pattern of the values changing over time (1969-2008) in the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPI values in the United States.\n",
    "us_consumer_prices = consumer_prices[['Value']].loc[consumer_prices['Country or Area'] == 'United States']\n",
    "us_consumer_prices = us_consumer_prices.sort_index()\n",
    "us_consumer_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series data.\n",
    "import matplotlib.dates as mdates\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Consumer Price Index')\n",
    "plt.plot(us_consumer_prices.index.to_pydatetime(), us_consumer_prices['Value']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explore\"></a>\n",
    "## 2. Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will explore the data to learn more about the stationarity of the series and determine the steps to take for data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Checking stationarity of time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the stationarity of the time series, since many models assume that the series is stationary. A time series is stationary when the mean, variance, and covariance of the data are constant and not dependent on time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seasonal Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the `statsmodels` package to plot and model the time series data.\n",
    "\n",
    "Decompose the time series to observe the trend and seasonality in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decomposition of the time series data.\n",
    "import numpy\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] =15, 10\n",
    "decomposition = sm.tsa.seasonal_decompose(us_consumer_prices['Value'], model = 'additive')\n",
    "fig = decomposition.plot()\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the trend is changing based on time, so you can infer that the series is not stationary. You can also use another method, called the Dicky-Fuller test, to confirm this observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dicky-Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dicky-Fuller test.\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "dftest = adfuller(us_consumer_prices['Value'], autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','Number of Lags Used','Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the Dicky-Fuller test to check the stationarity of the time series data.\n",
    "\n",
    "The null hypothesis $H_{o}$ assumes that the time series is dependent on time (that it is non-stationary). Since the `Test Statistic` is larger than the `Critical Values`, we cannot reject the null hypothesis and understand that the series is **non-stationary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare\"></a>\n",
    "## 3. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ACF & PACF plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common tool used to forecast time series data is the `ARIMA` (**A**uto **R**egressive **I**ntegrated **M**oving **A**verage) model. The model has 3 parameters \n",
    "- `p` - the parameter associated with the Auto-Regressive part of the ARIMA model. You can use the **PACF (partial autocorrelation function)** plot to find the optimal value.\n",
    "- `d` - the parameter associated with the Integration part of the ARIMA model. This is the **order of difference**, or the number of times the time series is differenced in order to stationarize the series.\n",
    "- `q` - the parameter associated with the Moving Average part of the ARIMA model. You can use the **ACF (autocorrelation function)** plot to find the optimal value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the ACF and PACF plots of the original time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the ACF and PACF plots.\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,6))\n",
    "plot_acf(us_consumer_prices['Value'], ax = ax1)\n",
    "plot_pacf(us_consumer_prices['Value'], ax = ax2, method='ywmle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the series is not stationary, you will first use differencing before finding the parameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Stationarizing the time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Differencing** is used to remove the non-stationarity caused by the trend. The number of differences needed to remove stationarity determines the parameter `d`, for the Integration component of the ARIMA model. Run the following code to difference the data twice and plot the resulting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differencing - remove non-stationarity.\n",
    "plt.figure(figsize=(20, 10))\n",
    "us_consumer_prices_dif = (((us_consumer_prices.diff()).dropna()).diff()).dropna()\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Consumer Price Index (differenced)')\n",
    "plt.plot(us_consumer_prices_dif['Value']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time series data has been differenced twice to remove stationarity. You can observe the trend of the modified data using the seasonal decomposition method once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Decomposition of stationarized time series.\n",
    "rcParams['figure.figsize'] =15, 10\n",
    "decomposition = sm.tsa.seasonal_decompose(us_consumer_prices_dif['Value'], model = 'additive')\n",
    "fig = decomposition.plot()\n",
    "plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot, you can see that there is no observable trend or seasonality in the differenced time series data. Once again, you can use the Augmented Dicky-Fuller test to confirm that the stationarity of the data as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmented Dicky-Fuller test.\n",
    "dftest = adfuller(us_consumer_prices_dif['Value'], autolag='AIC')\n",
    "dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', 'Number of Lags Used', 'Number of Observations Used'])\n",
    "for key,value in dftest[4].items():\n",
    "    dfoutput['Critical Value (%s)'%key] = value\n",
    "print(dfoutput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `Test Statistic` here is less than the `Critical Values`, we can reject the null hypothesis and we can assume that the series is stationary. As you can see from the decomposition plot and the Dicky-Fuller test, the stationarity has been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"modelselection\"></a>\n",
    "## 4. Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can run the code below to plot the ACF and PACF plots of the modified stationary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the ACF and PACF plots of the stationarized series.\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 6))\n",
    "plot_acf(us_consumer_prices_dif['Value'], ax = ax1)\n",
    "plot_pacf(us_consumer_prices_dif['Value'], ax = ax2, method='ywmle')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the optimal values for the ARIMA parameters, you can perform grid search using the package below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the pmdarima package.\n",
    "!pip install --upgrade pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import auto-arima - grid search for ARIMA.\n",
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code to compare the various combinations of the ARIMA parameters, as well as the seasonal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search for the ARIMA model.\n",
    "stepwise_model = auto_arima(us_consumer_prices[:'2000'], start_p=0, start_q=0, max_p=5, max_q=5, seasonal=False, d=2, D=0, \n",
    "                            trace=True, suppress_warnings=True, error_action='ignore', stepwise=True)\n",
    "print(stepwise_model.aic())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter set with the lowest `AIC` value (criteria that measures the model) is a good choice to fit the model. As you can see, the lowest `AIC` value is about 353.6, so the optimal parameters are `order = (0, 2, 1)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Install the custom scikit-learn estimator <a id=\"custom\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please refer to this <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-custom_libs_scikit_learn.html?audience=wdp&linkInPage=true\" target=\"_blank\" rel=\"noopener no referrer\">link</a> regarding packaging a custom `scikit-learn custom transformer`. The same method can also be applied to packaging a custom `scikit-learn custom estimator`.\n",
    "\n",
    "The `scikit-learn custom estimator` that wraps the `statsmodels` model looks like the following and is included in `sklearn_arima-0.1.zip` file that will be downloaded in this subsection."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "class SklearnArima(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, X, order=(0, 2, 1), steps=8, alpha=0.05):\n",
    "        self.X = X\n",
    "        self.order = order\n",
    "        self.steps = steps\n",
    "        self.alpha = alpha\n",
    "        self.fitted_model = None\n",
    "        self.forecast = None\n",
    "        self.stderr = None\n",
    "        self.conf_int = None\n",
    "        self.X.index = pd.DatetimeIndex(\n",
    "            self.X.index.values,\n",
    "            freq=self.X.index.inferred_freq\n",
    "        )\n",
    "        \n",
    "        self.model = ARIMA(self.X, self.order)\n",
    "        \n",
    "    def fit(self, X=None, y=None):\n",
    "        self.fitted_model = self.model.fit()\n",
    "        return self.fitted_model\n",
    "        \n",
    "    def predict(self, steps=1, alpha=.05):\n",
    "        try:\n",
    "            if self.fitted_model is not None:\n",
    "                self.forecast, self.stderr, self.conf_int = self.fitted_model.forecast(\n",
    "                    steps=self.steps, alpha=self.alpha\n",
    "                )\n",
    "            else:        \n",
    "                raise TypeError \n",
    "        except TypeError:\n",
    "            print('Please train the model before calling the predict method.')\n",
    "\n",
    "        return self.forecast, self.stderr, self.conf_int\n",
    "    \n",
    "    def resid(self):\n",
    "        try:\n",
    "            if self.fitted_model is not None:\n",
    "                return self.fitted_model.resid\n",
    "            else:        \n",
    "                raise TypeError \n",
    "        except TypeError:\n",
    "            print('Please train the model before calling the resid method.')\n",
    "        \n",
    "    def score(self, X=None, y=None):\n",
    "        if X.shape != self.forecast.shape:\n",
    "            X = X.values.reshape(-1, 1) if type(X) is pd.core.frame.DataFrame else X.reshape(-1, 1)\n",
    "            self.forecast = self.forecast.reshape(-1, 1)\n",
    "            \n",
    "            try:\n",
    "                if X.shape[0] == self.forecast.shape[0]:\n",
    "                    return numpy.mean(X - self.forecast)\n",
    "                else:\n",
    "                    raise ValueError\n",
    "            except ValueError:\n",
    "                print('The dimensions of the test data and predicted data are not the same.')\n",
    "        \n",
    "    def summary(self):\n",
    "        try:\n",
    "            if self.fitted_model is not None:\n",
    "                return self.fitted_model.summary()\n",
    "            else:        \n",
    "                raise TypeError \n",
    "        except TypeError:\n",
    "            print('Please train the model before calling the summary method.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the packaged `custom estimator` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sklearn_arima-0.1.zip'\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    filename = wget.download('https://github.com/IBMDataScience/sample-notebooks/raw/master/Files/sklearn_arima-0.1.zip')\n",
    "    \n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the downloaded `custom estimator` package that is compressed in `.zip` format using the `pip install` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn_arima-0.1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Build the model <a id=\"build\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required modules. The `SklearnArima` module is the `custom estimator` you installed locally in section [4.2 Install the custom scikit-learn estimator](#custom).\n",
    "\n",
    "A `scikit-learn` pipeline consists of `transformer(s)` and a final `estimator`. You can check the details of the `scikit-learn` pipeline <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline\" target=\"_blank\" rel=\"noopener no referrer\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn_arima.arima import SklearnArima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        ('arima', SklearnArima(us_consumer_prices[:'2000'], order=(0, 2, 1)))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(us_consumer_prices[:'2000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the model.\n",
    "\n",
    "- The first array is the out of sample forecasts.\n",
    "- The second array is the standard error of the forecasts.\n",
    "- The third array is a 2D array of the confidence interval for the forecast.\n",
    "\n",
    "Refer to this <a href=\"https://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMAResults.forecast.html#statsmodels.tsa.arima_model.ARIMAResults.forecast\" target=\"_blank\" rel=\"noopener no referrer\">link</a> on the return values of the `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(us_consumer_prices[:'2000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Deploy the custom scikit-learn estimator <a id=\"custom_deploy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the `WatsonMachineLearningAPIClient` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need your `Watson Machine Learning (WML)` credentials to instantiate a `WatsonMachineLearningAPIClient` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "    'url': 'https://ibm-watson-ml.mybluemix.net',\n",
    "    'username': '***',\n",
    "    'password': '***',\n",
    "    'instance_id': '***'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the downloaded `custom package` in the Watson Machine Learning repository.\n",
    "\n",
    "**Notes:**\n",
    "- For client.runtimes.LibraryMetaNames.NAME, specify the value passed in the name parameter of the setup() function in the setup.py file.\n",
    "- For client.runtimes.LibraryMetaNames.FILEPATH, specify the .zip file name of your custom package.\n",
    "- The identifier of the stored package, `custom_package_uid`, is required for the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_estimator_meta = {\n",
    "    client.runtimes.LibraryMetaNames.NAME: 'sklearn_arima',\n",
    "    client.runtimes.LibraryMetaNames.DESCRIPTION: 'ARIMA model for sklearn pipeline',\n",
    "    client.runtimes.LibraryMetaNames.FILEPATH: 'sklearn_arima-0.1.zip',\n",
    "    client.runtimes.LibraryMetaNames.VERSION: '0.1',\n",
    "    client.runtimes.LibraryMetaNames.PLATFORM: {'name': 'python', 'versions': ['3.6']}\n",
    "}\n",
    "custom_estimator_details = client.runtimes.store_library(custom_estimator_meta)\n",
    "custom_estimator_uid = client.runtimes.get_library_uid(custom_estimator_details)\n",
    "print('Custom Estimator UID: {}'.format(custom_estimator_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the details of the `custom package` metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "custom_estimator_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a `runtime resource` object that references your stored custom package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes_meta = {\n",
    "    client.runtimes.ConfigurationMetaNames.NAME: 'sklearn_arima_model', \n",
    "    client.runtimes.ConfigurationMetaNames.DESCRIPTION: 'scikit-learn ARIMA model', \n",
    "    client.runtimes.ConfigurationMetaNames.PLATFORM: {'name': 'python', 'version': '3.6'}, \n",
    "    client.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [custom_estimator_uid]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the `runtime resource` object in the Watson Machine Learning (WML) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_details = client.runtimes.store(runtimes_meta)\n",
    "runtime_details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need the identifier of the runtime resource object, `custom_runtime_uid`, for the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_url = client.runtimes.get_url(runtime_details)\n",
    "runtime_uid = client.runtimes.get_uid(runtime_details)\n",
    "print('Runtimes URL: {}'.format(runtime_url))\n",
    "print('Runtimes UID: {}'.format(runtime_uid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store your trained model in the Watson Machine Learning (WML) repository referencing your stored runtime resource in meta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {\n",
    "    client.repository.ModelMetaNames.NAME: 'Custom ARIMA estimator for sklearn pipeline',\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: runtime_uid\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model = client.repository.store_model(model=pipeline, meta_props=model_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the details of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_model_uid = client.repository.get_model_uid(published_model)\n",
    "model_details = client.repository.get_details(published_model_uid)\n",
    "print(json.dumps(model_details, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Forecasting <a id=\"forecast\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that you've built the model, you can use it to predict the Consumer Price Index for years 2001-08 and compare the predictions with the observed numbers. Run the code below to plot the observed values alongside the predicted values with a 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = us_consumer_prices['1969':'2008'].plot(label='Observed')\n",
    "forecast, stderr, conf_int = pipeline.predict(us_consumer_prices[:'2000'])\n",
    "forecast = pd.DataFrame(forecast).set_index(us_consumer_prices['2001':].index)\n",
    "forecast.plot(ax=ax, style = 'r', label='Forecast')\n",
    "\n",
    "# Calculate and visualize the 95% confidence interval.\n",
    "ax.fill_between(us_consumer_prices['2001':].index, conf_int[:,0], conf_int[:,1], color='dimgray', alpha=0.1)\n",
    "\n",
    "# Add the labels to the plot.\n",
    "plt.legend(('Observed', 'Forecast'))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Consumer Price Index');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above, you can observe how the predicted values (in red) measure up to the observed values (in blue) during the years 2001-08. As you can see, the time series model built in this notebook does a good job of predicting the Consumer Price Index in the United States close to the observed numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Deploy the model <a id=\"deploy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model to the Watson Machine Learning repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_arima_deployment = client.deployments.create(published_model_uid, name='sklearn_pipeline_arima')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Score the model <a id=\"score\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the url of the `scoring endpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_url(sklearn_arima_deployment)\n",
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The payload that is passed to the `scoring endpoint` is the same as the one used for testing the trained model in section [4.3 Build the model](#build)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_consumer_prices[:'2000'].values.reshape(1, -1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_payload = {\n",
    "    'values': us_consumer_prices[:'2000'].values.reshape(1, -1).tolist()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the prediction results of the deployed model through the `scoring endpoint`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = client.deployments.score(scoring_endpoint, scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['values']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the same graph in section [4.4 Forecasting](#forecast) to see if the scored results are the same as the one predicted locally.\n",
    "\n",
    "Prepare data to plot the forecast results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = numpy.array(predictions['values'][0][0])\n",
    "conf_int = numpy.array(predictions['values'][2][0])\n",
    "print(forecast)\n",
    "print(conf_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = us_consumer_prices['1969':'2008'].plot(label='Observed')\n",
    "forecast = pd.DataFrame(forecast).set_index(us_consumer_prices['2001':].index)\n",
    "forecast.plot(ax=ax, style = 'r', label='Forecast')\n",
    "\n",
    "# Calculate and visualize the 95% confidence interval.\n",
    "ax.fill_between(us_consumer_prices['2001':].index, conf_int[:,0], conf_int[:,1], color='dimgray', alpha=0.1)\n",
    "\n",
    "# Add the labels to the plot.\n",
    "plt.legend(('Observed', 'Forecast'))\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Consumer Price Index');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated graph and the one in section [4.4 Forecasting](#forecast) are the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 7. Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully completed this notebook and learned how to create a Time Series model. You can now analyze a time series data to check its stationarity, stationarize the series if necessary, and find the optimal parameters for the ARIMA model. You've learned how to use this model to forecast data with a confidence interval.\n",
    "\n",
    "You also learned how to deploy a non-supported model using a `custom scikit-learn estimator`.\n",
    "\n",
    "\n",
    "Check out our <a href=\"https://dataplatform.ibm.com/docs/content/analyze-data/wml-setup.html\" target=\"_blank\" rel=\"noopener no referrer\">Online Documentation</a> for more samples, tutorials, documentation, how-tos, and blog posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data citations\n",
    "\n",
    "UNData: Consumer prices, general indices (2000=100). (2010). Retrieved from [http://data.un.org/](http://data.un.org/Data.aspx?d=LABORSTA&f=tableCode%3a7A).\n",
    "\n",
    "Consumer Price Index: U.S. Bureau Of Labor Statistics. Retrieved from https://www.bls.gov/cpi/.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "**Ananya Kaushik** is a Data Scientist at IBM.  \n",
    "**Jihyoung Kim**, Ph.D., is a Data Scientist at IBM who strives to make data science easy for everyone through Watson Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright Â© 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style='background:#F5F7FA; height:110px; padding: 2em; font-size:14px;'>\n",
    "<span style='font-size:18px;color:#152935;'>Love this notebook? </span>\n",
    "<span style='font-size:15px;color:#152935;float:right;margin-right:40px;'>Don't have an account yet?</span><br>\n",
    "<span style='color:#5A6872;'>Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style='border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;'><a href='https://ibm.co/wsnotebooks' target='_blank' style='color: #3d70b2;text-decoration: none;'>Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
