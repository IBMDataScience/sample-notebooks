{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a Decision Optimization model with Watson Machine Learning\n",
    "\n",
    "This notebook shows you how to deploy a Decision Optimization model, create and monitor jobs, and get solutions using the Watson Machine Learning Python Client.\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Install the Watson Machine Learning client API](#setup)\n",
    "2. [Create a client instance](#create)\n",
    "3. [Prepare your model archive](#prepare)\n",
    "4. [Upload your model on Watson Machine Learning](#upload)\n",
    "5. [Create a deployment](#deploy)\n",
    "6. [Create and monitor a job with inline data for your deployed model](#job)\n",
    "7. [Display the solution](#display)\n",
    "8. [Solve another problem using the same deployment](#problem)\n",
    "9. [Summary](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the Watson Machine Learning client\n",
    "\n",
    "Before you use the sample code in this notebook, you need to:\n",
    "\n",
    "- create a <a href=\"https://cloud.ibm.com/catalog/services/machine-learning\" target=\"_blank\" rel=\"noopener noreferrer\">Watson Machine Learning (WML) Service</a> instance. A free plan is offered and information about how to create the instance can be found at <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-setup.html\" target=\"_blank\" rel=\"noopener noreferrer\"> https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/wml-setup.html.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and then import the Watson Machine Learning client library. This notebook uses the preview Python client based on v4 of Watson Machine Learning APIs. \n",
    "\n",
    "**Important** Do not load both Python client libraries into a notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uninstall the Watson Machine Learning client Python client based on v3 APIs\n",
    "\n",
    "!pip uninstall watson-machine-learning-client -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install WML client API\n",
    "\n",
    "!pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance\n",
    "\n",
    "Use your Watson Machine Learning credentials. You can find infos on how to get your API key and instance's URL <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp\">here</a> in the second step of the \"Before you begin\" section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "# You may want to change the URL depending on the instance you are using.\n",
    "\n",
    "api_key = 'PASTE YOUR PLATFORM API KEY HERE'\n",
    "location = 'PASTE YOUR INSTANCE LOCATION HERE'\n",
    "\n",
    "wml_credentials = {\n",
    "      \"apikey\": api_key,\n",
    "      \"url\": 'https://' + location + '.ml.cloud.ibm.com'\n",
    "}\n",
    "\n",
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Put the model.py file in a subdirectory and create a tar.gz file. The model consists of two parts:\n",
    "* some functions to create an `inputs` dictionary from files and create files from an `outputs` dictionary,\n",
    "* the real optimization model which uses the inputs and outputs dictionaries.\n",
    "\n",
    "Use the `write_file` command to write these models to a `main.py` file. \n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile model/main.py\n",
    "\n",
    "from docplex.util.environment import get_environment\n",
    "from os.path import splitext\n",
    "import pandas\n",
    "from six import iteritems\n",
    "\n",
    "def get_all_inputs():\n",
    "    '''Utility method to read a list of files and return a tuple with all\n",
    "    read data frames.\n",
    "    Returns:\n",
    "        a map { datasetname: data frame }\n",
    "    '''\n",
    "    result = {}\n",
    "    env = get_environment()\n",
    "    for iname in [f for f in os.listdir('.') if splitext(f)[1] == '.csv']:\n",
    "        with env.get_input_stream(iname) as in_stream:\n",
    "            df = pandas.read_csv(in_stream)\n",
    "            datasetname, _ = splitext(iname)\n",
    "            result[datasetname] = df\n",
    "    return result\n",
    "\n",
    "def write_all_outputs(outputs):\n",
    "    '''Write all dataframes in ``outputs`` as .csv.\n",
    "\n",
    "    Args:\n",
    "        outputs: The map of outputs 'outputname' -> 'output df'\n",
    "    '''\n",
    "    for (name, df) in iteritems(outputs):\n",
    "        csv_file = '%s.csv' % name\n",
    "        print(csv_file)\n",
    "        with get_environment().get_output_stream(csv_file) as fp:\n",
    "            if sys.version_info[0] < 3:\n",
    "                fp.write(df.to_csv(index=False, encoding='utf8'))\n",
    "            else:\n",
    "                fp.write(df.to_csv(index=False).encode(encoding='utf8'))\n",
    "    if len(outputs) == 0:\n",
    "        print(\"Warning: no outputs written\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile -a model/main.py\n",
    "\n",
    "# Load CSV files into inputs dictionnary\n",
    "inputs = get_all_inputs()\n",
    "\n",
    "food = inputs['diet_food']\n",
    "nutrients = inputs['diet_nutrients']\n",
    "food_nutrients = inputs['diet_food_nutrients']\n",
    "food_nutrients.set_index('Food', inplace=True)\n",
    "        \n",
    "from docplex.mp.model import Model\n",
    "\n",
    "# Model\n",
    "mdl = Model(name='diet')\n",
    "\n",
    "# Create decision variables, limited to be >= Food.qmin and <= Food.qmax\n",
    "qty = food[['name', 'qmin', 'qmax']].copy()\n",
    "qty['var'] = qty.apply(lambda x: mdl.continuous_var(lb=x['qmin'],\n",
    "                                                ub=x['qmax'],\n",
    "                                                name=x['name']),\n",
    "                   axis=1)\n",
    "# make the name the index\n",
    "qty.set_index('name', inplace=True)\n",
    "\n",
    "# Limit range of nutrients, and mark them as KPIs\n",
    "for n in nutrients.itertuples():\n",
    "    amount = mdl.sum(qty.loc[f.name]['var'] * food_nutrients.loc[f.name][n.name]\n",
    "                     for f in food.itertuples())\n",
    "    mdl.add_range(n.qmin, amount, n.qmax)\n",
    "    mdl.add_kpi(amount, publish_name='Total %s' % n.name)\n",
    "\n",
    "# Minimize cost\n",
    "obj = mdl.sum(qty.loc[f.name]['var'] * f.unit_cost for f in food.itertuples())\n",
    "mdl.add_kpi(obj, publish_name=\"Minimal cost\");\n",
    "mdl.minimize(obj)\n",
    "\n",
    "mdl.print_information()\n",
    "\n",
    "# solve\n",
    "ok = mdl.solve()\n",
    "\n",
    "mdl.print_solution()\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "solution_df = pandas.DataFrame(columns=['Food', 'value'])\n",
    "\n",
    "for index, dvar in enumerate(mdl.solution.iter_variables()):\n",
    "    solution_df.loc[index,'Food'] = dvar.to_string()\n",
    "    solution_df.loc[index,'value'] = dvar.solution_value\n",
    "    \n",
    "outputs = {}\n",
    "outputs['solution'] = solution_df\n",
    "        \n",
    "# Generate output files\n",
    "write_all_outputs(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"model/main.py\", arcname=\"main.py\", filter=reset)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on Watson Machine Learning\n",
    "\n",
    "Store model in Watson Machine Learning with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All available meta data properties \n",
    "\n",
    "client.repository.ModelMetaNames.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information about the CRNs can be found <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp\">here</a> in the third and fourth step of the \"Before you begin\" section.\n",
    "\n",
    "Use the following code to list deployment spaces and delete unneeded ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.spaces.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.spaces.delete(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.spaces.get_details(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set.default_space('PASTE YOUR SPACE ID HERE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"Diet\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Diet\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-docplex_20.1\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: client.software_specifications.get_uid_by_name(\"do_20.1\")\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/wsuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "\n",
    "model_uid = client.repository.get_model_id(model_details)\n",
    "\n",
    "# print model uid if needed\n",
    "# print( model_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"Diet Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Diet Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_uid(deployment_details)\n",
    "\n",
    "# print deployment id if needed\n",
    "# print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library \n",
    "import pandas as pd \n",
    "  \n",
    "# initialize list of lists \n",
    "diet_food = pd.DataFrame([ [\"Roasted Chicken\", 0.84, 0, 10],\n",
    "                [\"Spaghetti W/ Sauce\", 0.78, 0, 10],\n",
    "                [\"Tomato,Red,Ripe,Raw\", 0.27, 0, 10],\n",
    "                [\"Apple,Raw,W/Skin\", 0.24, 0, 10],\n",
    "                [\"Grapes\", 0.32, 0, 10],\n",
    "                [\"Chocolate Chip Cookies\", 0.03, 0, 10],\n",
    "                [\"Lowfat Milk\", 0.23, 0, 10],\n",
    "                [\"Raisin Brn\", 0.34, 0, 10],\n",
    "                [\"Hotdog\", 0.31, 0, 10]] , columns = [\"name\",\"unit_cost\",\"qmin\",\"qmax\"])\n",
    "\n",
    "diet_food_nutrients = pd.DataFrame([\n",
    "                [\"Spaghetti W/ Sauce\", 358.2, 80.2, 2.3, 3055.2, 11.6, 58.3, 8.2],\n",
    "                [\"Roasted Chicken\", 277.4, 21.9, 1.8, 77.4, 0, 0, 42.2],\n",
    "                [\"Tomato,Red,Ripe,Raw\", 25.8, 6.2, 0.6, 766.3, 1.4, 5.7, 1],\n",
    "                [\"Apple,Raw,W/Skin\", 81.4, 9.7, 0.2, 73.1, 3.7, 21, 0.3],\n",
    "                [\"Grapes\", 15.1, 3.4, 0.1, 24, 0.2, 4.1, 0.2],\n",
    "                [\"Chocolate Chip Cookies\", 78.1, 6.2, 0.4, 101.8, 0, 9.3, 0.9],\n",
    "                [\"Lowfat Milk\", 121.2, 296.7, 0.1, 500.2, 0, 11.7, 8.1],\n",
    "                [\"Raisin Brn\", 115.1, 12.9, 16.8, 1250.2, 4, 27.9, 4],\n",
    "                [\"Hotdog\", 242.1, 23.5, 2.3, 0, 0, 18, 10.4 ]\n",
    "            ] , columns = [\"Food\",\"Calories\",\"Calcium\",\"Iron\",\"Vit_A\",\"Dietary_Fiber\",\"Carbohydrates\",\"Protein\"])\n",
    "\n",
    "diet_nutrients = pd.DataFrame([\n",
    "                [\"Calories\", 2000, 2500],\n",
    "                [\"Calcium\", 800, 1600],\n",
    "                [\"Iron\", 10, 30],\n",
    "                [\"Vit_A\", 5000, 50000],\n",
    "                [\"Dietary_Fiber\", 25, 100],\n",
    "                [\"Carbohydrates\", 0, 300],\n",
    "                [\"Protein\", 50, 100]\n",
    "            ], columns = [\"name\",\"qmin\",\"qmax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\"diet_food.csv\",\n",
    "            \"values\" : diet_food\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_food_nutrients.csv\",\n",
    "            \"values\" : diet_food_nutrients\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_nutrients.csv\",\n",
    "            \"values\" : diet_nutrients\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.csv\"\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)\n",
    "\n",
    "# print job id if needed\n",
    "# print( job_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print( job_details['entity']['decision_optimization']['status']['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='display'></a>\n",
    "### Extract and display solution\n",
    "\n",
    "Display the output solution.\n",
    "\n",
    "Display the KPI Total Calories value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe for the solution\n",
    "solution = pd.DataFrame(job_details['entity']['decision_optimization']['output_data'][0]['values'], \n",
    "                        columns = job_details['entity']['decision_optimization']['output_data'][0]['fields'])\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='problem'></a>\n",
    "###  Solve another problem using the same deployment\n",
    "\n",
    "Create a new payload with modified input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the input data\n",
    "diet_nutrients.at[0,'qmin'] = 1500\n",
    "diet_nutrients.at[0,'qmax'] = 2000\n",
    "\n",
    "solve_payload = {\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\"diet_food.csv\",\n",
    "            \"values\" : diet_food         \n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_food_nutrients.csv\",\n",
    "             \"values\" : diet_food_nutrients            \n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_nutrients.csv\",\n",
    "            \"values\" : diet_nutrients\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "    {\n",
    "        \"id\":\".*\\.csv\"\n",
    "    }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_uid(job_details)\n",
    "\n",
    "# print job id if needed\n",
    "# print( job_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print( job_details['entity']['decision_optimization']['status']['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the KPI Total Calories value for this modified data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.deployments.get_job_details(job_uid)['entity']['decision_optimization']['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the Watson Machine Learning client\n",
    "- prepare your model archive and upload your model on Watson Machine Learning\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "- display the solution\n",
    "\n",
    "Check out our online documentation at <a href=\"https://dataplatform.cloud.ibm.com/docs\" target=\"_blank\" rel=\"noopener noreferrer\">https://dataplatform.cloud.ibm.com/docs</a> for more samples, tutorials and documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright Â© 2019, 2021. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:110px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Love this notebook? </span>\n",
    "<span style=\"font-size:15px;color:#152935;float:right;margin-right:40px;\">Don't have an account yet?</span><br>\n",
    "<span style=\"color:#5A6872;\">Share it with your colleagues and help them discover the power of Watson Studio!</span>\n",
    "<span style=\"border: 1px solid #3d70b2;padding:8px;float:right;margin-right:40px; color:#3d70b2;\"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
