{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a Decision Optimization model with watsonx.ai Runtime\n",
    "\n",
    "This notebook shows you how to deploy a Decision Optimization model, create and monitor jobs, and get solutions using the watsonx.ai Python Client.\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents:**\n",
    "\n",
    "- [Set up the watsonx.ai client](#Set-up-the-watsonx.ai-client)\n",
    "- [Create a client instance](#Create-a-client-instance)\n",
    "- [Prepare your model archive](#Prepare-your-model-archive)\n",
    "- [Upload your model on watsonx.ai Runtime](#Upload-your-model-on-watsonx.ai-Runtime)\n",
    "- [Create a deployment](#Create-a-deployment)\n",
    "- [Create and monitor a job with inline data for your deployed model](#Create-and-monitor-a-job-with-inline-data-for-your-deployed-model)\n",
    "- [Display the solution](#Extract-and-display-solution)\n",
    "- [Solve another problem using the same deployment](#Solve-another-problem-using-the-same-deployment)\n",
    "- [Summary](#Summary-and-next-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "### Set up the watsonx.ai client\n",
    "\n",
    "Before you use the sample code in this notebook, you must:\n",
    "\n",
    "- create a <a href=\"https://cloud.ibm.com/catalog?category=ai\" target=\"_blank\" rel=\"noopener noreferrer\">watsonx.ai Runtime Service</a> instance. A free plan is offered and information about how to create the instance can be found at <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-overview.html?context=cpdaas\" target=\"_blank\" rel=\"noopener noreferrer\"> https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-overview.html?context=cpdaas.</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the watsonx.ai client library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6f056b71-157b-48e3-b8b6-ed21758972e2"
   },
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import APIClient\n",
    "from ibm_watsonx_ai import Credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='create'></a>\n",
    "### Create a client instance\n",
    "\n",
    "Use your IBM Cloud API key. You can find information on how to get your API key <a href=\"https://dataplatform.cloud.ibm.com/docs/content/DO/WML_Deployment/DeployModelRest.html?audience=wdp&context=cpdaas#tasktask_deploymodelREST__prereq_el2_nft_bhb\">here</a> and the instance URL <a href=\"https://cloud.ibm.com/apidocs/machine-learning#endpoint-url\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3e588c98-122e-43d6-92c0-5f13074b3498"
   },
   "outputs": [],
   "source": [
    "# Instantiate a client using credentials\n",
    "credentials = Credentials(\n",
    "      api_key = \"<API_key>\",\n",
    "      url = \"<instance_url>\"\n",
    ")\n",
    "\n",
    "client = APIClient(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ac307511-2be4-4f73-ab82-3819143098db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.17'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prepare'></a>\n",
    "### Prepare your model archive\n",
    "\n",
    "Put the model.py file in a subdirectory and create a tar.gz file. The model consists of two parts:\n",
    "* some functions that create an `inputs` dictionary from files and that create files from an `outputs` dictionary,\n",
    "* the optimization model that uses the inputs and outputs dictionaries.\n",
    "\n",
    "Use the `write_file` command to write the model to a `main.py` file. \n",
    "\n",
    "Use the `tar` command to create a tar archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "166b361e-9a06-49c0-929b-a3a721b175d5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%mkdir model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "2885ddad-828a-47a1-9327-974ce79a7f02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model/main.py\n",
    "\n",
    "from docplex.util.environment import get_environment\n",
    "import pandas\n",
    "from six import iteritems\n",
    "from collections.abc import Mapping\n",
    "from os.path import join, dirname, basename, splitext, exists\n",
    "import glob\n",
    "\n",
    "class _InputDict(dict):\n",
    "    def __init__(self, directory, names):\n",
    "        dict.__init__(self)\n",
    "        self._directory = directory\n",
    "        for k in names:\n",
    "            dict.__setitem__(self, k, None)\n",
    "        file='model_schema.json'\n",
    "        if self._directory is not None:\n",
    "            file  = \"{0}/\".format(self._directory) + file\n",
    "        self.dtype_schemas = self.get_dtype_schemas( file)\n",
    "    def __getitem__(self, key):\n",
    "        if isinstance(key, str):\n",
    "            item = dict.__getitem__(self, key)\n",
    "            if item is None:\n",
    "                file = \"{0}.csv\".format(key)\n",
    "                if file in self.dtype_schemas:\n",
    "                    return self.read_df( key, dtype=self.dtype_schemas[file])\n",
    "                else:\n",
    "                    return self.read_df( key)\n",
    "            else:\n",
    "                return item\n",
    "        else:\n",
    "            raise Exception(\"Accessing input dict via non string index\")\n",
    "    def read_df(self, key, **kwargs):\n",
    "        env = get_environment()\n",
    "        file = \"{0}.csv\".format(key)\n",
    "        if self._directory is not None:\n",
    "            file  = \"{0}/\".format(self._directory) + file\n",
    "        with env.get_input_stream(file) as ist:\n",
    "            params = {'encoding': 'utf8'}\n",
    "            if kwargs:\n",
    "                params.update(kwargs)\n",
    "            df = pandas.read_csv( ist, **params)\n",
    "            dict.__setitem__(self, key, df)\n",
    "        return df\n",
    "    def get_dtype_schemas(self, path):\n",
    "        dtype_schemas = {}\n",
    "        if exists(path):\n",
    "            input_schemas=json.load(open(path))\n",
    "            if 'input' in input_schemas:\n",
    "                for input_schema in input_schemas['input']:\n",
    "                    dtype_schema = {}\n",
    "                    if 'fields' in input_schema:\n",
    "                        for input_schema_field in input_schema['fields']:\n",
    "                            if input_schema_field['type']=='string':\n",
    "                                dtype_schema[input_schema_field['name']]='str'\n",
    "                        if len(dtype_schema) > 0:\n",
    "                            dtype_schemas[input_schema['id']]=dtype_schema\n",
    "        print(dtype_schemas)\n",
    "        return dtype_schemas\n",
    "\n",
    "class _LazyDict(Mapping):\n",
    "    def __init__(self, *args, **kw):\n",
    "        self._raw_dict = _InputDict(*args, **kw)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self._raw_dict.__getitem__(key)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._raw_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._raw_dict)\n",
    "\n",
    "    def read_df(self, key, **kwargs):\n",
    "        return self._raw_dict.read_df(key, **kwargs)\n",
    "\n",
    "def get_all_inputs(directory=None):\n",
    "    '''Utility method to read a list of files and return a tuple with all\n",
    "    read data frames.\n",
    "    Returns:\n",
    "        a map { datasetname: data frame }\n",
    "    '''\n",
    "\n",
    "    all_csv = \"*.csv\"\n",
    "    g = join(directory, all_csv) if directory else all_csv\n",
    "\n",
    "    names = [splitext(basename(f))[0] for f in glob.glob(g)]\n",
    "    result = _LazyDict(directory, names)\n",
    "    return result\n",
    "\n",
    "def write_all_outputs(outputs):\n",
    "    '''Write all dataframes in ``outputs`` as .csv.\n",
    "\n",
    "    Args:\n",
    "        outputs: The map of outputs 'outputname' -> 'output df'\n",
    "    '''\n",
    "    for (name, df) in iteritems(outputs):\n",
    "        csv_file = '%s.csv' % name\n",
    "        print(csv_file)\n",
    "        with get_environment().get_output_stream(csv_file) as fp:\n",
    "            if sys.version_info[0] < 3:\n",
    "                fp.write(df.to_csv(index=False, encoding='utf8'))\n",
    "            else:\n",
    "                fp.write(df.to_csv(index=False).encode(encoding='utf8'))\n",
    "    if len(outputs) == 0:\n",
    "        print(\"Warning: no outputs written\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8218900b-ab78-4c77-be4d-6a8c71854ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to model/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a model/main.py\n",
    "\n",
    "from docplex.mp.progress import SolutionListener\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "\n",
    "def build_solution(sol):\n",
    "    solution_df = pandas.DataFrame(columns=['Food', 'value'])\n",
    "\n",
    "    for index, dvar in enumerate(sol.iter_variables()):\n",
    "        solution_df.loc[index,'Food'] = dvar.to_string()\n",
    "        solution_df.loc[index,'value'] = dvar.solution_value\n",
    "    \n",
    "    outputs = {}\n",
    "    outputs['solution'] = solution_df\n",
    "        \n",
    "    # Generate output files\n",
    "    write_all_outputs(outputs)\n",
    "\n",
    "    \n",
    "class SolutionKeeper(SolutionListener):\n",
    "    ''' A specialized implementation of :class:`SolutionListener`, which keeps track\n",
    "    of the latest intermediate solution found.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        SolutionListener.__init__(self)\n",
    "        self.index = -1\n",
    "\n",
    "    def notify_solution(self, sol):\n",
    "        self.index +=1\n",
    "        build_solution(sol)\n",
    "        #  `write_all_outputs()` will publish tables from outputs dictionnary as solution tables\n",
    "        write_all_outputs(outputs)\n",
    "\n",
    "\n",
    "# Load CSV files into inputs dictionnary\n",
    "inputs = get_all_inputs()\n",
    "\n",
    "food = inputs['diet_food']\n",
    "nutrients = inputs['diet_nutrients']\n",
    "food_nutrients = inputs['diet_food_nutrients']\n",
    "food_nutrients.set_index('Food', inplace=True)\n",
    "        \n",
    "from docplex.mp.model import Model\n",
    "\n",
    "# Model\n",
    "mdl = Model(name='diet')\n",
    "\n",
    "# To obtain tables for intermediate solutions, you must add a SolutionListener\n",
    "# so that you can then create solution tables and publish them.\n",
    "mdl.add_progress_listener(SolutionKeeper())\n",
    "    \n",
    "# Create decision variables, limited to be >= Food.qmin and <= Food.qmax\n",
    "qty = food[['name', 'qmin', 'qmax']].copy()\n",
    "qty['var'] = qty.apply(lambda x: mdl.continuous_var(lb=x['qmin'],\n",
    "                                                ub=x['qmax'],\n",
    "                                                name=x['name']),\n",
    "                   axis=1)\n",
    "# make the name the index\n",
    "qty.set_index('name', inplace=True)\n",
    "\n",
    "# Limit range of nutrients, and mark them as KPIs\n",
    "for n in nutrients.itertuples():\n",
    "    amount = mdl.sum(qty.loc[f.name]['var'] * food_nutrients.loc[f.name][n.name]\n",
    "                     for f in food.itertuples())\n",
    "    mdl.add_range(n.qmin, amount, n.qmax)\n",
    "    mdl.add_kpi(amount, publish_name='Total %s' % n.name)\n",
    "\n",
    "# Minimize cost\n",
    "obj = mdl.sum(qty.loc[f.name]['var'] * f.unit_cost for f in food.itertuples())\n",
    "mdl.add_kpi(obj, publish_name=\"Minimal cost\");\n",
    "mdl.minimize(obj)\n",
    "\n",
    "mdl.print_information()\n",
    "\n",
    "# solve\n",
    "ok = mdl.solve()\n",
    "\n",
    "mdl.print_solution()\n",
    "build_solution(mdl.solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "c9b599c9-c36d-4e03-bbc7-c697b816fba2"
   },
   "outputs": [],
   "source": [
    "import tarfile\n",
    "def reset(tarinfo):\n",
    "    tarinfo.uid = tarinfo.gid = 0\n",
    "    tarinfo.uname = tarinfo.gname = \"root\"\n",
    "    return tarinfo\n",
    "tar = tarfile.open(\"model.tar.gz\", \"w:gz\")\n",
    "tar.add(\"model/main.py\", arcname=\"main.py\", filter=reset)\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='upload'></a>\n",
    "### Upload your model on watsonx.ai Runtime\n",
    "\n",
    "Store model in watsonx.ai Runtime with:\n",
    "* the tar archive previously created,\n",
    "* metadata including the model type and runtime\n",
    "\n",
    "Get the `model_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "d06edfe8-fa2b-4827-b248-707617670b98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "META_PROP NAME            TYPE  REQUIRED  SCHEMA\n",
      "NAME                      str   Y\n",
      "DESCRIPTION               str   N\n",
      "INPUT_DATA_SCHEMA         list  N         {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}\n",
      "TRAINING_DATA_REFERENCES  list  N         [{'name(optional)': 'string', 'type(required)': 'string', 'connection(required)': {'endpoint_url(required)': 'string', 'access_key_id(required)': 'string', 'secret_access_key(required)': 'string'}, 'location(required)': {'bucket': 'string', 'path': 'string'}, 'schema(optional)': {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}}]\n",
      "TEST_DATA_REFERENCES      list  N         [{'name(optional)': 'string', 'type(required)': 'string', 'connection(required)': {'endpoint_url(required)': 'string', 'access_key_id(required)': 'string', 'secret_access_key(required)': 'string'}, 'location(required)': {'bucket': 'string', 'path': 'string'}, 'schema(optional)': {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}}]\n",
      "OUTPUT_DATA_SCHEMA        dict  N         {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}\n",
      "LABEL_FIELD               str   N\n",
      "TRANSFORMED_LABEL_FIELD   str   N\n",
      "TAGS                      list  N         ['string', 'string']\n",
      "SIZE                      dict  N         {'in_memory(optional)': 'string', 'content(optional)': 'string'}\n",
      "PIPELINE_ID               str   N\n",
      "RUNTIME_ID                str   N\n",
      "TYPE                      str   Y\n",
      "CUSTOM                    dict  N\n",
      "DOMAIN                    str   N\n",
      "HYPER_PARAMETERS          dict  N\n",
      "METRICS                   list  N\n",
      "IMPORT                    dict  N         {'name(optional)': 'string', 'type(required)': 'string', 'connection(required)': {'endpoint_url(required)': 'string', 'access_key_id(required)': 'string', 'secret_access_key(required)': 'string'}, 'location(required)': {'bucket': 'string', 'path': 'string'}}\n",
      "TRAINING_LIB_ID           str   N\n",
      "MODEL_DEFINITION_ID       str   N\n",
      "SOFTWARE_SPEC_ID          str   N\n",
      "TF_MODEL_PARAMS           dict  N\n",
      "FAIRNESS_INFO             dict  N\n",
      "MODEL_LOCATION            dict  N\n",
      "FRAMEWORK                 str   N\n",
      "VERSION                   str   N\n",
      "------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# All available meta data properties \n",
    "\n",
    "client.repository.ModelMetaNames.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to list deployment spaces and delete any that are no longer needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.spaces.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.spaces.delete(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.spaces.get_details(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "84c4677c-fef8-4636-8f6f-ad2992ec0f67"
   },
   "outputs": [],
   "source": [
    "# Find the space ID\n",
    "\n",
    "space_name = \"<space_name>\"\n",
    "\n",
    "space_id = [x['metadata']['id'] for x in client.spaces.get_details()['resources'] if x['entity']['name'] == space_name][0]\n",
    "\n",
    "client = APIClient(credentials, space_id = space_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7d78fbea-857d-407c-8e7b-25c151e0cc3a"
   },
   "outputs": [],
   "source": [
    "mnist_metadata = {\n",
    "    client.repository.ModelMetaNames.NAME: \"Diet\",\n",
    "    client.repository.ModelMetaNames.DESCRIPTION: \"Model for Diet\",\n",
    "    client.repository.ModelMetaNames.TYPE: \"do-docplex_22.1\",\n",
    "    client.repository.ModelMetaNames.SOFTWARE_SPEC_ID: client.software_specifications.get_id_by_name(\"do_22.1\"),\n",
    "    # OPTIONAL but can be interesting for a better inference of string data if needed\n",
    "    client.repository.ModelMetaNames.INPUT_DATA_SCHEMA: [ \n",
    "        { \"id\" : \"diet_food_nutrients.csv\",  \"fields\" : [ \n",
    "            { \"name\" : \"Food\", \"type\" : \"string\" }, { \"name\" : \"Calories\", \"type\" : \"double\" }, { \"name\" : \"Calcium\", \"type\" : \"double\" }, { \"name\" : \"Iron\", \"type\" : \"double\" }, \n",
    "            { \"name\" : \"Vit_A\", \"type\" : \"double\" }, { \"name\" : \"Dietary_Fiber\", \"type\" : \"double\" }, { \"name\" : \"Carbohydrates\", \"type\" : \"double\" }, { \"name\" : \"Protein\", \"type\" : \"double\" } ] }, \n",
    "        { \"id\" : \"diet_food.csv\", \"fields\" : [ \n",
    "            { \"name\" : \"name\", \"type\" : \"string\" }, { \"name\" : \"unit_cost\", \"type\" : \"double\" }, { \"name\" : \"qmin\", \"type\" : \"double\" }, { \"name\" : \"qmax\", \"type\" : \"double\" } ] }, \n",
    "        { \"id\" : \"diet_nutrients.csv\", \"fields\" : [ \n",
    "            { \"name\" : \"name\", \"type\" : \"string\" }, { \"name\" : \"qmin\", \"type\" : \"double\" }, { \"name\" : \"qmax\", \"type\" : \"double\" } ] } ],\n",
    "    # OPTIONAL but can be interesting for a better inference of string data mainly in context of inline data if needed\n",
    "    client.repository.ModelMetaNames.OUTPUT_DATA_SCHEMA: [ \n",
    "        { \"id\" : \"stats.csv\", \"fields\" : [ \n",
    "            { \"name\" : \"Name\", \"type\" : \"string\" }, { \"name\" : \"Value\", \"type\" : \"string\" } ] }, \n",
    "        { \"id\" : \"solution.csv\", \"fields\" : [ \n",
    "            { \"name\" : \"name\", \"type\" : \"string\" }, { \"name\" : \"value\", \"type\" : \"double\" } ] }, \n",
    "        { \"id\" : \"kpis.csv\", \"fields\" : [ \n",
    "            { \"name\" : \"Name\", \"type\" : \"string\" }, { \"name\" : \"Value\", \"type\" : \"double\" } ] } ]\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(model='/home/wsuser/work/model.tar.gz', meta_props=mnist_metadata)\n",
    "\n",
    "model_uid = client.repository.get_model_id(model_details)\n",
    "\n",
    "# print model uid if needed\n",
    "# print( model_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deploy'></a>\n",
    "### Create a deployment \n",
    "\n",
    "Create a batch deployment for the model, providing information such as:\n",
    "* the maximum number of compute nodes\n",
    "* the T-shirt size of the compute nodes\n",
    "\n",
    "Get the `deployment_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "307fc758-02a2-43cd-a8b9-571e7f542870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "Synchronous deployment creation for id: '64ba0a0d-cc2b-4f78-8127-5696ffab913c' started\n",
      "\n",
      "######################################################################################\n",
      "\n",
      "\n",
      "ready.\n",
      "\n",
      "\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Successfully finished deployment creation, deployment_id='9d46268e-f632-406b-8b35-7245f9560ee2'\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "meta_props = {\n",
    "    client.deployments.ConfigurationMetaNames.NAME: \"Diet Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.DESCRIPTION: \"Diet Deployment\",\n",
    "    client.deployments.ConfigurationMetaNames.BATCH: {},\n",
    "    client.deployments.ConfigurationMetaNames.HARDWARE_SPEC: {'name': 'S', 'num_nodes': 1}\n",
    "}\n",
    "\n",
    "deployment_details = client.deployments.create(model_uid, meta_props=meta_props)\n",
    "\n",
    "deployment_uid = client.deployments.get_id(deployment_details)\n",
    "\n",
    "# print deployment id if needed\n",
    "# print( deployment_uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "d5150ebb-3b85-4493-9fe1-4c74317f5cd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NAME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CREATED</th>\n",
       "      <th>ARTIFACT_TYPE</th>\n",
       "      <th>SPEC_STATE</th>\n",
       "      <th>SPEC_REPLACEMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9d46268e-f632-406b-8b35-7245f9560ee2</td>\n",
       "      <td>Diet Deployment</td>\n",
       "      <td>ready</td>\n",
       "      <td>2025-05-09T14:20:15.953Z</td>\n",
       "      <td>do</td>\n",
       "      <td>supported</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     ID             NAME  STATE  \\\n",
       "0  9d46268e-f632-406b-8b35-7245f9560ee2  Diet Deployment  ready   \n",
       "\n",
       "                    CREATED ARTIFACT_TYPE SPEC_STATE SPEC_REPLACEMENT  \n",
       "0  2025-05-09T14:20:15.953Z            do  supported                   "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all existing deployments\n",
    "\n",
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='job'></a>\n",
    "### Create and monitor a job with inline data for your deployed model\n",
    "\n",
    "Create a payload containing inline input data.\n",
    "\n",
    "Create a new job with this payload and the deployment.\n",
    "\n",
    "Get the `job_uid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ef5e31e1-65c2-48dc-bf8a-c7cfda671e0d"
   },
   "outputs": [],
   "source": [
    "# Import pandas library \n",
    "import pandas as pd \n",
    "  \n",
    "# Initialize list of lists \n",
    "diet_food = pd.DataFrame([ [\"Roasted Chicken\", 0.84, 0, 10],\n",
    "                [\"Spaghetti W/ Sauce\", 0.78, 0, 10],\n",
    "                [\"Tomato,Red,Ripe,Raw\", 0.27, 0, 10],\n",
    "                [\"Apple,Raw,W/Skin\", 0.24, 0, 10],\n",
    "                [\"Grapes\", 0.32, 0, 10],\n",
    "                [\"Chocolate Chip Cookies\", 0.03, 0, 10],\n",
    "                [\"Lowfat Milk\", 0.23, 0, 10],\n",
    "                [\"Raisin Brn\", 0.34, 0, 10],\n",
    "                [\"Hotdog\", 0.31, 0, 10]] , columns = [\"name\", \"unit_cost\", \"qmin\", \"qmax\"])\n",
    "\n",
    "diet_food_nutrients = pd.DataFrame([\n",
    "                [\"Spaghetti W/ Sauce\", 358.2, 80.2, 2.3, 3055.2, 11.6, 58.3, 8.2],\n",
    "                [\"Roasted Chicken\", 277.4, 21.9, 1.8, 77.4, 0, 0, 42.2],\n",
    "                [\"Tomato,Red,Ripe,Raw\", 25.8, 6.2, 0.6, 766.3, 1.4, 5.7, 1],\n",
    "                [\"Apple,Raw,W/Skin\", 81.4, 9.7, 0.2, 73.1, 3.7, 21, 0.3],\n",
    "                [\"Grapes\", 15.1, 3.4, 0.1, 24, 0.2, 4.1, 0.2],\n",
    "                [\"Chocolate Chip Cookies\", 78.1, 6.2, 0.4, 101.8, 0, 9.3, 0.9],\n",
    "                [\"Lowfat Milk\", 121.2, 296.7, 0.1, 500.2, 0, 11.7, 8.1],\n",
    "                [\"Raisin Brn\", 115.1, 12.9, 16.8, 1250.2, 4, 27.9, 4],\n",
    "                [\"Hotdog\", 242.1, 23.5, 2.3, 0, 0, 18, 10.4]\n",
    "            ] , columns = [\"Food\", \"Calories\", \"Calcium\", \"Iron\", \"Vit_A\", \"Dietary_Fiber\", \"Carbohydrates\", \"Protein\"])\n",
    "\n",
    "diet_nutrients = pd.DataFrame([\n",
    "                [\"Calories\", 2000, 2500],\n",
    "                [\"Calcium\", 800, 1600],\n",
    "                [\"Iron\", 10, 30],\n",
    "                [\"Vit_A\", 5000, 50000],\n",
    "                [\"Dietary_Fiber\", 25, 100],\n",
    "                [\"Carbohydrates\", 0, 300],\n",
    "                [\"Protein\", 50, 100]\n",
    "            ], columns = [\"name\", \"qmin\", \"qmax\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to enable intermediate solutions for your solve, uncomment the ``oaas.outputUploadPeriod`` solve parameter (expressed in minutes).\n",
    "\n",
    "You can also uncomment ``oaas.outputUploadFiles`` if you want to get logs at each intermediate solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "d2d00b3c-ed8a-4df4-82b5-755b6e597f48",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "solve_payload = {\n",
    "    \"solve_parameters\" : {\n",
    "        #\"oaas.outputUploadPeriod\": \"1\",\n",
    "        #\"oaas.outputUploadFiles\": \".*\\.txt\",\n",
    "        \"oaas.logAttachmentName\":\"log.txt\",\n",
    "        \"oaas.logTailEnabled\":\"true\"\n",
    "    },\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\"diet_food.csv\",\n",
    "            \"values\" : diet_food\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_food_nutrients.csv\",\n",
    "            \"values\" : diet_food_nutrients\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_nutrients.csv\",\n",
    "            \"values\" : diet_nutrients\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\".*\\.csv\"\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA_REFERENCES: [\n",
    "        {\n",
    "            \"id\": \"log.txt\",\n",
    "            \"type\": \"data_asset\",\n",
    "            \"connection\": {},\n",
    "            \"location\": {\"name\":\"job_${oaas_job_id}_log_${oaas_update_time}.txt\"}\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_id(job_details)\n",
    "\n",
    "# print job id if needed\n",
    "# print( job_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed.\n",
    "\n",
    "The first job of a new deployment might take some time as a compute node must be started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "45331f6a-f7d3-4978-912c-78cffd4f0d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued...\n",
      "      No intermediate available\n",
      "queued...\n",
      "      No intermediate available\n",
      "queued...\n",
      "      No intermediate available\n",
      "queued...\n",
      "      No intermediate available\n",
      "queued...\n",
      "      No intermediate available\n",
      "queued...\n",
      "      No intermediate available\n",
      "queued...\n",
      "      No intermediate available\n",
      "queued...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "running...\n",
      "      No intermediate available\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    if('solve_state' in job_details['entity']['decision_optimization']\n",
    "       and 'details' in job_details['entity']['decision_optimization']['solve_state']\n",
    "       and 'latestOutputUpload' in job_details['entity']['decision_optimization']['solve_state']['details']):\n",
    "        print( \"      Intermediate captured at: \", job_details['entity']['decision_optimization']['solve_state']['details']['latestOutputUpload'])\n",
    "    else:\n",
    "        print( \"      No intermediate available\" )\n",
    "    \n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "if job_details['entity']['decision_optimization']['status']['state'] in ['failed']:\n",
    "    print( job_details['entity']['decision_optimization']['status'] )    \n",
    "else:\n",
    "    print( job_details['entity']['decision_optimization']['status']['state'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='display'></a>\n",
    "### Extract and display solution\n",
    "\n",
    "Display the output solution.\n",
    "\n",
    "Display the KPI Total Calories value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "f90b923a-db71-4ea4-a0da-b964fb08a5b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cplex.size.integerVariables</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cplex.size.linearConstraints</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cplex.modelType</td>\n",
       "      <td>LP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cplex.size.semiintegerVariables</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cplex.size.variables</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name Value\n",
       "0      cplex.size.integerVariables     0\n",
       "1     cplex.size.linearConstraints     7\n",
       "2                  cplex.modelType    LP\n",
       "3  cplex.size.semiintegerVariables     0\n",
       "4             cplex.size.variables     9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe for the solution\n",
    "solution = pd.DataFrame(job_details['entity']['decision_optimization']['output_data'][0]['values'], \n",
    "                        columns = job_details['entity']['decision_optimization']['output_data'][0]['fields'])\n",
    "solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "55af2d88-57ec-4fed-879d-d2eb8a208e41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000.0\n"
     ]
    }
   ],
   "source": [
    "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='problem'></a>\n",
    "###  Solve another problem using the same deployment\n",
    "\n",
    "Create a new payload with modified input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "77ad8102-8238-4b47-9c7b-b1a23244f513"
   },
   "outputs": [],
   "source": [
    "# Change the input data\n",
    "diet_nutrients.at[0,'qmin'] = 1500\n",
    "diet_nutrients.at[0,'qmax'] = 2000\n",
    "\n",
    "solve_payload = {\n",
    "    client.deployments.DecisionOptimizationMetaNames.INPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\"diet_food.csv\",\n",
    "            \"values\" : diet_food         \n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_food_nutrients.csv\",\n",
    "             \"values\" : diet_food_nutrients            \n",
    "        },\n",
    "        {\n",
    "            \"id\":\"diet_nutrients.csv\",\n",
    "            \"values\" : diet_nutrients\n",
    "        }\n",
    "    ],\n",
    "    client.deployments.DecisionOptimizationMetaNames.OUTPUT_DATA: [\n",
    "        {\n",
    "            \"id\":\".*\\.csv\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "46f84690-4c1a-455f-bff3-022f347d49b5"
   },
   "outputs": [],
   "source": [
    "job_details = client.deployments.create_job(deployment_uid, solve_payload)\n",
    "job_uid = client.deployments.get_job_id(job_details)\n",
    "\n",
    "# print job id if needed\n",
    "# print( job_uid )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display job status until it is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "1b0cfbe5-e2e5-44ff-a695-342768dab951"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queued...\n",
      "completed\n"
     ]
    }
   ],
   "source": [
    "while job_details['entity']['decision_optimization']['status']['state'] not in ['completed', 'failed', 'canceled']:\n",
    "    print(job_details['entity']['decision_optimization']['status']['state'] + '...')\n",
    "    sleep(5)\n",
    "    job_details=client.deployments.get_job_details(job_uid)\n",
    "\n",
    "print( job_details['entity']['decision_optimization']['status']['state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the KPI Total Calories value for this modified data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "5d0179ca-6bfb-4074-b92b-93ed6f80047e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500.0\n"
     ]
    }
   ],
   "source": [
    "print( job_details['entity']['decision_optimization']['solve_state']['details']['KPI.Total Calories'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "c873ff96-1caa-40ee-947e-fa0256b2ceed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'completed_at': '2025-05-09T14:22:22.773Z', 'running_at': '2025-05-09T14:22:21.123Z', 'state': 'completed'}\n"
     ]
    }
   ],
   "source": [
    "print(client.deployments.get_job_details(job_uid)['entity']['decision_optimization']['status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete the deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following method to delete the deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "b238d24e-f2b4-4b79-929f-b5d18062a16d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.deployments.delete(deployment_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "### Summary and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've successfully completed this notebook! \n",
    "\n",
    "You've learned how to:\n",
    "\n",
    "- work with the watsonx.ai client\n",
    "- prepare your model archive and upload your model on watsonx.ai Runtime\n",
    "- create a deployment\n",
    "- create and monitor a job with inline data for your deployed model\n",
    "- display the solution\n",
    "\n",
    "Check out our online documentation for more samples, tutorials and documentation:\n",
    "* <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/welcome-main.html?context=cpdaas\" target=\"_blank\" rel=\"noopener noreferrer\">IBM Cloud Pak for Data as a Service documentation</a>\n",
    "* <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/welcome-main.html?context=wx\" target=\"_blank\" rel=\"noopener noreferrer\">IBM watsonx.ai documentation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "Copyright © 2019-2025. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
