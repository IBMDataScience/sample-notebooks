{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect potentially malfunctioning sensors in real time using Streaming Analytics and Python\n",
    "\n",
    "\n",
    "In this notebook, you will create an application that receives weather data from simulated weather stations and then detects if any of those stations are malfunctioning. This is done by comparing the temperature from each station with the average temperature from all the other stations in the same region. If a station's reading is considered to be an outlier, then it is flagged as potentially malfunctioning.\n",
    "\n",
    "The data is visualized on a map, and malfunctioning stations are shown as red, as in the image below. Note that the readings are updated in real time.\n",
    "<img src=\"https://raw.githubusercontent.com/IBMStreams/samples/master/IoT/WeatherStationApp/img/dsx-weather-app.gif\"/>\n",
    "\n",
    "This notebook runs on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Setup](#setup)<br>\n",
    "    1.1 [Option 1: Automatically deploy and configure the services](#setup1)<br>\n",
    "    1.2 [Option 2: Manual deployment](#setup2)<br>\n",
    "    1.3 [Specify service credentials](#setup3)<br>\n",
    "    1.4 [Start generating data](#setup4)<br>\n",
    "2. [Create Streams application](#step2)<br>\n",
    "    2.1 [Define helper classes](#step21)<br>\n",
    "    2.2 [Define Streams `Topology` to tag outliers](#step22)<br>\n",
    "    2.3 [View the data in the Streams Console](#step23)<br>\n",
    "3. [Load data](#load)<br>\n",
    "    3.1 [Get your Plotly credentials information](#load31)<br>\n",
    "    3.2 [Create Plotly stream  objects using your credentials](#load32)<br>\n",
    "    3.3 [Fetch and display the sensor data from Streams](#load33)<br>\n",
    "    3.4 [Troubleshooting](#load34)<br>\n",
    "4. [Shutdown](#step4)<br>\n",
    "5. [Summary and next steps](#summary)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n",
    "## 1. Setup\n",
    "\n",
    "This notebook requires you to have the Streaming Analytics service and the Watson IoT Platform service. You can set up and connect the services manually or use the automatic option if it applies to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup1\"></a>\n",
    "### 1.1 Option 1: Automatically deploy and configure the services\n",
    "\n",
    "You can use this option if:\n",
    "- You do not have the services created in IBM Cloud, or\n",
    "- You have both services created and would like to use automatic configuration. If so, you must first rename the services to match the names expected by the configuration script before starting the process:\n",
    "   - Rename the Streaming Analtyics service to *Streaming-Analytics* \n",
    "   - Rename the Watson IoT Platform to *Internet-of-Things-Platform*.\n",
    "   *These names must match exactly as indicated here*.\n",
    "\n",
    " 1. Click the **Deploy to IBM Cloud** button to deploy the services automatically.\n",
    "[![Deploy To IBM Cloud](https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2017/11/deploy-to-ibm-cloud-small.png)](https://bluemix.net/deploy?repository=https://github.com/IBMStreams/streamsx.iot.starterkit.git)\n",
    "\n",
    " 2. Once the deployment is finished, go to your IBM Cloud dashboard as shown below. Click the newly deployed app under \"Cloud Foundry Apps\". This will take you to the application page.\n",
    "    ![app dashboard](https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2018/01/app-dashboard.png)\n",
    "\n",
    "    Set up a username and password for the starter kit by following these instructions:\n",
    "    - Click **Runtime** > **Environment variables**.\n",
    "    - Under **User defined**, create a username and password for your starter kit by adding 2 variables called `KIT_OWNER` (username) and `KIT_PASSWORD` (password). Names must be exactly as shown here.  Click **Save**.\n",
    "    - Click **Visit app URL** to go to the starter kit home page and log in with the username and password you just created.\n",
    "    These steps are illustrated below.\n",
    "    ![setusername](https://raw.githubusercontent.com/IBMStreams/streamsx.iot.starterkit/master/img/env.png)\n",
    "\n",
    " 3. Clicking **Visit App URL** will take you to the home page of your starter kit. Log in using the `KIT_OWNER` and `KIT_PASSWORD` as username and password. Now you can access the needed credentials.\n",
    "    To finish the automatic setup: \n",
    "\n",
    "        1. Go to \"Tools\" and click \"Submit IotPlatform Job\".\n",
    "        1. Download the `device.cfg` file: Click **View All Credentials**, then under **Edgent Credentials**, select **Download Device.cfg**. Save this file locally.\n",
    "        1. Get credentials for your Streaming Analytics service:\n",
    "         - From the landing page, click **View All Credentials**.\n",
    "         - In the  **Streams credentials** tab, click \"Get Credentials\", and copy the contents of the cell. You will paste them where required in the cell below. \n",
    "         - Paste them in the cell titled *Specify Streams Credentials* below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup2\"></a>\n",
    "### 1.2 Option 2: Manual deployment \n",
    "\n",
    "If you have not already done so, create instances of the <a href=\"https://console.bluemix.net/catalog/services/streaming-analytics\" target=\"_blank\">Streaming Analytics service</a> and the <a href=\"https://console.bluemix.net/catalog/services/internet-of-things-platform\" target=\"_blank\">Watson IoT Platform</a> service. \n",
    "\n",
    "Next, follow the <a href=\"https://developer.ibm.com/streamsdev/docs/setup-instructions-connecting-edgent-streams-applications-watson-iot-platform\" target=\"_blank\">instructions in this post</a>.\n",
    "After completing the steps in the above article, you will get:\n",
    " - A registered device on the Watson IoT Platform and a `device.cfg` file with the information for the device.\n",
    " - The `IotPlatformBluemix` application running in your Streaming Analytics application.\n",
    " \n",
    "Finally, **get your Streaming Analytics credentials** and paste them in the cell below:\n",
    "- Open the Streaming Analytics service dashboard, click **Service Credentials**. If no credentials are listed, click **New Credential** to create a set of credentials. Then click **View Credentials**, and finally click the Copy icon.\n",
    "- You need the *service_name* (`test1` in the screenshot)  below. Then, set  the credentials you copied to the `credentials` variable in the cell below and change the `service_name` variable to your service name.\n",
    "\n",
    "<img src='https://github.com/orzade/streamsx-notebooks/blob/master/copyservicecredentials.png?raw=true' alt=\"Copy your service credentials\" title=\"Streaming Analytics catalog - Copy your service credentials\"></img>\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup3\"></a>\n",
    "### 1.3 Specify service credentials\n",
    "\n",
    "- Set  the Streaming Analytics credentials you copied to the `credentials` variable in the cell below.\n",
    "- Change the `service_name` variable to your service name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Set up access to Streaming Analytics service\n",
    "\n",
    "def get_service_name():\n",
    "    service_name = \"Streaming-Analytics\" ## If you chose manual deployment, change the service name here \n",
    "    return service_name\n",
    "def get_credentials():\n",
    "    \n",
    "    credentials = \"\"\" enter credentials here\"\"\"\n",
    "    return credentials\n",
    "\n",
    "def submit_to_service(topo):\n",
    "    service_name = get_service_name()\n",
    "    credentials = get_credentials()\n",
    "    vs={'streaming-analytics': [{'name': service_name, 'credentials': json.loads (credentials)}]}\n",
    "    cfg = {}\n",
    "    cfg[ConfigParams.VCAP_SERVICES] = vs\n",
    "    cfg[ConfigParams.SERVICE_NAME] = service_name\n",
    "    return submit('STREAMING_ANALYTICS_SERVICE', topo, cfg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup4\"></a>\n",
    "### 1.4 Start generating data\n",
    "\n",
    "The data processed by this notebook is from an Edgent application that sends simulated weather data from different locations in Toronto and Markham. To generate the sample data: \n",
    "\n",
    "1. Download and unpack the <a href=\"https://github.com/IBMStreams/samples/raw/WeatherStationApp/IoT/WeatherStationApp/WeatherStationSimulator/weather-station-simulator.jar\" target=\"_blank\">Weather Station simulator application</a>.\n",
    "1. Make sure you have also saved your `device.cfg` file locally.\n",
    "1. Start generating data by running the application:\n",
    "\n",
    "`java -Dcom.ibm.iotf.enableCustomFormat=false -jar weather-station-simulator.jar path/to/device.cfg`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step2\"></a>\n",
    "## 2. Create Streams application\n",
    "\n",
    "This application will ingest data from the sensors in different locations and show the live readings from each sensor on a map, updating in real time. It will also show any sensors that are detected to be outliers as red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step21\"></a>\n",
    "### 2.1 Define helper classes\n",
    "\n",
    "The `TagOutliers` class below will compute the rolling average temperature for the weather stations, and then will add a tag to each station based on whether or not it could possibly be malfunctioning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "        \n",
    "def parse_json(tuple):\n",
    "    js = tuple[\"jsonString\"]\n",
    "    reading = json.loads(js)\n",
    "    return reading[\"d\"]\n",
    "   \n",
    "class TagOutliers():\n",
    "    \"\"\"\n",
    "    A callable class that determines if a tuple is an outlier. \n",
    "    It adds a new key \"outlier\" to the tuple to indicate whether or not the value is an outlier.\n",
    "    An outlier is defined as more than (threshold * standard deviation) from the average.\n",
    "    \n",
    "    Args:\n",
    "        threshold (number): threshold\n",
    "        n: window size, the number of items used to compute the average\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold, n):\n",
    "        self.threshold = threshold\n",
    "        self.window = {}\n",
    "        self.num = n\n",
    "    def window_isfull(self):\n",
    "        return len(self.window) == self.num \n",
    "    def is_outlier(self, value, average, stddev):\n",
    "        distance_from_avg = abs(value-average)\n",
    "        #if the distance_from_avg exceeds the threshold then this is an outlier\n",
    "        is_outlier = distance_from_avg > (self.threshold *stddev)\n",
    "        return is_outlier\n",
    "    \n",
    "    def __call__(self, tuple):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tuple that represents a reading from a weather station.\n",
    "        Returns:\n",
    "            None if the window is not full.\n",
    "            When the window is full, returns a list of all the tuples in the window, flagging those which are outliers\n",
    "        \"\"\"\n",
    "        #add an entry to the window for this tuple based on its id\n",
    "        self.window[tuple[\"id\"]] = tuple\n",
    "        \n",
    "        #calculate stddev and avg when the window is full\n",
    "        if self.window_isfull():\n",
    "\n",
    "            readings = [x[\"temp\"] for x in self.window.values()]\n",
    "            #use numpy.average and std to compute average and stddev\n",
    "            avg = np.average(readings);\n",
    "            stddev = np.std(readings)\n",
    "            #determine which of the stations in the window have a value that is an outlier\n",
    "            for station in self.window.values():\n",
    "                temp = station[\"temp\"]\n",
    "                station[\"outlier\"] = str(self.is_outlier(temp, avg, stddev))\n",
    "                station[\"avg\"] = avg\n",
    "                \n",
    "            values =  list(self.window.values()) \n",
    "            self.window = {}\n",
    "            \n",
    "            return values\n",
    "\n",
    "    \n",
    "class MergeStreams:\n",
    "    \"\"\"\n",
    "    It will take two streams of lists, and produce one stream with the contents of lists\n",
    "    The incoming data is split by location, and this class merges the previously split streams\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.last_rh = []\n",
    "        self.last_mkm = []\n",
    "    \n",
    "    def __call__(self, tuple):\n",
    "        if tuple[0][\"location\"] == \"tor\":\n",
    "            self.last_rh = tuple\n",
    "        else:\n",
    "            self.last_mkm = tuple\n",
    "        if len(self.last_mkm) > 0 and len(self.last_rh) > 0 :\n",
    "            merged = self.last_mkm + self.last_rh\n",
    "            self.last_mkm = []\n",
    "            self.last_rh = []\n",
    "            return merged\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step22\"></a>\n",
    "### 2.2 Define Streams `Topology` to tag outliers\n",
    "\n",
    "Streams applications are directed graphs with data moving from one operation to the next. A Streams application written in Python is called a `Topology`.\n",
    "The `Topology` you are creating will:\n",
    "- Subscribe to data from the Watson IoT platform, \n",
    "- Create 2  groups of readings, one for each location so you can compare each sensor to its nearest neighbors.\n",
    "- Use numpy to determine the rolling average and standard deviation and check each sensor's values to see if it is an outlier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dec 05, 2017 9:33:44 AM com.ibm.streamsx.topology.internal.context.remote.BuildServiceRemoteRESTWrapper remoteBuildAndSubmit\n",
      "INFO: Streaming Analytics service (Streaming-Analytics): Checking status\n",
      "Dec 05, 2017 9:33:47 AM com.ibm.streamsx.topology.internal.streaminganalytics.RestUtils checkInstanceStatus\n",
      "INFO: Streaming Analytics service (Streaming-Analytics): instance status response:{\"state\":\"STARTED\",\"plan\":\"Standard\",\"enabled\":true,\"status\":\"running\"}\n",
      "Dec 05, 2017 9:33:47 AM com.ibm.streamsx.topology.internal.context.remote.BuildServiceRemoteRESTWrapper remoteBuildAndSubmit\n",
      "INFO: Streaming Analytics service (Streaming-Analytics): submitting build TaggedWeatherStationData_E14404CA22DD3DA2\n",
      "Dec 05, 2017 9:34:43 AM com.ibm.streamsx.topology.internal.context.remote.BuildServiceRemoteRESTWrapper remoteBuildAndSubmit\n",
      "INFO: Streaming Analytics service (Streaming-Analytics): submitting job request.\n",
      "Dec 05, 2017 9:34:51 AM com.ibm.streamsx.topology.internal.context.remote.BuildServiceRemoteRESTWrapper doSubmitJobFromBuildArtifactPut\n",
      "INFO: Streaming Analytics service (Streaming-Analytics): submit job response: {\"artifact\":\"20476\",\"jobId\":\"0\",\"application\":\"ipythoninput741ebb8993b1b::TaggedWeatherStationData\",\"name\":\"ipythoninput741ebb8993b1b::TaggedWeatherStationData_0\",\"state\":\"STARTED\",\"plan\":\"Standard\",\"enabled\":true,\"status\":\"running\"}\n",
      "\n",
      "Submitted the job to Streaming Analytics service\n"
     ]
    }
   ],
   "source": [
    "#this window size is the number of stations in each location, \n",
    "#if you change the Edgent application to add more stations, this needs to be changed accordingly.\n",
    "from streamsx.topology.topology import Topology\n",
    "from streamsx.topology.context import *\n",
    "from streamsx.topology import schema\n",
    "import streamsx.spl.op as op\n",
    "import json\n",
    "\n",
    "NUM_STATIONS = 20\n",
    "NUM_STATIONS_PER_LOCATION = NUM_STATIONS/2\n",
    "window_size = NUM_STATIONS_PER_LOCATION\n",
    "threshold = 2\n",
    "\n",
    "# Create Topology - our application graph\n",
    "topo = Topology('TaggedWeatherStationData')\n",
    "sch =  schema.StreamSchema(\"tuple <rstring typeId, rstring deviceId, rstring eventId,rstring jsonString>\")\n",
    "# read from data source\n",
    "raw_events = topo.subscribe(topic=\"streamsx/iot/device/events\", schema=sch)\n",
    "\n",
    "# Get only events with id \"weather\"\n",
    "json_data_from_iotp = raw_events.filter(lambda tuple: tuple[\"eventId\"] == \"weather\", \"RawEvents\")\n",
    "\n",
    "#parse json to python objects\n",
    "readings = json_data_from_iotp.map(parse_json,\"WeatherEvents\")\n",
    "\n",
    "# Split by location so that averages are computed based on location\n",
    "tor_str = readings.filter(lambda tuple: tuple[\"location\"] == \"tor\", \"Toronto\")\n",
    "mkm_str  = readings.filter(lambda tuple: tuple[\"location\"] == \"mkm\", \"Markham\")\n",
    "\n",
    "#each stream is a list of all the current readings for each station\n",
    "#the TagOutliers class uses numpy to compute average and standard deviation and determines which stations are outliers\n",
    "tor_tagged =  tor_str.map(TagOutliers(threshold, window_size))\n",
    "mkm_tagged = mkm_str.map(TagOutliers(threshold, window_size))\n",
    "\n",
    "#merge the output streams for easy graphing in plotly\n",
    "merged = tor_tagged.union({mkm_tagged}).map(MergeStreams())\n",
    "\n",
    "merged.print()\n",
    "\n",
    "#this view allows us to graph the data from the merged stream\n",
    "station_data_view = merged.view()\n",
    "\n",
    "# Submit the application to the service\n",
    "job_submission_result = submit_to_service(topo)\n",
    "\n",
    "if (job_submission_result and job_submission_result.results[\"return_code\"] is 0):\n",
    "    print(\"\\nSubmitted the job to Streaming Analytics service\")\n",
    "else:\n",
    "    print(\"\\nError submitting the job, please see error above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"step23\"></a>\n",
    "### 2.3 View the data in the Streams Console\n",
    "Now that your application is running, you can view the printed output in the Streams console.\n",
    "\n",
    "1. Go to the <a href=\"https://console.bluemix.net/dashboard/\" target=\"_blank\">IBM Cloud dashboard</a>. \n",
    "1. Click your Streaming Analytics service instance.\n",
    "1. Click launch on the service management page. This will open the Streams Console.\n",
    "1. Click the \"Log Viewer\", and look for the application with a name of the form `ipythoninput::TaggedWeatherStations`, and open the **Console Log** as shown below. You can see the output of the application.\n",
    "![ConsoleLog](https://raw.githubusercontent.com/IBMStreams/samples/master/IoT/WeatherStationApp/img/view_log.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n",
    "## 3. Load data\n",
    "\n",
    "You now have a Streams application running and ingesting data, and have seen its output in the Streams console.  But this is just printed data. You can take the output of the Streams application and display it on a Plotly map so you can see which weather stations are malfunctioning. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load31\"></a>\n",
    "### 3.1 Get your Plotly credentials information\n",
    "\n",
    "Now, you can create a map that shows readings from weather stations in real time. This map is created using Plotly. So, if you want to create the visualization, you need to <a href=\"https://plot.ly/accounts/login/?action=signup\" target=\"_blank\">register with Plotly</a> then get the following keys for your Plotly account:\n",
    "- API key  \n",
    "- Streaming API key.\n",
    "\n",
    "Paste that information in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change the values in this cell with your username, api key, stream ids\n",
    "\n",
    "plotly_api_key = 'your_api_key'\n",
    "plotly_stream_ids =['stream_id_1','stream_id_2']\n",
    "plotly_username = 'your_user_name'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load32\"></a>\n",
    "### 3.2 Create Plotly stream  objects using your credentials\n",
    "\n",
    "This cell creates a plotly stream link object called `plotly_data_stream` that is used to update the map with streaming data. The `plotly_stream_id` object is the object that identifies the stream. Both objects require the `plotly_stream_id` you just set above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.graph_objs import *\n",
    "import plotly\n",
    "import plotly.plotly as pty\n",
    "import plotly.tools \n",
    "import plotly.graph_objs as graph_objs\n",
    "\n",
    "\n",
    "#Configure plotly to use your token\n",
    "plotly.tools.set_credentials_file(username=plotly_username, api_key=plotly_api_key, stream_ids=plotly_stream_ids)\n",
    "\n",
    "stream_tokens = plotly.tools.get_credentials_file()['stream_ids']\n",
    "#In this case you just have the one token. If you wanted to graph multiple streams you would have to use multiple tokens.\n",
    "token = stream_tokens[0]   \n",
    "\n",
    "plotly_stream_id = dict(token=token, maxpoints=100)\n",
    "plotly_data_stream = pty.Stream(stream_id=token)\n",
    "\n",
    "\n",
    "def get_trace():\n",
    "    loc_1_lats = [43.722,43.685,43.671,43.677,43.673]\n",
    "    loc_1_lons = [-79.384,-79.474,-79.343,-79.421,-79.345]\n",
    "    loc_2_lats  =[43.870,43.880,43.844750,43.8570,43.830]\n",
    "    loc_2_lons  = [-79.271,-79.362,-79.330,-79.370,-79.310]\n",
    "    loc_ids = [\"loc_\" + str(x) for x in range(20)]\n",
    "    lats = loc_1_lats + loc_2_lats\n",
    "    lons=loc_1_lons+loc_2_lons\n",
    "    trace = Data([\n",
    "        Scattermapbox(lat= lats,lon=lons,\n",
    "            mode='markers+text',\n",
    "            marker=Marker(\n",
    "                size=40,symbol=\"circle\",color=\"royalblue\",\n",
    "            ),ids=loc_ids,hovertext=\"\", text=loc_ids,stream=plotly_stream_id, textfont=dict(size=\"12\",color=\"white\")\n",
    "        )\n",
    "    ])\n",
    "    return trace\n",
    "\n",
    "def get_layout():\n",
    "    layout = Layout(autosize=True, hovermode='closest' ,title=\"Weather Stations\",\n",
    "        mapbox= dict(bearing=0,  pitch=0, zoom=10,\n",
    "            center=dict(lat=43.760859080766361,\n",
    "                        lon=-79.3474682425380699)),\n",
    "    )\n",
    "    return layout\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = dict(data=get_trace(), layout=get_layout())\n",
    "map_url = pty.plot( fig, validate=False, filename='weather_stn_graph', auto_open=False, fileopt='overwrite')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load33\"></a>\n",
    "### 3.3 Fetch and display the sensor data from Streams\n",
    "\n",
    "Now, you can start streaming data from Streams to the map.  The cell below defines a function called `send_data_to_plotly()`. As the name implies, it will retrieve the tagged weather station data from Streams and send it to the Plotly map.\n",
    "\n",
    "Though this function could run indefinitely, you will set it to run only for a few minutes, or you can use the `run_time_in_seconds` parameter to control how many times the data is fetched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "REFRESH_INTERVAL = 0.2 #how often to sleep before retrieving more data from Streams\n",
    "\n",
    "def send_data_to_plotly(streams_view, plotly_map_stream, run_time_in_seconds=60, tag=True):\n",
    "    plotly_map_stream.open() \n",
    "    view_data = streams_view.start_data_fetch()\n",
    "\n",
    "    for i in range(run_time_in_seconds*4):\n",
    "        try:\n",
    "            stations = view_data.get()\n",
    "            #need list of latitudes, longitudes\n",
    "            lats =[]\n",
    "            ids =[]\n",
    "            lons = []\n",
    "            colors = []\n",
    "            labels=[]\n",
    "            #print(stations)\n",
    "            for station in stations:\n",
    "                lats.append(station[\"lat\"])\n",
    "                lons.append(station[\"lon\"])\n",
    "                color =\"royalblue\"\n",
    "               \n",
    "                if tag is True:\n",
    "                    color = \"red\" if station.get(\"outlier\",\"False\") ==\"True\"  else \"seagreen\"\n",
    "                    \n",
    "                colors.append(color)\n",
    "\n",
    "                labels.append(str(round(station[\"temp\"],1)))\n",
    "                s_id = station[\"id\"]\n",
    "                if (color == \"red\"):\n",
    "                    s_id = s_id + \"(Avg = \" + str(station[\"avg\"]) +\")\"\n",
    "                ids.append(s_id)\n",
    "\n",
    "            n = len(stations)\n",
    "           \n",
    "            plotly_map_stream.write(dict(\n",
    "                    lon=lons, lat=lats,\n",
    "                    text=labels, hovertext=ids,type=\"Scattermapbox\" , \n",
    "                    marker={\"opacity\":[1.0]*n,\"size\": [30]*n, \"color\":colors,\"symbol\": [\"circle\"] * n}) )\n",
    "            \n",
    "            time.sleep(REFRESH_INTERVAL)\n",
    "            \n",
    "            if (i % 5) == 0:\n",
    "                sys.stdout.write(\".\")\n",
    "            plotly_map_stream.heartbeat()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "    plotly_map_stream.close()\n",
    "    streams_view.stop_data_fetch()\n",
    "    print(\"\\nDone refreshing map. Re-run this cell to send data to the map again\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embed the map in the notebook\n",
    "\n",
    "Run the next cell to embed the map in the notebook. But no data will display because you have not yet called the  `send_data_to_plotly()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ndsilvaplotly/15.embed\" height=\"800\" width=\"85%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotly.tools.embed(map_url,width=\"85%\",height=800)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `send_data_to_plotly()` function to send tagged station data from Streams to the map. Scroll up to view the map. \n",
    "This cell will run for a few minutes and then stop.  You can re-run the cell to start generating data once it stops, or increase the `run_time_in_seconds` parameter.\n",
    "Re-run the cell to continue updating the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Sending data to map application. Scroll up to view embedded map\")\n",
    "run_time_in_seconds = 180\n",
    "send_data_to_plotly(station_data_view, plotly_data_stream, run_time_in_seconds, tag=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load34\"></a>\n",
    "### 3.4 Troubleshooting\n",
    "If the map is not being updated, verify the following:\n",
    "- The connection to Plot.ly is active. Try re-running <a href=\"#load32\">re-run cell 3.2</a>\n",
    "- The Weather Station simulator application is still running. It stops after 20 minutes. \n",
    "- The Streams applications are running without any errors. Log in to the Streams Console and check that:\n",
    "  - The Python Streams job is running correctly without any errors.  Check the log for errors by opening the Log Viewer,<a href=\"#step23\">as described earlier</a>.\n",
    "  - The `IotPlatform` job is running in your instance. It too runs for an hour.\n",
    "  - The `IotPlatform` job is connected to the `TaggedWeatherStations` application. In the *Streams Graph*, the two applications should be displayed as one application, as shown here:\n",
    "  ![IotPlatform and python job](https://developer.ibm.com/streamsdev/wp-content/uploads/sites/15/2017/11/troubleshooting2.png)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"step4\"></a>\n",
    "## 4. Shutdown\n",
    "\n",
    "Follow these steps when you are done:\n",
    "\n",
    "1. Shutdown the simulator process. By default, it will terminate after 30 minutes.\n",
    "2. Terminate the Streams application by running the cell below.\n",
    "3. Stop the `IotPlatform` job: log in to the Streams Console to cancel it or use the \"Tools\" page of the IoT starter kit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "job = job_submission_result.job\n",
    "if job.cancel():\n",
    "    print(\"Cancelled the Streams application. Run the cells in step 2 to re-submit the application.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 5. Summary and next steps  \n",
    "\n",
    "In this notebook, you created a Streaming Analytics application that analyzed data from IoT devices and visualized the results. The following are helpful resources to learn more:\n",
    "\n",
    "- Learn more about developing Streaming Analytics applications in Python: \n",
    "  - <a href=\"http://ibmstreams.github.io/streamsx.documentation/docs/python/1.6/python-appapi-devguide/\" target=\"_blank\">Consult the Streams Python API Developer Guide</a>.\n",
    "  - Take the <a href=\"https://developer.ibm.com/courses/all/streaming-analytics-basics-python-developers/\" target=\"_blank\">Streaming Analytics for Python developers course</a> on developerWorks.\n",
    "- For more Edgent and IoTP documentation, you can check out the <a href=\"http://edgent.incubator.apache.org/docs/quickstart.html\" target=\"_blank\">Edgent to Quickstart guide</a>.\n",
    "- Visit <a href=\"https://developer.ibm.com/streamsdev/\" target=\"_blank\">Streamsdev, the Streams developer community</a>, for more useful resources about Streams.\n",
    "\n",
    "Happy Streaming!\n",
    "\n",
    "<a id=\"authors\"></a> \n",
    "### Author\n",
    "\n",
    "**Natasha D'Silva** is a software developer at IBM Canada who specializes in streaming technology and cloud solutions.\n",
    "\n",
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2018. This notebook and its source code are released under the terms of the Apache 2.0 License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 2.0",
   "language": "python",
   "name": "python3-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
