{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spark lab, part 3: machine learning\n",
    "\n",
    "In this notebook you'll learn how to create a model for purchase recommendations using the alternating least squares algorithm of the Spark machine learning library. Machine learning is based on algorithms that can learn from data without relying on rules-based programming.  \n",
    "\n",
    "\"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E\"\n",
    "-Tom M. Mitchell\n",
    "\n",
    "This notebook uses pySpark, the Python API for Spark. Some knowledge of Python is recommended. This notebook runs on Python and Spark.\n",
    "\n",
    "If you are new to Spark, see the first two parts of this lab: \n",
    " - <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/95811fca38af4ccbea8acf8658bedcfc\" target=\"_blank\" rel=\"noopener noreferrer\">Introduction to Spark lab, part 1: Basic Concepts</a>\n",
    " - <a href=\"https://dataplatform.cloud.ibm.com/exchange/public/entry/view/5ad1c820f57809ddec9a040e37b2bd55\" target=\"_blank\" rel=\"noopener noreferrer\">Introduction to Spark lab, part 2: Querying data</a>\n",
    "\n",
    "## Spark machine learning library\n",
    "The Spark machine learning library makes practical machine learning scalable and easy. The library consists of common machine learning algorithms and utilities, including classification, regression, clustering, collaborative filtering (this notebook!), dimensionality reduction, lower-level optimization primitives, and higher-level pipeline APIs.\n",
    "\n",
    "The library has two packages:\n",
    "- spark.mllib contains the original API that handles data in RDDs. It's in maintenance mode, but fully supported.\n",
    "- spark.ml contains a newer API for constructing ML pipelines. It handles data in DataFrames. It's being actively enhanced.\n",
    "\n",
    "## Alternating least squares algorithm\n",
    "The alternating least squares (ALS) algorithm provides collaborative filtering between customers and products to find products that the customers might like, based on their previous purchases or ratings.\n",
    "\n",
    "The ALS algorithm creates a matrix of all customers versus all products. Most cells in the matrix are empty, which means the customer hasn't bought that product. The ALS algorithm then fills in the probability of customers buying products that they haven't bought yet, based on similarities between customer purchases and similarities between products. The algorithm uses the least squares computation to minimize the estimation errors, and alternates between fixing the customer factors and solving for product factors and fixing the product factors and solving for customer factors.\n",
    "\n",
    "You don't, however, need to understand how the ALS algorithm works to use it! Spark machine learning algorithms have default values that work well in most cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. [Get the data](#getdata)<br>\n",
    "2. [Prepare and shape the data](#prepare)<br>\n",
    "    2.1 [Format the data](#prepare1)<br>\n",
    "    2.2 [Clean the data](#prepare2)<br>\n",
    "    2.3 [Create a DataFrame](#prepare3)<br>\n",
    "    2.4 [Remove unneeded columns](#prepare4)<br>\n",
    "3. [Split the data into three sets](#split)<br>\n",
    "4. [Build recommendation models](#model)<br>\n",
    "5. [Test the models](#test)<br>\n",
    "    5.1 [Clean the cross validation data set](#test1)<br>\n",
    "    5.2 [Run the models on the cross validation data set](#test2)<br>\n",
    "    5.3 [Calculate the accuracy for each model](#test3)<br>\n",
    "    5.4 [Confirm the best model](#test4)<br>\n",
    "6. [Implement the mode](#implement)<br>\n",
    "    6.1 [Create a DataFrame for the customer and all products](#implement1)<br>\n",
    "    6.2 [Rate each product](#implement2)<br>\n",
    "    6.3 [Find the top recommendations](#implement3)<br>\n",
    "    6.4 [Compare purchased and recommended products](#implement4)<br>\n",
    "7. [Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"getdata\"></a>\n",
    "## 1. Get the data \n",
    "The data set contains the transactions of an online retailer of gift items for the period from 01/12/2010 to 09/12/2011. Many of the customers are wholesalers.\n",
    "\n",
    "You'll be using a slightly modified version of UCI's <a href=\"http://archive.ics.uci.edu/ml/datasets/Online+Retail\" target=\"_blank\" rel=\"noopener noreferrer\">Online Retail Data Set</a>.  \n",
    "\n",
    "Here's a glimpse of the data:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/FullFile.png' width=\"80%\" height=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the CSV version of the data set, from which commas in the product descriptions are removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for a Spark session to start...\n",
      "Spark Initialization Done! ApplicationId = app-20190527201552-0001\n",
      "KERNEL_ID = 99334292-0b37-459c-b178-6fc5e5b202e2\n",
      "--2019-05-27 20:15:57--  https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/OnlineRetail.csv.gz\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.48.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.48.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7483128 (7.1M) [application/octet-stream]\n",
      "Saving to: 'OnlineRetail.csv.gz'\n",
      "\n",
      "OnlineRetail.csv.gz 100%[===================>]   7.14M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2019-05-27 20:15:57 (73.8 MB/s) - 'OnlineRetail.csv.gz' saved [7483128/7483128]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm 'OnlineRetail.csv.gz' -f\n",
    "!wget https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/OnlineRetail.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the data into an RDD and print the first 5 rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country\n",
      "536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/10 8:26,2.55,17850,United Kingdom\n",
      "536365,71053,WHITE METAL LANTERN,6,12/1/10 8:26,3.39,17850,United Kingdom\n",
      "536365,84406B,CREAM CUPID HEARTS COAT HANGER,8,12/1/10 8:26,2.75,17850,United Kingdom\n",
      "536365,84029G,KNITTED UNION FLAG HOT WATER BOTTLE,6,12/1/10 8:26,3.39,17850,United Kingdom\n"
     ]
    }
   ],
   "source": [
    "loadRetailData = sc.textFile(\"OnlineRetail.csv.gz\")\n",
    "\n",
    "for row in loadRetailData.take(5):\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the RDD is a string that correlates to a line in the CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare\"></a>\n",
    "## 2. Prepare and shape the data\n",
    "\n",
    "It's been said that preparing and shaping data is 80% of a data scientist's job. Having the right data in the right format is critical for getting accurate results.\n",
    "\n",
    "To get the data ready, complete these tasks:\n",
    "\n",
    "1. [Format the data](#prepare1)\n",
    "1. [Clean the data](#prepare2)\n",
    "1. [Create a DataFrame](#prepare3)\n",
    "1. [Remove unneeded columns](#prepare4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare1\"></a>\n",
    "### 2.1 Format the data\n",
    "Remove the header from the RDD and split the string in each row with a comma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['536365', '85123A', 'WHITE HANGING HEART T-LIGHT HOLDER', '6', '12/1/10 8:26', '2.55', '17850', 'United Kingdom']\n",
      "['536365', '71053', 'WHITE METAL LANTERN', '6', '12/1/10 8:26', '3.39', '17850', 'United Kingdom']\n",
      "['536365', '84406B', 'CREAM CUPID HEARTS COAT HANGER', '8', '12/1/10 8:26', '2.75', '17850', 'United Kingdom']\n",
      "['536365', '84029G', 'KNITTED UNION FLAG HOT WATER BOTTLE', '6', '12/1/10 8:26', '3.39', '17850', 'United Kingdom']\n",
      "['536365', '84029E', 'RED WOOLLY HOTTIE WHITE HEART.', '6', '12/1/10 8:26', '3.39', '17850', 'United Kingdom']\n"
     ]
    }
   ],
   "source": [
    "header = loadRetailData.first()\n",
    "loadRetailData = loadRetailData.filter(lambda line: line != header).\\\n",
    "                            map(lambda l: l.split(\",\"))\n",
    "\n",
    "for row in loadRetailData.take(5):\n",
    "    print (row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare2\"></a>\n",
    "### 2.2 Clean the data\n",
    "Remove the rows that have incomplete data. Keep only the rows that meet the following criteria:\n",
    " - The purchase quantity is greater than 0 \n",
    " - The customer ID not equal to 0 \n",
    " - The stock code is not blank after you remove non-numeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['536365', '85123A', 'WHITE HANGING HEART T-LIGHT HOLDER', '6', '12/1/10 8:26', '2.55', '17850', 'United Kingdom'], ['536365', '71053', 'WHITE METAL LANTERN', '6', '12/1/10 8:26', '3.39', '17850', 'United Kingdom']]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "loadRetailData = loadRetailData.filter(lambda l: int(l[3]) > 0\\\n",
    "                                and len(re.sub(\"\\D\", \"\", l[1])) != 0 \\\n",
    "                                and len(l[6]) != 0)\n",
    "\n",
    "print (loadRetailData.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare3\"></a>\n",
    "### 2.3 Create a DataFrame\n",
    "\n",
    "First, create an SQLContext and map each line to a row: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, Row\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#Convert each line to a Row.\n",
    "loadRetailData = loadRetailData.map(lambda l: Row(inv=int(l[0]),\\\n",
    "                                    stockCode=int(re.sub(\"\\D\", \"\", l[1])),\\\n",
    "                                    description=l[2],\\\n",
    "                                    quant=int(l[3]),\\\n",
    "                                    invDate=l[4],\\\n",
    "                                    price=float(l[5]),\\\n",
    "                                    custId=int(l[6]),\\\n",
    "                                    country=l[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a DataFrame and show the inferred schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- country: string (nullable = true)\n",
      " |-- custId: long (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- inv: long (nullable = true)\n",
      " |-- invDate: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- quant: long (nullable = true)\n",
      " |-- stockCode: long (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "retailDf = sqlContext.createDataFrame(loadRetailData)\n",
    "print (retailDf.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the DataFrame as a table so that you can run SQL queries on it and show the first two rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>custId</th>\n",
       "      <th>description</th>\n",
       "      <th>inv</th>\n",
       "      <th>invDate</th>\n",
       "      <th>price</th>\n",
       "      <th>quant</th>\n",
       "      <th>stockCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>536365</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>6</td>\n",
       "      <td>85123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>17850</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>536365</td>\n",
       "      <td>12/1/10 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>6</td>\n",
       "      <td>71053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country  custId                         description     inv  \\\n",
       "0  United Kingdom   17850  WHITE HANGING HEART T-LIGHT HOLDER  536365   \n",
       "1  United Kingdom   17850                 WHITE METAL LANTERN  536365   \n",
       "\n",
       "        invDate  price  quant  stockCode  \n",
       "0  12/1/10 8:26   2.55      6      85123  \n",
       "1  12/1/10 8:26   3.39      6      71053  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retailDf.registerTempTable(\"retailPurchases\")\n",
    "sqlContext.sql(\"SELECT * FROM retailPurchases limit 2\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"prepare4\"></a>\n",
    "### 2.4 Remove unneeded columns\n",
    "The only columns you need are `custId`, `stockCode`, and a new column, `purch`, which has a value of 1 to indicate that the customer purchased the product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>custId</th>\n",
       "      <th>stockCode</th>\n",
       "      <th>purch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18074</td>\n",
       "      <td>22224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13705</td>\n",
       "      <td>21889</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15862</td>\n",
       "      <td>22441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15862</td>\n",
       "      <td>21592</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12838</td>\n",
       "      <td>22739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12838</td>\n",
       "      <td>22149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14078</td>\n",
       "      <td>22548</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14078</td>\n",
       "      <td>22423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12433</td>\n",
       "      <td>21977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14696</td>\n",
       "      <td>84360</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   custId  stockCode  purch\n",
       "0   18074      22224      1\n",
       "1   13705      21889      1\n",
       "2   15862      22441      1\n",
       "3   15862      21592      1\n",
       "4   12838      22739      1\n",
       "5   12838      22149      1\n",
       "6   14078      22548      1\n",
       "7   14078      22423      1\n",
       "8   12433      21977      1\n",
       "9   14696      84360      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    custId, stockCode, 1 as purch\n",
    "FROM \n",
    "    retailPurchases \n",
    "group \n",
    "    by custId, stockCode\"\"\"\n",
    "retailDf = sqlContext.sql(query)\n",
    "retailDf.registerTempTable(\"retailDf\")\n",
    "\n",
    "sqlContext.sql(\"select * from retailDf limit 10\").toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"split\"></a>\n",
    "## 3. Split the data into three sets\n",
    "You'll split the data into three sets: \n",
    " - a testing data set (10% of the data)\n",
    " - a cross-validation data set (10% of the data)\n",
    " - a training data set (80% of the data)\n",
    "\n",
    "Split the data randomly and create a DataFrame for each data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainDf count:  208123  example: \n",
      "Row(custId=12359, stockCode=23345, purch=1)\n",
      "Row(custId=12363, stockCode=20685, purch=1)\n",
      "\n",
      "cvDf count:  25876  example: \n",
      "Row(custId=12349, stockCode=23545, purch=1)\n",
      "Row(custId=12388, stockCode=22960, purch=1)\n",
      "\n",
      "testDf count:  26113  example: \n",
      "Row(custId=12362, stockCode=22372, purch=1)\n",
      "Row(custId=12391, stockCode=20985, purch=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDf, cvDf, trainDf = retailDf.randomSplit([.1,.1,.8],1)\n",
    "\n",
    "print (\"trainDf count: \", trainDf.count(), \" example: \")\n",
    "for row in trainDf.take(2): print (row)\n",
    "print ()\n",
    "\n",
    "print (\"cvDf count: \", cvDf.count(), \" example: \")\n",
    "for row in cvDf.take(2): print (row)\n",
    "print ()\n",
    "\n",
    "print (\"testDf count: \", testDf.count(), \" example: \")\n",
    "for row in testDf.take(2): print (row)\n",
    "print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "## 4. Build recommendation models\n",
    "Machine learning algorithms have standard parameters and hyperparameters. Standard parameters specify data and options. Hyperparameters control the performance of the algorithm.\n",
    "\n",
    "The ALS algorithm has these hyperparameters:  \n",
    "\n",
    " - The `rank` hyperparameter represents the number of features. The default value of `rank` is 10.\n",
    " - The `maxIter` hyperparameter represents the number of iterations to run the least squares computation. The default value of `maxIter` is 10.\n",
    "\n",
    "Use the training DataFrame to train three models with the ALS algorithm with different values for the `rank` and `maxIter` hyperparameters. Assign the `userCol`, `itemCol`, and `ratingCol` parameters to the appropriate data columns. Set the `implicitPrefs` parameter to `true` so that the algorithm can predict latent factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The models are trained\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "als1 = ALS(rank=3, maxIter=15,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"purch\",implicitPrefs=True)\n",
    "model1 = als1.fit(trainDf)\n",
    "\n",
    "als2 = ALS(rank=15, maxIter=3,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"purch\",implicitPrefs=True)\n",
    "model2 = als2.fit(trainDf)\n",
    "\n",
    "als3 = ALS(rank=15, maxIter=15,userCol=\"custId\",itemCol=\"stockCode\",ratingCol=\"purch\",implicitPrefs=True)\n",
    "model3 = als3.fit(trainDf)\n",
    "\n",
    "print (\"The models are trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test\"></a>\n",
    "## 5. Test the models\n",
    "\n",
    "First, test the three models on the cross-validation data set, and then on the testing data set. \n",
    "\n",
    "You'll know the model is accurate when the prediction values for products that the customers have already bought are close to 1. \n",
    "\n",
    "<a id=\"test1\"></a>\n",
    "### 5.1 Clean the cross validation data set\n",
    "\n",
    "Remove any of the customers or products in the cross-validation data set that are not in the training data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25876\n",
      "25846\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import BooleanType\n",
    "customers = set(trainDf.rdd.map(lambda line: line.custId).collect())\n",
    "stock = set(trainDf.rdd.map(lambda line: line.stockCode).collect())\n",
    "\n",
    "print (cvDf.count())\n",
    "cvDf = cvDf.rdd.filter(lambda line: line.stockCode in stock and\\\n",
    "                                           line.custId in customers).toDF()\n",
    "print (cvDf.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test2\"></a>\n",
    "### 5.2 Run the models on the cross-validation data set\n",
    "Run the model with the cross-validation DataFrame by using the `transform` function and print the first two rows of each set of predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(custId=14606, stockCode=20735, purch=1, prediction=0.02294829487800598), Row(custId=16464, stockCode=20735, purch=1, prediction=0.00998256541788578)]\n",
      "[Row(custId=14606, stockCode=20735, purch=1, prediction=0.0441482812166214), Row(custId=16464, stockCode=20735, purch=1, prediction=0.004716672468930483)]\n",
      "[Row(custId=14606, stockCode=20735, purch=1, prediction=0.10467907041311264), Row(custId=16464, stockCode=20735, purch=1, prediction=0.0019032559357583523)]\n"
     ]
    }
   ],
   "source": [
    "predictions1 = model1.transform(cvDf)\n",
    "predictions2 = model2.transform(cvDf)\n",
    "predictions3 = model3.transform(cvDf)\n",
    "\n",
    "print (predictions1.take(2))\n",
    "print (predictions2.take(2))\n",
    "print (predictions3.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test3\"></a>\n",
    "### 5.3 Calculate the accuracy for each model  \n",
    "\n",
    "You'll use the mean squared error calculation to determine accuracy by comparing the prediction values for products to the actual purchase values. Remember that if a customer purchased a product, the value in the `purch` column is 1. The mean squared error calculation measures the average of the squares of the errors between what is estimated and the existing data. The lower the mean squared error value, the more accurate the model. \n",
    "\n",
    "For all predictions, subtract the prediction from the actual purchase value (1), square the result, and calculate the mean of all of the squared differences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 0.7393 for our first model\n",
      "Mean squared error = 0.7011 for our second model\n",
      "Mean squared error = 0.6683 for our third model\n"
     ]
    }
   ],
   "source": [
    "meanSquaredError1 = predictions1.rdd.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "meanSquaredError2 = predictions2.rdd.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "meanSquaredError3 = predictions3.rdd.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "    \n",
    "print ('Mean squared error = %.4f for our first model' % meanSquaredError1)\n",
    "print ('Mean squared error = %.4f for our second model' % meanSquaredError2)\n",
    "print ('Mean squared error = %.4f for our third model' % meanSquaredError3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third model (model3) has the lowest mean squared error value, so it's the most accurate.\n",
    "\n",
    "Notice that of the three models, model3 has the highest values for the hyperparameters. At this point you might be tempted to run the model with even higher values for `rank` and `maxIter`. However, you might not get better results. Increasing the values of the hyperparameters increases the time for the model to run. Also, you don't want to overfit the model so that it exactly fits the original data. In that case, you wouldn't get any recommendations! For best results, keep the values of the hyperparameters close to the defaults.\n",
    "\n",
    "<a id=\"test4\"></a>\n",
    "### 5.4 Confirm the best model \n",
    "\n",
    "Now run model3 on the testing data set to confirm that it's the best model. You want to make sure that the model is not over-matched to the cross-validation data. It's possible for a model to match one subset of the data well but not another. If the values of the mean squared error for the testing data set and the cross-validation data set are close, then you've confirmed that the model works for all the data.\n",
    "\n",
    "Clean the testing data set, run model3 on the testing data set, and calculate the mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error = 0.6693 for our best model\n"
     ]
    }
   ],
   "source": [
    "filteredTestDf = testDf.rdd.filter(lambda line: line.stockCode in stock and\\\n",
    "                                              line.custId in customers).toDF()\n",
    "predictions4 = model3.transform(filteredTestDf)\n",
    "meanSquaredError4 = predictions4.rdd.map(lambda line: (line.purch - line.prediction)**2).mean()\n",
    "    \n",
    "print ('Mean squared error = %.4f for our best model' % meanSquaredError4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty close. The model works for all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"implement\"></a>\n",
    "## 6. Implement the model\n",
    "\n",
    "Use the best model to predict which products a specific customer might be interested in purchasing.\n",
    "\n",
    "<a id=\"implement1\"></a>\n",
    "### 6.1 Create a DataFrame for the customer and all products \n",
    "\n",
    "Create a DataFrame in which each row has the customer ID (15544) and a product ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21899 15544\n",
      "22429 15544\n",
      "22201 15544\n",
      "22165 15544\n",
      "21209 15544\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "stock15544 = set(trainDf.filter(trainDf['custId'] == 15544).rdd.map(lambda line: line.stockCode).collect())\n",
    "\n",
    "userItems = trainDf.select(\"stockCode\").distinct().\\\n",
    "            withColumn('custId', lit(15544)).\\\n",
    "            rdd.filter(lambda line: line.stockCode not in stock15544).toDF()\n",
    "\n",
    "for row in userItems.take(5):\n",
    "    print (row.stockCode, row.custId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"implement2\"></a>\n",
    "### 6.2 Rate each product\n",
    "\n",
    "Run the `transform` function to create a prediction value for each product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20735 15544 0.003406377974897623\n",
      "21220 15544 0.06270085275173187\n",
      "21700 15544 0.05252227559685707\n",
      "22097 15544 -0.025320032611489296\n",
      "22223 15544 0.02550472691655159\n"
     ]
    }
   ],
   "source": [
    "userItems = model3.transform(userItems)\n",
    "\n",
    "for row in userItems.take(5):\n",
    "    print (row.stockCode, row.custId, row.prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"implement3\"></a>\n",
    "### 6.3 Find the top recommendations\n",
    "\n",
    "Print the top five product recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockCode</th>\n",
       "      <th>custId</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21242</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.573960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22417</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.531522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21987</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.508154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22367</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.497426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21122</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.494572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stockCode  custId  prediction\n",
       "0      21242   15544    0.573960\n",
       "1      22417   15544    0.531522\n",
       "2      21987   15544    0.508154\n",
       "3      22367   15544    0.497426\n",
       "4      21122   15544    0.494572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userItems.registerTempTable(\"predictions\")\n",
    "query = \"select * from predictions order by prediction desc limit 5\"\n",
    "\n",
    "sqlContext.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"implement4\"></a>\n",
    "### 6.4 Compare purchased and recommended products\n",
    "\n",
    "Here's a view of the products that customer 15544 bought:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/rosswlewis/RecommendationPoT/master/user.png' width=\"80%\" height=\"80%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This customer bought lots of children's gifts and some holiday items. \n",
    "\n",
    "Look at the descriptions of the recommended products to see if they are in the same categories.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">Note: The ALS algorithm uses some randomness, so the recommendations you get might be different from these.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockCode</th>\n",
       "      <th>custId</th>\n",
       "      <th>prediction</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21242</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.573960</td>\n",
       "      <td>RED RETROSPOT PLATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22417</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.531522</td>\n",
       "      <td>PACK OF 60 SPACEBOY CAKE CASES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21987</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.508154</td>\n",
       "      <td>PACK OF 6 SKULL PAPER CUPS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22367</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.497426</td>\n",
       "      <td>CHILDRENS APRON SPACEBOY DESIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21122</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.494572</td>\n",
       "      <td>SET/10 PINK POLKADOT PARTY CANDLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22326</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.486443</td>\n",
       "      <td>ROUND SNACK BOXES SET OF4 WOODLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21975</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.485125</td>\n",
       "      <td>PACK OF 60 DINOSAUR CAKE CASES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>22554</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.477713</td>\n",
       "      <td>PLASTERS IN TIN WOODLAND ANIMALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21559</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.474228</td>\n",
       "      <td>STRAWBERRY LUNCH BOX WITH CUTLERY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21124</td>\n",
       "      <td>15544</td>\n",
       "      <td>0.472176</td>\n",
       "      <td>SET/10 BLUE POLKADOT PARTY CANDLES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stockCode  custId  prediction                          description\n",
       "0      21242   15544    0.573960                 RED RETROSPOT PLATE \n",
       "1      22417   15544    0.531522       PACK OF 60 SPACEBOY CAKE CASES\n",
       "2      21987   15544    0.508154           PACK OF 6 SKULL PAPER CUPS\n",
       "3      22367   15544    0.497426      CHILDRENS APRON SPACEBOY DESIGN\n",
       "4      21122   15544    0.494572   SET/10 PINK POLKADOT PARTY CANDLES\n",
       "5      22326   15544    0.486443  ROUND SNACK BOXES SET OF4 WOODLAND \n",
       "6      21975   15544    0.485125       PACK OF 60 DINOSAUR CAKE CASES\n",
       "7      22554   15544    0.477713     PLASTERS IN TIN WOODLAND ANIMALS\n",
       "8      21559   15544    0.474228    STRAWBERRY LUNCH BOX WITH CUTLERY\n",
       "9      21124   15544    0.472176   SET/10 BLUE POLKADOT PARTY CANDLES"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockItems = sqlContext.sql(\"select distinct stockCode, description from retailPurchases\")\n",
    "stockItems.registerTempTable(\"stockItems\")\n",
    "\n",
    "query = \"\"\"\n",
    "select \n",
    "    predictions.*,\n",
    "    stockItems.description\n",
    "from\n",
    "    predictions\n",
    "inner join stockItems on\n",
    "    predictions.stockCode = stockItems.stockCode\n",
    "order by predictions.prediction desc\n",
    "limit 10\n",
    "\"\"\"\n",
    "sqlContext.sql(query).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recommended products look pretty similar to the purchased products, and, in some cases, are actually the same. Your model works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"summary\"></a>\n",
    "## 7. Summary and next steps\n",
    "You created a predictive model that makes product recommendations for customers and verified that it works.\n",
    "\n",
    "Dig deeper:\n",
    " - <a href=\"http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html\" target=\"_blank\" rel=\"noopener noreferrer\">Collaborative Filtering</a>\n",
    " - <a href=\"http://spark.apache.org/docs/latest/ml-guide.html\" target=\"_blank\" rel=\"noopener noreferrer\">Spark Machine Learning Library (MLlib) Guide</a>\n",
    " - <a href=\"http://spark.apache.org/docs/latest/api/python/index.html\" target=\"_blank\" rel=\"noopener noreferrer\">Spark Python API Docs</a>\n",
    "\n",
    "\n",
    "### Authors\n",
    "**Carlo Appugliese** is a Spark and Hadoop evangelist at IBM.<br>\n",
    "**Braden Callahan** is a Big Data Technical Specialist for IBM.<br>\n",
    "**Ross Lewis** is a Big Data Technical Sales Specialist for IBM.<br>\n",
    "**Mokhtar Kandil** is a World Wide Big Data Technical Specialist for IBM.\n",
    "\n",
    "\n",
    "## Data citation\n",
    "Daqing Chen, Sai Liang Sain, and Kun Guo, Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining, Journal of Database Marketing and Customer Strategy Management, Vol. 19, No. 3, pp. 197-208, 2012 (Published online before print: 27 August 2012. doi: 10.1057/dbm.2012.17).\n",
    "\n",
    "Chen, D. (2012). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<hr>\n",
    "Copyright &copy; IBM Corp. 2017-2019. This notebook and its source code are released under the terms of the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:100px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Want to do more?</span><span style=\"border: 1px solid #3d70b2;padding: 15px;float:right;margin-right:40px; color:#3d70b2; \"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "<span style=\"color:#5A6872;\"> Try out this notebook with your free trial of IBM Watson Studio.</span>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 with Spark",
   "language": "python3",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
