{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background:#F5F7FA; height:100px; padding: 2em; font-size:14px;\">\n",
    "<span style=\"font-size:18px;color:#152935;\">Want to do more?</span><span style=\"border: 1px solid #3d70b2;padding: 15px;float:right;margin-right:40px; color:#3d70b2; \"><a href=\"https://ibm.co/wsnotebooks\" target=\"_blank\" style=\"color: #3d70b2;text-decoration: none;\">Sign Up</a></span><br>\n",
    "<span style=\"color:#5A6872;\"> Try out this notebook with your free trial of IBM Watson Studio.</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=\"https://www.ibm.com/blogs/bluemix/wp-content/uploads/2017/02/NLU.png\", width=270, height=270, align = 'right'> \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/IBM_logo.svg/640px-IBM_logo.svg.png\", width = 90, height = 90, align = 'right', style=\"margin:0px 25px\"></div>\n",
    "\n",
    "# Retrieve DataFrames to visualize data from IBM Watson Natural Language Understanding\n",
    "\n",
    "In this R notebook, you'll use IBM Watson Natural Language Understanding (NLU) to analyze keywords from the websites of the Fortune 100 companies. You'll convert the results of NLU into a set of R DataFrames that you can easily analyze in a notebook. Then you'll create a visual representation of the keywords. \n",
    "\n",
    "Data scientists use NLU to uncover insights about sentiment and emotion from structured and unstructured data and to analyze text to extract metadata, such as concepts, entities, keywords, categories, relations, and semantic roles. NLU returns both the overall sentiment and emotion for the whole document and the specific sentiment and emotion for each of the keywords in the text, for deeper analysis.\n",
    "\n",
    "To start with that tutorial, see [Visualize a customer base with Watson NLU](#visualize). To read a little more about the technology and some of the other fun things you can do, see [Getting personal about Watson Natural Language Understanding](#about) and [Using R & Watson NLU](#using_r). \n",
    "\n",
    "This notebook runs on R and Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1.  [Getting personal about Watson Natural Language Understanding](#about)<br>\n",
    "    1.1  [What data do we get from Watson NLU?](#what_data)\n",
    "\n",
    "2.  [Using R & Watson NLU](#using_r)<br>\n",
    "    2.1  [Using the `httr` and `jsonlite` packages](#httr)<br>\n",
    "    2.2  [Functional access to Watson NLU](#functiondetails) <br>\n",
    "    2.3  [Understand the `watsonNLUtoDF()` package](#watsonnlutodf)<br>\n",
    "\n",
    "3.  [Visualize a customer base with Watson NLU](#visualize)<br>\n",
    "    3.1  [Load the customer data](#visualize1) <br>\n",
    "    3.2  [Shape the data for the NLU function](#visualize2)<br>\n",
    "    3.3  [Send customersDF to Watson](#visualize3)<br>\n",
    "    3.4  [Concatenate the concepts and keywords extracted from Watson](#visualize4)<br>\n",
    "    3.5  [Format the Text for a Word Cloud](#visualize5)<br>\n",
    "    3.6  [Visualize with the Brunel library](#visualize6)<br>\n",
    "\n",
    "[Summary and next steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='about'></a>\n",
    "## 1. Getting personal about Watson Natural Language Understanding \n",
    "\n",
    "The first time I tested Watson NLU a huge grin spread across my face. For me it was one another one of those moments where technology inspired awe - sort of like when I played my first PC game as a kid in 1990 or when I saw the iPhone in 2006.  So what exactly is Watson NLU? \n",
    "\n",
    "> *With a sophisticated suite of natural language processing capabilities, NLU can analyze text and extract meta-data from unstructured content such as concepts, entities, keywords, categories, sentiment, emotion, relations, semantic roles. You can also customize the text analysis with NLU for linguistic nuances specific to your domain or industry (such as entities and relations) with custom models developed using Watson Knowledge Studio. With customization, you can further improve the accuracy of meta-data extraction. Whether it is social media monitoring, content recommendation, or advertising optimization, NLU can be easily put to use for extracting the hard to find insights from unstructured content.*  \n",
    "\n",
    "> Source: __[IBM Cloud Blog](https://www.ibm.com/blogs/bluemix/2017/02/hello-nlu/)__\n",
    "\n",
    "In other words, the NLU service allows you to send unstructured data to Watson and have it return a rich set of structured data.  For example, you can send Watson a block of text and it will understand the information contained therein. Alternatively, you can send a URL and extract all the information from it.\n",
    "\n",
    "Ok, sounds kinda cool, but what's the 'wow' factor?  Read on.\n",
    "\n",
    "<a id='what_data'></a>\n",
    "### 1.1 What data do we get from Watson NLU?\n",
    "\n",
    "The easiest way to get a sense of what NLU does is to __[try the demo](https://natural-language-understanding-demo.mybluemix.net/)__.  So, go there and come back after you've played around with submitting different URLs and text to the service.  \n",
    "\n",
    "Back?  Are you impressed yet?  You must be!  As you saw, we get detailed information about the concepts, sentiment, and categorization of the data we send to Watson.  \n",
    "\n",
    "<a id='using_r'></a>\n",
    "## 2. Using R and Watson NLU\n",
    "\n",
    "I wanted to work with the data from NLU in R but there didn't seem to be many resources available online.  Rather than work directly with the JSON returned by the service, I decided to write a function - `watsonNLUtoDF()` - that converts NLU results from JSON into a list of R DataFrames.  To do so, I had to use two excellent R packages.\n",
    "\n",
    "<a id='httr'></a>\n",
    "### 2.1 The `httr` and `jsonlite` packages\n",
    "\n",
    "The `httr` package is one of the many packages for R that is written by Hadley Wickham. It provides access to `curl` functionality from inside of R, and its simplicity is classic Hadley. For example, if to run `POST()` or `GET()` using a URL is easy. You must include authentication and JSON-structured data in the `POST()` to Watson NLU:\n",
    "\n",
    "> `> POST(URL, authenticate(username, password), body = toJSON(list(features)))`\n",
    "\n",
    "You'll notice the `toJSON()` function in there.  That comes from the `jsonlite` package, which offers excellent support for converting R objects to and from JSON.  As you can see this came in handy when I needed to send JSON to Watson NLU.  It is also essential in parsing the response from Watson into R DataFrames. \n",
    "\n",
    "These two packages let me access Watson NLU from R, but I still needed a way to access the API in a more programmatic, scalable fashion. That's why I wrote the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='functiondetails'></a>\n",
    "### 2.2 Functional access to Watson NLU\n",
    "\n",
    "You need to define the function to access NLU and understand its usage and arguments. You can skip ahead and look at the [function documentation](#watsonnlutodf). But before you can run the function, you need to get NLU credentials and import packages.\n",
    "\n",
    "Sign up for NLU and add your NLU credentials:\n",
    "1. Create a service for [Natural Language Understanding (NLU)](https://www.ibm.com/watson/developercloud/natural-language-understanding.html). \n",
    "1. Insert the username and password values for your NLU service in the following cell. \n",
    "1. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@hidden_cell\n",
    "# Add your Watson Natural Language Understanding service credentials\n",
    "username <- \"***\"\n",
    "password <- \"***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook uses version 2.3 of Brunel. If the version changes in the future, the visualization may not work and you will need \n",
    "# to update the version number in the code. \n",
    " \n",
    "install.packages('tm')\n",
    "install.packages(\"devtools\")\n",
    "devtools::install_github(\"Brunel-Visualization/Brunel\", subdir=\"R\", ref=\"v2.3\", force=TRUE)\n",
    "library(brunel)\n",
    "library(tm)\n",
    "library(httr)\n",
    "library(jsonlite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function to retrieve DataFrames from the Watson API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "watsonNLUtoDF <- function(data, username, password, verbose = F, language = 'en') {\n",
    "  \n",
    "  ## Url for Watson NLU service on IBM Cloud used to POST (send) content to the service to have it analyzed.  \n",
    "  ## For more details: https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#post-analyze \n",
    "  base_url <- \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze?version=2017-02-27\"\n",
    "  \n",
    "    ## Initialize Empty DataFrames\n",
    "  conceptsDF <- data.frame()\n",
    "  keywordsDF <- data.frame()\n",
    "  sentimentDF <- data.frame()\n",
    "  categoriesDF <- data.frame()\n",
    "  analyzedTextDF <- data.frame()\n",
    "  \n",
    "  ## Loop over each id, identify the type and send the value to Watson\n",
    "  for (i in 1:nrow(data)){\n",
    "    try({\n",
    "      \n",
    "      id <- data$id[i]\n",
    "      value <- data$value[i]\n",
    "      \n",
    "      ## Define the JSON payload for NLU\n",
    "      body <- list(api_endpoint = value, \n",
    "                   features = list(\n",
    "                     categories = {},\n",
    "                     concepts = {},\n",
    "                     keywords = {},\n",
    "                     sentiment = {}),\n",
    "                   language = language,\n",
    "                   return_analyzed_text = TRUE)\n",
    "      \n",
    "      ## Provide the correct type for each id\n",
    "      names(body)[1] <- data$type[i]\n",
    "      \n",
    "      if(verbose == T){\n",
    "      print(paste(\"Sending\", data$type[i], \"for\", id, \"to Watson NLU...\"))\n",
    "      }\n",
    "      \n",
    "      ## Hit the API and return JSON\n",
    "      watsonResponse <- POST(base_url,\n",
    "                             content_type_json(),\n",
    "                             authenticate(username, password, type = \"basic\"),\n",
    "                             body = toJSON(body, auto_unbox = T)) \n",
    "\n",
    "        ## Parse JSON into DataFrames\n",
    "      concepts <- data.frame(id = id, \n",
    "                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$concepts,\n",
    "                             stringsAsFactors = F)\n",
    "\n",
    "      keywords <- data.frame(id = id, \n",
    "                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$keywords,\n",
    "                             stringsAsFactors = F)\n",
    "      \n",
    "      sentiment <- data.frame(id = id, \n",
    "                             fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$sentiment,\n",
    "                             stringsAsFactors = F)\n",
    "      \n",
    "      categories <- data.frame(id = id,\n",
    "                               fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$categories,\n",
    "                               stringsAsFactors = F)\n",
    "      \n",
    "      analyzedText <- data.frame(id = id,\n",
    "                                 fromJSON(toJSON(content(watsonResponse), pretty = T), flatten = T)$analyzed_text,\n",
    "                                 stringsAsFactors = F)\n",
    "      \n",
    "      \n",
    "      ## Append results to output DataFrames\n",
    "      conceptsDF <- rbind(conceptsDF, concepts)\n",
    "      keywordsDF <- rbind(keywordsDF, keywords)\n",
    "      sentimentDF <- rbind(sentimentDF, sentiment)\n",
    "      categoriesDF <- rbind(categoriesDF, categories)\n",
    "      analyzedTextDF <- rbind(analyzedTextDF, analyzedText)\n",
    "      \n",
    "      if(verbose == T) {\n",
    "      print(paste(\"Iteration\", i, \"of\", nrow(data), \"complete.\"))\n",
    "      }\n",
    "    })\n",
    "  }\n",
    "  resultsList <- list(conceptsDF, keywordsDF, sentimentDF, categoriesDF, analyzedTextDF, watsonResponse)\n",
    "  names(resultsList) <- c(\"conceptsDF\", \"keywordsDF\", \"sentimentDF\", \"categoriesDF\", \"analyzedTextDF\", \"response\")\n",
    "  return(resultsList)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='watsonnlutodf'></a>\n",
    "### 2.3 Understand the `watsonNLUtoDF()` function\n",
    "\n",
    "#### Usage\n",
    " > `watsonNLUtoDF(data, username, password, verbose = F, language = 'en')`\n",
    "\n",
    "#### Arguments\n",
    " > - **data:** *DataFrame* with 3 columns: \n",
    "     - `id` *(string)* \n",
    "     - `type` *(string)*, must be one of `url` or `text` - think of this as which API endpoint you want to submit to. \n",
    "     - `value` *(string)*, contains the data you want to send.\n",
    "     \n",
    " > * **username:** *string*.  User name for the NLU service on Bluemix.\n",
    " \n",
    " > * **password:** *string*.  Password for the NLU service on Bluemix.\n",
    " \n",
    " > * **verbose**: *boolean*.  Print messages showing progress. Defaults to `F`.\n",
    " \n",
    " > * **language**: *string*.  Default is English. [See the API docs](https://www.ibm.com/watson/developercloud/doc/natural-language-understanding/#supported-languages) for available options.\n",
    " \n",
    "#### Value\n",
    "\n",
    " > A *list* of five dataframes extracted from the service:\n",
    "     1. conceptsDF\n",
    "     2. keywordsDF\n",
    "     3. sentimentDF\n",
    "     4. categoriesDF\n",
    "     5. analyzedTextDF\n",
    "  \n",
    "#### Example:\n",
    "Create a DataFrame with `id`, `type`, and `value` columns that contains a row with a URL and a row with text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>type</th><th scope=col>value</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Seattle Seahawks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         </td><td>www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td></tr>\n",
       "\t<tr><td>Seattle Sounders                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td>text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </td><td>From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n",
       "                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n",
       "                           Major League Soccer (MLS) and are the league's current defending champions, having won\n",
       "                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n",
       "                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n",
       "                           Sounders name being part of a legacy which traces back to the original team of the NASL\n",
       "                           in 1974.</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " id & type & value\\\\\n",
       "\\hline\n",
       "\t Seattle Seahawks                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             & url                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          & www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \\\\\n",
       "\t Seattle Sounders                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             & text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         & From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n",
       "                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n",
       "                           Major League Soccer (MLS) and are the league's current defending champions, having won\n",
       "                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n",
       "                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n",
       "                           Sounders name being part of a legacy which traces back to the original team of the NASL\n",
       "                           in 1974.\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  id               type\n",
       "1 Seattle Seahawks url \n",
       "2 Seattle Sounders text\n",
       "  value                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "1 www.seahawks.com                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "2 From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \\n                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \\n                           Major League Soccer (MLS) and are the league's current defending champions, having won\\n                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\\n                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \\n                           Sounders name being part of a legacy which traces back to the original team of the NASL\\n                           in 1974."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- data.frame(id = c(\"Seattle Seahawks\", \"Seattle Sounders\"), \n",
    "                 type = c(\"url\", \"text\"),\n",
    "                 value = c(\"www.seahawks.com\", \n",
    "                           \"From Wikipedia.org: Seattle Sounders FC is an American professional soccer club based \n",
    "                           in Seattle, Washington. The Sounders compete as a member of the Western Conference of \n",
    "                           Major League Soccer (MLS) and are the league's current defending champions, having won\n",
    "                           the 2016 MLS Cup. The club was established on November 13, 2007, and began play in 2009\n",
    "                           as an MLS expansion team. The Sounders are the third Seattle soccer club to share the \n",
    "                           Sounders name being part of a legacy which traces back to the original team of the NASL\n",
    "                           in 1974.\"),\n",
    "                 stringsAsFactors = F)\n",
    "\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the `watsonNLUtoDF` function on the DataFrame and specify to return a DataFrame of concepts and a DataFrame of categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Sending url for Seattle Seahawks to Watson NLU...\"\n",
      "[1] \"Iteration 1 of 2 complete.\"\n",
      "[1] \"Sending text for Seattle Sounders to Watson NLU...\"\n",
      "[1] \"Iteration 2 of 2 complete.\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>text</th><th scope=col>relevance</th><th scope=col>dbpedia_resource</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Seattle Seahawks                                    </td><td>National Football League                            </td><td>0.9627                                              </td><td>http://dbpedia.org/resource/National_Football_League</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                            </td><td>Seattle Seahawks                            </td><td>0.529                                       </td><td>http://dbpedia.org/resource/Seattle_Seahawks</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                             </td><td>American football                            </td><td>0.5233                                       </td><td>http://dbpedia.org/resource/American_football</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                          </td><td>Draft                                     </td><td>0.4871                                    </td><td>http://dbpedia.org/resource/Draft_(sports)</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                    </td><td>Sea Gals                            </td><td>0.4638                              </td><td>http://dbpedia.org/resource/Sea_Gals</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                   </td><td>Seattle                            </td><td>0.4364                             </td><td>http://dbpedia.org/resource/Seattle</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " id & text & relevance & dbpedia\\_resource\\\\\n",
       "\\hline\n",
       "\t Seattle Seahawks                                         & National Football League                                 & 0.9627                                                   & http://dbpedia.org/resource/National\\_Football\\_League\\\\\n",
       "\t Seattle Seahawks                               & Seattle Seahawks                               & 0.529                                          & http://dbpedia.org/resource/Seattle\\_Seahawks\\\\\n",
       "\t Seattle Seahawks                                & American football                               & 0.5233                                          & http://dbpedia.org/resource/American\\_football\\\\\n",
       "\t Seattle Seahawks                             & Draft                                        & 0.4871                                       & http://dbpedia.org/resource/Draft\\_(sports)\\\\\n",
       "\t Seattle Seahawks                       & Sea Gals                               & 0.4638                                 & http://dbpedia.org/resource/Sea\\_Gals\\\\\n",
       "\t Seattle Seahawks                    & Seattle                             & 0.4364                              & http://dbpedia.org/resource/Seattle\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  id               text                     relevance\n",
       "1 Seattle Seahawks National Football League 0.9627   \n",
       "2 Seattle Seahawks Seattle Seahawks         0.529    \n",
       "3 Seattle Seahawks American football        0.5233   \n",
       "4 Seattle Seahawks Draft                    0.4871   \n",
       "5 Seattle Seahawks Sea Gals                 0.4638   \n",
       "6 Seattle Seahawks Seattle                  0.4364   \n",
       "  dbpedia_resource                                    \n",
       "1 http://dbpedia.org/resource/National_Football_League\n",
       "2 http://dbpedia.org/resource/Seattle_Seahawks        \n",
       "3 http://dbpedia.org/resource/American_football       \n",
       "4 http://dbpedia.org/resource/Draft_(sports)          \n",
       "5 http://dbpedia.org/resource/Sea_Gals                \n",
       "6 http://dbpedia.org/resource/Seattle                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<strong>$categoriesDF</strong> = <table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>score</th><th scope=col>label</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Seattle Seahawks</td><td>0.9999          </td><td>/sports/football</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                                           </td><td>0.3237                                                     </td><td>/art and entertainment/comics and animation/anime and manga</td></tr>\n",
       "\t<tr><td>Seattle Seahawks                                            </td><td>0.301                                                       </td><td>/technology and computing/internet technology/social network</td></tr>\n",
       "\t<tr><td>Seattle Sounders</td><td>0.7794          </td><td>/sports/soccer  </td></tr>\n",
       "\t<tr><td>Seattle Sounders  </td><td>0.3538            </td><td>/sports/gymnastics</td></tr>\n",
       "\t<tr><td>Seattle Sounders</td><td>0.2107          </td><td>/real estate    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\textbf{\\$categoriesDF} = \\begin{tabular}{r|lll}\n",
       " id & score & label\\\\\n",
       "\\hline\n",
       "\t Seattle Seahawks & 0.9999           & /sports/football\\\\\n",
       "\t Seattle Seahawks                                            & 0.3237                                                      & /art and entertainment/comics and animation/anime and manga\\\\\n",
       "\t Seattle Seahawks                                             & 0.301                                                        & /technology and computing/internet technology/social network\\\\\n",
       "\t Seattle Sounders & 0.7794           & /sports/soccer  \\\\\n",
       "\t Seattle Sounders   & 0.3538             & /sports/gymnastics\\\\\n",
       "\t Seattle Sounders & 0.2107           & /real estate    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "$categoriesDF\n",
       "                id  score\n",
       "1 Seattle Seahawks 0.9999\n",
       "2 Seattle Seahawks 0.3237\n",
       "3 Seattle Seahawks  0.301\n",
       "4 Seattle Sounders 0.7794\n",
       "5 Seattle Sounders 0.3538\n",
       "6 Seattle Sounders 0.2107\n",
       "                                                         label\n",
       "1                                             /sports/football\n",
       "2  /art and entertainment/comics and animation/anime and manga\n",
       "3 /technology and computing/internet technology/social network\n",
       "4                                               /sports/soccer\n",
       "5                                           /sports/gymnastics\n",
       "6                                                 /real estate\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Send properly formatted DataFrame with credentials to Watson\n",
    "responseList <- watsonNLUtoDF(df, username, password, verbose = T)\n",
    "\n",
    "head(responseList$conceptsDF)\n",
    "head(responseList[4]) ## 'categories'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first returned DataFrame shows which concepts are most important. The second returned DataFrame shows which categories best describe the text. Watson is very confident that the text is about football! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize'></a>\n",
    "\n",
    "## 3. Visualize a customer base with Watson NLU\n",
    "\n",
    "At this point, you should have a good idea of what the NLU service provides and how you've accessed it in R. Now have a little fun and visualize some output.\n",
    "\n",
    "The data science goal of this notebook is understanding market segmentation across a customer base.  **Can you use an AI engine to better understand and classify both existing and potential customers?  Watson is well suited for this task!**  Use the `watsonNLUtoDF` function to send Watson a DataFrame full of company names and a mix of their URLs and text descriptions. Then  build a word cloud with the concepts and keywords that are returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='visualize1'></a>\n",
    "### 3.1  Load the customer data\n",
    "Download the data set from the Watson Studio community and load it into a DataFrame.\n",
    "\n",
    "To load the data:\n",
    "1. Go to the [Fortune 100 companies data set](https://apsportal.ibm.com/exchange/public/entry/view/4d26cd0dd964734bc23c6475a8dc454b) on the Watson Studio Community. \n",
    "2. Click the download icon and save the data set as .csv file to your computer.  \n",
    "3. Load the `fortune100.csv` file into your notebook. Click the **Find and Add Data** icon on the notebook action bar. Drop the file into the box or browse to select the file. The file is loaded to your object storage and appears in the Data Assets section of the project. For more information, see <a href=\"https://datascience.ibm.com/docs/content/analyze-data/load-and-access-data.html\" target=\"_blank\" rel=\"noopener noreferrer\">Load and access data</a>.\n",
    "4. To load the data from the `fortune100.csv` file into a R DataFrame, click in the next code cell and select **Insert to code > Insert R DataFrame** under the file name.\n",
    "5. Rename the two instances of `df.data.x` to `customersDF` in the last two lines.\n",
    "6. Run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>id</th><th scope=col>type</th><th scope=col>value</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>Walmart                         </td><td>url                             </td><td>http://www.walmart.com          </td></tr>\n",
       "\t<tr><td>Exxon Mobil                     </td><td>url                             </td><td>http://www.exxonmobil.com       </td></tr>\n",
       "\t<tr><td>Apple                           </td><td>url                             </td><td>http://www.apple.com            </td></tr>\n",
       "\t<tr><td>Berkshire Hathaway              </td><td>url                             </td><td>http://www.berkshirehathaway.com</td></tr>\n",
       "\t<tr><td>McKesson                        </td><td>url                             </td><td>http://www.mckesson.com         </td></tr>\n",
       "\t<tr><td>UnitedHealth Group              </td><td>url                             </td><td>http://www.unitedhealthgroup.com</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " id & type & value\\\\\n",
       "\\hline\n",
       "\t Walmart                          & url                              & http://www.walmart.com          \\\\\n",
       "\t Exxon Mobil                      & url                              & http://www.exxonmobil.com       \\\\\n",
       "\t Apple                            & url                              & http://www.apple.com            \\\\\n",
       "\t Berkshire Hathaway               & url                              & http://www.berkshirehathaway.com\\\\\n",
       "\t McKesson                         & url                              & http://www.mckesson.com         \\\\\n",
       "\t UnitedHealth Group               & url                              & http://www.unitedhealthgroup.com\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  id                 type value                           \n",
       "1 Walmart            url  http://www.walmart.com          \n",
       "2 Exxon Mobil        url  http://www.exxonmobil.com       \n",
       "3 Apple              url  http://www.apple.com            \n",
       "4 Berkshire Hathaway url  http://www.berkshirehathaway.com\n",
       "5 McKesson           url  http://www.mckesson.com         \n",
       "6 UnitedHealth Group url  http://www.unitedhealthgroup.com"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data using Insert to code > Insert R DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize2'></a>\n",
    "### 3.2 Shape the data for the NLU function\n",
    "\n",
    "The DataFrame already has correctly named columns of `id`, `type`, and `value`. Make sure that all the column types are strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t100 obs. of  3 variables:\n",
      " $ id   : chr  \"Walmart\" \"Exxon Mobil\" \"Apple\" \"Berkshire Hathaway\" ...\n",
      " $ type : chr  \"url\" \"url\" \"url\" \"url\" ...\n",
      " $ value: chr  \"http://www.walmart.com\" \"http://www.exxonmobil.com\" \"http://www.apple.com\" \"http://www.berkshirehathaway.com\" ...\n"
     ]
    }
   ],
   "source": [
    "## Change column types to string\n",
    "customersDF <- as.data.frame(apply(customersDF, 2, as.character), stringsAsFactors = F)\n",
    "\n",
    "## Inspect dataframe types\n",
    "str(customersDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Looks good!  \n",
    "\n",
    "<a id='visualize3'></a>\n",
    "### 3.3 Send `customersDF`  to Watson \n",
    "Run the `watsonNLUtoDF` function to send the customersDF DataFrame to Watson NLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseList <- watsonNLUtoDF(customersDF, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize4'></a>\n",
    "### 3.4 Concatenate the concepts and keywords extracted from Watson \n",
    "Now concatenate the resulting concepts and keywords lists into a customerDocument DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "customerDocument <- paste(responseList$concepts$text, responseList$keywords$text, sep = \" \", collapse = \" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize5'></a>\n",
    "### 3.5 Format the Text for a Word Cloud\n",
    "Use functions from the R tm package to format the text so that you can create a word cloud:\n",
    "\n",
    "- Remove punctuation, numbers, and spaces\n",
    "- Remove very short words and very long words\n",
    "- Calculate the frequency of each word\n",
    "- Drop words that appear 8 or fewer times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Corpus from concatenated text\n",
    "customerCorpus <- Corpus(VectorSource(customerDocument))\n",
    "\n",
    "## Scrub text\n",
    "customerCorpus <- tm_map(customerCorpus, removePunctuation)\n",
    "customerCorpus <- tm_map(customerCorpus, removeNumbers)\n",
    "customerCorpus <- tm_map(customerCorpus, stripWhitespace)\n",
    "\n",
    "## Remove words less than 4 characters or greater than 20\n",
    "customerTDM <- TermDocumentMatrix(customerCorpus, control = list(wordLengths = c(4, 20)))\n",
    "\n",
    "## Calculate word frequencies\n",
    "wordFreqDF <- data.frame(word = row.names(as.matrix(customerTDM)), freq = as.vector(customerTDM))\n",
    "\n",
    "## Drop words with a count less than 8\n",
    "wordFreqDF <- subset(wordFreqDF, freq >= 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the resulting wordFreDF DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>word</th><th scope=col>freq</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>22</th><td>adventures  </td><td> 9          </td></tr>\n",
       "\t<tr><th scope=row>27</th><td>advisors    </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>52</th><td>airlines    </td><td>14          </td></tr>\n",
       "\t<tr><th scope=row>55</th><td>alaska      </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>58</th><td>aleutian    </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>72</th><td>america     </td><td>20          </td></tr>\n",
       "\t<tr><th scope=row>74</th><td>american    </td><td>36          </td></tr>\n",
       "\t<tr><th scope=row>84</th><td>annual      </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>93</th><td>apple       </td><td>16          </td></tr>\n",
       "\t<tr><th scope=row>106</th><td>arctic      </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>126</th><td>atlantic    </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>127</th><td>attachments </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>160</th><td>bank        </td><td>28          </td></tr>\n",
       "\t<tr><th scope=row>169</th><td>bear        </td><td> 9          </td></tr>\n",
       "\t<tr><th scope=row>179</th><td>best        </td><td>21          </td></tr>\n",
       "\t<tr><th scope=row>182</th><td>beverage    </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>200</th><td>board       </td><td>11          </td></tr>\n",
       "\t<tr><th scope=row>224</th><td>broadcasting</td><td>15          </td></tr>\n",
       "\t<tr><th scope=row>236</th><td>building    </td><td>15          </td></tr>\n",
       "\t<tr><th scope=row>240</th><td>business    </td><td>68          </td></tr>\n",
       "\t<tr><th scope=row>245</th><td>california  </td><td>16          </td></tr>\n",
       "\t<tr><th scope=row>250</th><td>canada      </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>264</th><td>card        </td><td>11          </td></tr>\n",
       "\t<tr><th scope=row>266</th><td>cards       </td><td>12          </td></tr>\n",
       "\t<tr><th scope=row>267</th><td>care        </td><td>56          </td></tr>\n",
       "\t<tr><th scope=row>303</th><td>chain       </td><td>13          </td></tr>\n",
       "\t<tr><th scope=row>325</th><td>chief       </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>336</th><td>city        </td><td>13          </td></tr>\n",
       "\t<tr><th scope=row>337</th><td>civil       </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>364</th><td>cocacola    </td><td>11          </td></tr>\n",
       "\t<tr><th scope=row>...</th><td>...</td><td>...</td></tr>\n",
       "\t<tr><th scope=row>178</th><td>site        </td><td>13          </td></tr>\n",
       "\t<tr><th scope=row>179</th><td>small       </td><td>15          </td></tr>\n",
       "\t<tr><th scope=row>180</th><td>solutions   </td><td>16          </td></tr>\n",
       "\t<tr><th scope=row>181</th><td>state       </td><td>15          </td></tr>\n",
       "\t<tr><th scope=row>182</th><td>states      </td><td>67          </td></tr>\n",
       "\t<tr><th scope=row>183</th><td>stock       </td><td>16          </td></tr>\n",
       "\t<tr><th scope=row>184</th><td>storage     </td><td>11          </td></tr>\n",
       "\t<tr><th scope=row>185</th><td>store       </td><td>17          </td></tr>\n",
       "\t<tr><th scope=row>186</th><td>subsidiary  </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>187</th><td>supply      </td><td>15          </td></tr>\n",
       "\t<tr><th scope=row>188</th><td>support     </td><td> 9          </td></tr>\n",
       "\t<tr><th scope=row>189</th><td>system      </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>190</th><td>systems     </td><td>20          </td></tr>\n",
       "\t<tr><th scope=row>191</th><td>technologies</td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>192</th><td>technology  </td><td>24          </td></tr>\n",
       "\t<tr><th scope=row>193</th><td>term        </td><td>12          </td></tr>\n",
       "\t<tr><th scope=row>194</th><td>text        </td><td> 8          </td></tr>\n",
       "\t<tr><th scope=row>195</th><td>time        </td><td>30          </td></tr>\n",
       "\t<tr><th scope=row>196</th><td>types       </td><td>12          </td></tr>\n",
       "\t<tr><th scope=row>197</th><td>underwriting</td><td>13          </td></tr>\n",
       "\t<tr><th scope=row>198</th><td>united      </td><td>87          </td></tr>\n",
       "\t<tr><th scope=row>199</th><td>vehicles    </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>200</th><td>verizon     </td><td>11          </td></tr>\n",
       "\t<tr><th scope=row>201</th><td>wells       </td><td>14          </td></tr>\n",
       "\t<tr><th scope=row>202</th><td>windows     </td><td>16          </td></tr>\n",
       "\t<tr><th scope=row>203</th><td>winnie      </td><td> 9          </td></tr>\n",
       "\t<tr><th scope=row>204</th><td>womens      </td><td> 9          </td></tr>\n",
       "\t<tr><th scope=row>205</th><td>work        </td><td>10          </td></tr>\n",
       "\t<tr><th scope=row>206</th><td>world       </td><td>44          </td></tr>\n",
       "\t<tr><th scope=row>207</th><td>york        </td><td>11          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & word & freq\\\\\n",
       "\\hline\n",
       "\t22 & adventures   &  9          \\\\\n",
       "\t27 & advisors     &  8          \\\\\n",
       "\t52 & airlines     & 14          \\\\\n",
       "\t55 & alaska       &  8          \\\\\n",
       "\t58 & aleutian     &  8          \\\\\n",
       "\t72 & america      & 20          \\\\\n",
       "\t74 & american     & 36          \\\\\n",
       "\t84 & annual       &  8          \\\\\n",
       "\t93 & apple        & 16          \\\\\n",
       "\t106 & arctic       & 10          \\\\\n",
       "\t126 & atlantic     &  8          \\\\\n",
       "\t127 & attachments  &  8          \\\\\n",
       "\t160 & bank         & 28          \\\\\n",
       "\t169 & bear         &  9          \\\\\n",
       "\t179 & best         & 21          \\\\\n",
       "\t182 & beverage     &  8          \\\\\n",
       "\t200 & board        & 11          \\\\\n",
       "\t224 & broadcasting & 15          \\\\\n",
       "\t236 & building     & 15          \\\\\n",
       "\t240 & business     & 68          \\\\\n",
       "\t245 & california   & 16          \\\\\n",
       "\t250 & canada       &  8          \\\\\n",
       "\t264 & card         & 11          \\\\\n",
       "\t266 & cards        & 12          \\\\\n",
       "\t267 & care         & 56          \\\\\n",
       "\t303 & chain        & 13          \\\\\n",
       "\t325 & chief        & 10          \\\\\n",
       "\t336 & city         & 13          \\\\\n",
       "\t337 & civil        &  8          \\\\\n",
       "\t364 & cocacola     & 11          \\\\\n",
       "\t... & ... & ...\\\\\n",
       "\t178 & site         & 13          \\\\\n",
       "\t179 & small        & 15          \\\\\n",
       "\t180 & solutions    & 16          \\\\\n",
       "\t181 & state        & 15          \\\\\n",
       "\t182 & states       & 67          \\\\\n",
       "\t183 & stock        & 16          \\\\\n",
       "\t184 & storage      & 11          \\\\\n",
       "\t185 & store        & 17          \\\\\n",
       "\t186 & subsidiary   & 10          \\\\\n",
       "\t187 & supply       & 15          \\\\\n",
       "\t188 & support      &  9          \\\\\n",
       "\t189 & system       & 10          \\\\\n",
       "\t190 & systems      & 20          \\\\\n",
       "\t191 & technologies &  8          \\\\\n",
       "\t192 & technology   & 24          \\\\\n",
       "\t193 & term         & 12          \\\\\n",
       "\t194 & text         &  8          \\\\\n",
       "\t195 & time         & 30          \\\\\n",
       "\t196 & types        & 12          \\\\\n",
       "\t197 & underwriting & 13          \\\\\n",
       "\t198 & united       & 87          \\\\\n",
       "\t199 & vehicles     & 10          \\\\\n",
       "\t200 & verizon      & 11          \\\\\n",
       "\t201 & wells        & 14          \\\\\n",
       "\t202 & windows      & 16          \\\\\n",
       "\t203 & winnie       &  9          \\\\\n",
       "\t204 & womens       &  9          \\\\\n",
       "\t205 & work         & 10          \\\\\n",
       "\t206 & world        & 44          \\\\\n",
       "\t207 & york         & 11          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "    word         freq\n",
       "22  adventures    9  \n",
       "27  advisors      8  \n",
       "52  airlines     14  \n",
       "55  alaska        8  \n",
       "58  aleutian      8  \n",
       "72  america      20  \n",
       "74  american     36  \n",
       "84  annual        8  \n",
       "93  apple        16  \n",
       "106 arctic       10  \n",
       "126 atlantic      8  \n",
       "127 attachments   8  \n",
       "160 bank         28  \n",
       "169 bear          9  \n",
       "179 best         21  \n",
       "182 beverage      8  \n",
       "200 board        11  \n",
       "224 broadcasting 15  \n",
       "236 building     15  \n",
       "240 business     68  \n",
       "245 california   16  \n",
       "250 canada        8  \n",
       "264 card         11  \n",
       "266 cards        12  \n",
       "267 care         56  \n",
       "303 chain        13  \n",
       "325 chief        10  \n",
       "336 city         13  \n",
       "337 civil         8  \n",
       "364 cocacola     11  \n",
       "... ...          ... \n",
       "178 site         13  \n",
       "179 small        15  \n",
       "180 solutions    16  \n",
       "181 state        15  \n",
       "182 states       67  \n",
       "183 stock        16  \n",
       "184 storage      11  \n",
       "185 store        17  \n",
       "186 subsidiary   10  \n",
       "187 supply       15  \n",
       "188 support       9  \n",
       "189 system       10  \n",
       "190 systems      20  \n",
       "191 technologies  8  \n",
       "192 technology   24  \n",
       "193 term         12  \n",
       "194 text          8  \n",
       "195 time         30  \n",
       "196 types        12  \n",
       "197 underwriting 13  \n",
       "198 united       87  \n",
       "199 vehicles     10  \n",
       "200 verizon      11  \n",
       "201 wells        14  \n",
       "202 windows      16  \n",
       "203 winnie        9  \n",
       "204 womens        9  \n",
       "205 work         10  \n",
       "206 world        44  \n",
       "207 york         11  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wordFreqDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='visualize6'></a>\n",
    "### 3.6 Visualize with the Brunel library\n",
    "Finally, use the Brunel library to visualize the word cloud to see themes amoung Fortune 100 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!--   ~ Copyright (c) 2015 IBM Corporation and others.   ~   ~ Licensed under the Apache License, Version 2.0 (the \"License\");   ~ You may not use this file except in compliance with the License.   ~ You may obtain a copy of the License at   ~   ~     http://www.apache.org/licenses/LICENSE-2.0   ~   ~ Unless required by applicable law or agreed to in writing, software   ~ distributed under the License is distributed on an \"AS IS\" BASIS,   ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   ~ See the License for the specific language governing permissions and   ~ limitations under the License.   -->  <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/brunel.2.3.css\"> <link rel=\"stylesheet\" type=\"text/css\" href=\"https://brunelvis.org/js/sumoselect.css\"> <style>      </style>  <div id=\"controls8fef43e8-b0bf-4aae-a3de-27012ad6b52c\" class=\"brunel\"/> <svg id=\"visc8b5f153-6259-45a4-b009-e15eb18a8794\" width=\"800\" height=\"600\"></svg>  <script>     require.config({         waitSeconds: 60,         paths: {             'd3': '//cdnjs.cloudflare.com/ajax/libs/d3/4.2.1/d3.min',             'topojson': '//cdnjs.cloudflare.com/ajax/libs/topojson/1.6.20/topojson.min',             'brunel' : 'https://brunelvis.org/js/brunel.2.3.min',             'brunelControls' : 'https://brunelvis.org/js/brunel.controls.2.3.min'         },         shim: {             'brunel' : {                  exports: 'BrunelD3',                  deps: ['d3', 'topojson'],                  init: function() {                     return {                       BrunelD3 : BrunelD3,                       BrunelData : BrunelData                    }                  }              },             'brunelControls' : {                  exports: 'BrunelEventHandlers',                  init: function() {                     return {                       BrunelEventHandlers: BrunelEventHandlers,                       BrunelJQueryControlFactory: BrunelJQueryControlFactory                    }                  }              }           }      });      require([\"d3\"], function(d3) {         require([\"brunel\", \"brunelControls\"], function(brunel, brunelControls) {             function  BrunelVis(visId) {\n",
       "  \"use strict\";                                                                       // strict mode\n",
       "  var datasets = [],                                      // array of datasets for the original data\n",
       "      pre = function(d, i) { return d },                         // default pre-process does nothing\n",
       "      post = function(d, i) { return d },                       // default post-process does nothing\n",
       "      transitionTime = 200,                                        // transition time for animations\n",
       "      charts = [],                                                       // the charts in the system\n",
       "      vis = d3.select('#' + visId).attr('class', 'brunel');                     // the SVG container\n",
       "\n",
       "  BrunelD3.addDefinitions(vis);                                   // ensure standard symbols present\n",
       "\n",
       "  // Define chart #1 in the visualization //////////////////////////////////////////////////////////\n",
       "\n",
       "  charts[0] = function(parentNode, filterRows) {\n",
       "    var geom = BrunelD3.geometry(parentNode || vis.node(), 0, 0, 1, 1, 0, 0, 0, 0),\n",
       "      elements = [];                                              // array of elements in this chart\n",
       "\n",
       "    // Define groups for the chart parts ///////////////////////////////////////////////////////////\n",
       "\n",
       "    var chart =  vis.append('g').attr('class', 'chart1')\n",
       "      .attr('transform','translate(' + geom.chart_left + ',' + geom.chart_top + ')');\n",
       "    var overlay = chart.append('g').attr('class', 'element').attr('class', 'overlay');\n",
       "    var zoom = d3.zoom().scaleExtent([1/3,3]);\n",
       "    var zoomNode = overlay.append('rect').attr('class', 'overlay')\n",
       "      .attr('x', geom.inner_left).attr('y', geom.inner_top)\n",
       "      .attr('width', geom.inner_rawWidth).attr('height', geom.inner_rawHeight)\n",
       "      .style('cursor', 'default')\n",
       "      .node();\n",
       "    zoomNode.__zoom = d3.zoomIdentity;\n",
       "    chart.append('rect').attr('class', 'background').attr('width', geom.chart_right-geom.chart_left).attr('height', geom.chart_bottom-geom.chart_top);\n",
       "    var interior = chart.append('g').attr('class', 'interior zoomNone')\n",
       "      .attr('transform','translate(' + geom.inner_left + ',' + geom.inner_top + ')')\n",
       "      .attr('clip-path', 'url(#clip_visc8b5f153-6259-45a4-b009-e15eb18a8794_chart1_inner)');\n",
       "    interior.append('rect').attr('class', 'inner').attr('width', geom.inner_width).attr('height', geom.inner_height);\n",
       "    var gridGroup = interior.append('g').attr('class', 'grid');\n",
       "    vis.append('clipPath').attr('id', 'clip_visc8b5f153-6259-45a4-b009-e15eb18a8794_chart1_inner').append('rect')\n",
       "      .attr('x', 0).attr('y', 0)\n",
       "      .attr('width', geom.inner_rawWidth+1).attr('height', geom.inner_rawHeight+1);\n",
       "    var scale_x = d3.scaleLinear(), scale_y = d3.scaleLinear();\n",
       "    var base_scales = [scale_x, scale_y];                           // untransformed original scales\n",
       "    zoom.on('zoom', function(t, time) {\n",
       "        t = t || d3.event.transform;\n",
       "        zoomNode.__zoom = t;\n",
       "        interior.attr('class', 'interior ' + BrunelD3.zoomLabel(t.k));;\n",
       "        interior.attr('transform', d3.zoomTransform(zoomNode));\n",
       "    });\n",
       "\n",
       "    // Define element #1 ///////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "    elements[0] = function() {\n",
       "      var original, processed,                           // data sets passed in and then transformed\n",
       "        element, data,                                 // brunel element information and brunel data\n",
       "        selection, merged;                                      // d3 selection and merged selection\n",
       "      var elementGroup = interior.append('g').attr('class', 'element1')\n",
       "        .attr('transform','translate(' + geom.inner_width/2 + ',' + geom.inner_height/2 + ')'),\n",
       "        main = elementGroup.append('g').attr('class', 'main'),\n",
       "        labels = BrunelD3.undoTransform(elementGroup.append('g').attr('class', 'labels').attr('aria-hidden', 'true'), elementGroup);\n",
       "\n",
       "      function makeData() {\n",
       "        original = datasets[0];\n",
       "        if (filterRows) original = original.retainRows(filterRows);\n",
       "        processed = pre(original, 0)\n",
       "          .summarize('freq=freq:mean; word=word');\n",
       "        processed = post(processed, 0);\n",
       "        var f0 = processed.field('word'),\n",
       "          f1 = processed.field('freq'),\n",
       "          f2 = processed.field('#row'),\n",
       "          f3 = processed.field('#selection');\n",
       "        var keyFunc = function(d) { return f0.value(d) };\n",
       "        data = {\n",
       "          word:         function(d) { return f0.value(d.row) },\n",
       "          freq:         function(d) { return f1.value(d.row) },\n",
       "          $row:         function(d) { return f2.value(d.row) },\n",
       "          $selection:   function(d) { return f3.value(d.row) },\n",
       "          word_f:       function(d) { return f0.valueFormatted(d.row) },\n",
       "          freq_f:       function(d) { return f1.valueFormatted(d.row) },\n",
       "          $row_f:       function(d) { return f2.valueFormatted(d.row) },\n",
       "          $selection_f: function(d) { return f3.valueFormatted(d.row) },\n",
       "          _split:       function(d) { return f0.value(d.row)+ '|' + f1.value(d.row) },\n",
       "          _key:         keyFunc,\n",
       "          _rows:        BrunelD3.makeRowsWithKeys(keyFunc, processed.rowCount())\n",
       "        };\n",
       "      }\n",
       "      // Aesthetic Functions\n",
       "      var scale_color = d3.scaleOrdinal()\n",
       "        .domain(['adventures', 'advisors', 'airlines', 'alaska', 'aleutian', 'america', 'american', 'annual', 'apple', 'arctic', 'atlantic', 'attachments', 'bank', 'bear', 'best', 'beverage', 'board', 'broadcasting', 'building', 'business', 'california', 'canada', 'card', 'cards', 'care', 'chain', 'chief', 'city', 'civil', 'cocacola', 'community', 'companies', 'company', 'computer', 'conglomerate', 'controls', 'cooperative', 'corporate', 'corporation', 'countries', 'creativity', 'credit', 'customer', 'customers', 'detroit', 'development', 'directors', 'disease', 'drink', 'drug', 'earth', 'economic', 'economics', 'energy', 'engine', 'english', 'englishlanguage', 'entity', 'environment', 'equipment', 'equity', 'exchange', 'executive', 'experience', 'express', 'family', 'fargo', 'farm', 'films', 'finance', 'financial', 'food', 'ford', 'fuel', 'future', 'games', 'general', 'global', 'goldman', 'governance', 'group', 'growth', 'hawaii', 'health', 'healthcare', 'help', 'home', 'hospital', 'household', 'housing', 'human', 'indonesia', 'industry', 'information', 'innovation', 'insurance', 'interest', 'international', 'internet', 'investment', 'investor', 'iphone', 'ipod', 'islands', 'johnson', 'knowledge', 'language', 'largest', 'life', 'liquefied', 'loan', 'local', 'management', 'market', 'marketing', 'media', 'medicine', 'menu', 'michigan', 'microsoft', 'mobile', 'money', 'mortgage', 'motor', 'motors', 'mower', 'music', 'mutual', 'national', 'nationwide', 'natural', 'network', 'news', 'ocean', 'officer', 'pacific', 'partner', 'partnership', 'payment', 'pension', 'people', 'performance', 'personal', 'petroleum', 'pharmaceutical', 'pharmacology', 'pharmacy', 'phone', 'physician', 'plan', 'policy', 'pooh', 'press', 'pricing', 'printer', 'printing', 'privacy', 'products', 'public', 'radio', 'rally', 'rate', 'relationship', 'reserved', 'results', 'rights', 'risk', 'russia', 'safety', 'savings', 'school', 'science', 'search', 'securities', 'service', 'services', 'shop', 'site', 'small', 'solutions', 'state', 'states', 'stock', 'storage', 'store', 'subsidiary', 'supply', 'support', 'system', 'systems', 'technologies', 'technology', 'term', 'text', 'time', 'types', 'underwriting', 'united', 'vehicles', 'verizon', 'wells', 'windows', 'winnie', 'womens', 'work', 'world', 'york'])\n",
       "        .range([ '#00538A', '#C10020', '#F4C800', '#007D34', '#803E75', '#FF6800', \n",
       "          '#817066', '#FFB300', '#F6768E', '#93AA00', '#53377A', '#FF8E00', '#B32851', \n",
       "          '#CEA262', '#FF7A5C', '#7F180D', '#593315', '#F13A13', '#232C16']);\n",
       "      var color = function(d) { return scale_color(data.word(d)) };\n",
       "      var scale_size = d3.scaleSqrt().domain([0, 121.00001])\n",
       "        .range([ 0.001, 1]);\n",
       "      var size = function(d) { return scale_size(data.freq(d)) };\n",
       "\n",
       "      // Build element from data ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "      function build(transitionMillis) {\n",
       "        element = elements[0];\n",
       "        // Build the cloud layout\n",
       "        var cloud = BrunelD3.cloudLayout(processed, [geom.inner_width, geom.inner_height], zoomNode);\n",
       "        function keyFunction(d) { return d.key };\n",
       "        main.attr('class', 'diagram cloud');\n",
       "\n",
       "        // Define selection entry operations\n",
       "        function initialState(selection) {\n",
       "          selection\n",
       "            .attr('class', 'element text filled')\n",
       "            .style('text-anchor', 'middle').classed('label', true)\n",
       "            .text(function(d) { return data.word_f(d) })\n",
       "            .style('font-size', function(d) { return (100*size(d)) + '%' })\n",
       "            .style('pointer-events', 'none')\n",
       "        }\n",
       "\n",
       "        // Define selection update operations on merged data\n",
       "        function updateState(selection) {\n",
       "          selection\n",
       "            .each(cloud.prepare).call(cloud.build)\n",
       "            .filter(BrunelD3.hasData)                     // following only performed for data items\n",
       "            .style('fill', color);\n",
       "        }\n",
       "        // Create selections, set the initial state and transition updates\n",
       "        selection = main.selectAll('.element').data(data._rows, function(d) { return d.key });\n",
       "        var added = selection.enter().append('text');\n",
       "        merged = selection.merge(added);\n",
       "        initialState(added);\n",
       "        selection.filter(BrunelD3.hasData)\n",
       "          .classed('selected', BrunelD3.isSelected(data))\n",
       "          .filter(BrunelD3.isSelected(data)).raise();\n",
       "        updateState(BrunelD3.transition(merged, transitionMillis));\n",
       "\n",
       "        BrunelD3.transition(selection.exit(), transitionMillis/3)\n",
       "          .style('opacity', 0.5).each( function() {\n",
       "            this.remove(); BrunelD3.removeLabels(this); \n",
       "        });\n",
       "      }\n",
       "\n",
       "      return {\n",
       "        data:           function() { return processed },\n",
       "        original:       function() { return original },\n",
       "        internal:       function() { return data },\n",
       "        selection:      function() { return merged },\n",
       "        makeData:       makeData,\n",
       "        build:          build,\n",
       "        chart:          function() { return charts[0] },\n",
       "        group:          function() { return elementGroup },\n",
       "        fields: {\n",
       "          key:          ['word'],\n",
       "          color:        ['word'],\n",
       "          size:         ['freq']\n",
       "        }\n",
       "      };\n",
       "    }();\n",
       "\n",
       "    function build(time, noData) {\n",
       "      var first = elements[0].data() == null;\n",
       "      if (first) time = 0;                                           // no transition for first call\n",
       "      if ((first || time > -1) && !noData) {\n",
       "        elements[0].makeData();\n",
       "      }\n",
       "      elements[0].build(time);\n",
       "    }\n",
       "\n",
       "    // Expose the following components of the chart\n",
       "    return {\n",
       "      elements : elements,\n",
       "      interior : interior,\n",
       "      zoom: function(params, time) {\n",
       "          if (params) zoom.on('zoom').call(zoomNode, params, time);\n",
       "          return d3.zoomTransform(zoomNode);\n",
       "      },\n",
       "      build : build\n",
       "    };\n",
       "    }();\n",
       "\n",
       "  function setData(rowData, i) { datasets[i||0] = BrunelD3.makeData(rowData) }\n",
       "  function updateAll(time) { charts.forEach(function(x) {x.build(time || 0)}) }\n",
       "  function buildAll() {\n",
       "    for (var i=0;i<arguments.length;i++) setData(arguments[i], i);\n",
       "    updateAll(transitionTime);\n",
       "  }\n",
       "\n",
       "  return {\n",
       "    dataPreProcess:     function(f) { if (f) pre = f; return pre },\n",
       "    dataPostProcess:    function(f) { if (f) post = f; return post },\n",
       "    data:               function(d,i) { if (d) setData(d,i); return datasets[i||0] },\n",
       "    visId:              visId,\n",
       "    build:              buildAll,\n",
       "    rebuild:            updateAll,\n",
       "    charts:             charts\n",
       "  }\n",
       "}\n",
       "\n",
       "// Data Tables /////////////////////////////////////////////////////////////////////////////////////\n",
       "\n",
       "var table1 = {\n",
       "   summarized: true,\n",
       "   names: ['word', 'freq'], \n",
       "   options: ['string', 'numeric'], \n",
       "   rows: [['adventures', 9], ['advisors', 8], ['airlines', 14], ['alaska', 8], ['aleutian', 8],\n",
       "  ['america', 20], ['american', 36], ['annual', 8], ['apple', 16], ['arctic', 10], ['atlantic', 8],\n",
       "  ['attachments', 8], ['bank', 28], ['bear', 9], ['best', 21], ['beverage', 8], ['board', 11],\n",
       "  ['broadcasting', 15], ['building', 15], ['business', 68], ['california', 16], ['canada', 8],\n",
       "  ['card', 11], ['cards', 12], ['care', 56], ['chain', 13], ['chief', 10], ['city', 13],\n",
       "  ['civil', 8], ['cocacola', 11], ['community', 10], ['companies', 21], ['company', 46],\n",
       "  ['computer', 14], ['conglomerate', 9], ['controls', 8], ['cooperative', 8], ['corporate', 33],\n",
       "  ['corporation', 42], ['countries', 9], ['creativity', 10], ['credit', 24], ['customer', 17],\n",
       "  ['customers', 9], ['detroit', 10], ['development', 10], ['directors', 11], ['disease', 10],\n",
       "  ['drink', 9], ['drug', 12], ['earth', 9], ['economic', 12], ['economics', 18], ['energy', 52],\n",
       "  ['engine', 10], ['english', 9], ['englishlanguage', 21], ['entity', 8], ['environment', 21],\n",
       "  ['equipment', 10], ['equity', 8], ['exchange', 11], ['executive', 11], ['experience', 14],\n",
       "  ['express', 18], ['family', 14], ['fargo', 15], ['farm', 14], ['films', 21], ['finance', 43],\n",
       "  ['financial', 48], ['food', 29], ['ford', 18], ['fuel', 8], ['future', 23], ['games', 12],\n",
       "  ['general', 20], ['global', 36], ['goldman', 11], ['governance', 22], ['group', 15], ['growth', 8],\n",
       "  ['hawaii', 8], ['health', 121], ['healthcare', 8], ['help', 9], ['home', 35], ['hospital', 11],\n",
       "  ['household', 8], ['housing', 10], ['human', 13], ['indonesia', 9], ['industry', 8],\n",
       "  ['information', 24], ['innovation', 10], ['insurance', 98], ['interest', 10],\n",
       "  ['international', 33], ['internet', 13], ['investment', 40], ['investor', 11], ['iphone', 12],\n",
       "  ['ipod', 12], ['islands', 23], ['johnson', 10], ['knowledge', 11], ['language', 30],\n",
       "  ['largest', 11], ['life', 26], ['liquefied', 9], ['loan', 11], ['local', 11], ['management', 68],\n",
       "  ['market', 25], ['marketing', 10], ['media', 16], ['medicine', 29], ['menu', 14], ['michigan', 10],\n",
       "  ['microsoft', 12], ['mobile', 32], ['money', 9], ['mortgage', 22], ['motor', 10], ['motors', 11],\n",
       "  ['mower', 9], ['music', 8], ['mutual', 30], ['national', 8], ['nationwide', 12], ['natural', 51],\n",
       "  ['network', 8], ['news', 10], ['ocean', 24], ['officer', 10], ['pacific', 12], ['partner', 8],\n",
       "  ['partnership', 16], ['payment', 9], ['pension', 8], ['people', 13], ['performance', 9],\n",
       "  ['personal', 39], ['petroleum', 20], ['pharmaceutical', 13], ['pharmacology', 15],\n",
       "  ['pharmacy', 20], ['phone', 17], ['physician', 9], ['plan', 15], ['policy', 34], ['pooh', 17],\n",
       "  ['press', 8], ['pricing', 10], ['printer', 10], ['printing', 8], ['privacy', 27], ['products', 39],\n",
       "  ['public', 36], ['radio', 16], ['rally', 10], ['rate', 9], ['relationship', 8], ['reserved', 13],\n",
       "  ['results', 9], ['rights', 25], ['risk', 34], ['russia', 10], ['safety', 9], ['savings', 8],\n",
       "  ['school', 13], ['science', 19], ['search', 12], ['securities', 8], ['service', 27],\n",
       "  ['services', 49], ['shop', 8], ['site', 13], ['small', 15], ['solutions', 16], ['state', 15],\n",
       "  ['states', 67], ['stock', 16], ['storage', 11], ['store', 17], ['subsidiary', 10], ['supply', 15],\n",
       "  ['support', 9], ['system', 10], ['systems', 20], ['technologies', 8], ['technology', 24],\n",
       "  ['term', 12], ['text', 8], ['time', 30], ['types', 12], ['underwriting', 13], ['united', 87],\n",
       "  ['vehicles', 10], ['verizon', 11], ['wells', 14], ['windows', 16], ['winnie', 9], ['womens', 9],\n",
       "  ['work', 10], ['world', 44], ['york', 11]]\n",
       "};\n",
       "\n",
       "// Call Code to Build the system ///////////////////////////////////////////////////////////////////\n",
       "\n",
       "var v  = new BrunelVis('visc8b5f153-6259-45a4-b009-e15eb18a8794');\n",
       "v.build(table1);\n",
       "         });     });  </script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brunel (\" data('wordFreqDF') cloud color(word) size(freq) label(word) mean(freq) legends(none)\",\n",
    "        width = 800, height = 600, online_js = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## Summary and next steps\n",
    "\n",
    "Congratulations! In this notebook you learned about the Watson Natural Language Understanding API and how to access it in a programmatic way by using the R programming language.  \n",
    "\n",
    "Try substituting your own client list for the Fortune 100 data and creating a word cloud.\n",
    "\n",
    "### Author\n",
    "\n",
    "**Rafi Kurlansik** is an Open Source Solutions Engineer specializing in big data technologies, such as Hadoop and Spark. He's responsible for developing and delivering demonstrations of IBM tech to both enterprise clients and the larger analytics community. Kurlansik has hands-on experience with machine learning, natural language processing, data visualization, and dashboard development. If you're wondering where he comes down on the biggest data science debate of our day, Rafi is, in his own words, \"an avid R fan, especially RStudio!\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © 2017, 2018 IBM. This notebook and its source code are released under the terms of the MIT License."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R with Spark 2.1",
   "language": "R",
   "name": "r-spark21"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
