{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"9facac65-2f21-4c60-a082-7cf5a08d3589","jupyter":{"outputs_hidden":true}},"source":["# Classifying customer complaints with Watson NLP"]},{"cell_type":"markdown","metadata":{"id":"905c51c1-7396-4111-85e0-cb1c231cc63e"},"source":["This notebook demonstrates how to train different text classifiers using Watson NLP. The classifiers predict the product group from the text of a customer complaint. This could be used, for example to route a complaint to the appropriate staff member. \n","\n","The data that is used in this notebook is taken from the Consumer Complaint Database that is published by the Consumer Financial Protection Bureau (CFPB), a U.S. government agency. The Consumer Complaint Database is a collection of complaints about consumer financial products and services that the CFPB sent to companies for response.  A complaint contains the consumer’s narrative description of their experience if the consumer opted to share this information publicly and after the Bureau has removed all personal information. In this notebook, you will focus on complaints that contain this narrative description to show how to use Watson NLP.\n","\n","The data is publicly available at https://www.consumerfinance.gov/data-research/consumer-complaints/.\n","\n","## What you'll learn in this notebook\n","\n","Watson NLP implements state-of-the-art classification algorithms from three different families: \n","- Classic machine learning using SVM (Support Vector Machines)\n","- Deep learning using CNN (Convolutional Neural Networks)\n","- Transformer-based models based on the pretrained Slate IBM Foundation model\n","\n","Watson NLP also offers an easy to use _ensemble classifier_ which combines different classification algorithms and a majority voting.\n","\n","In this notebook, you'll learn how to:\n","\n","- **Prepare your data** so that it can be used as training data for the Watson NLP classification algorithms.\n","- **Train a custom SVM model** using `watson_nlp.blocks.classification.SVM`. SVM stands for Support Vector Machines. It's an established classification method. We will run it based on USE (Universal Sentence Encoder) embeddings of the input text.\n","- **Train a VotingEnsemble** using `watson_nlp.workflows.classification.GenericEnsemble`. Generic Ensemble allows to use any combination of the three base classifierts CNN, SVM with TF-IDF and SVM with USE (Universal Sentence Encoder). It computes the weighted mean of classification predictions using confidence scores.\n","- **Store and load classification models** as an asset of a Watson Studio project.\n","- **Score data and compare model quality** by running the models on test data and using the built-in quality evaluation and building a custom confusion matrix.\n","\n","\n","## Table of Contents\n","\n","\n","1. [Before you start](#beforeYouStart)\n","2. [Load the complaint data](#loadData)\n","3. [Prepare training and test data](#prepareData)\n","4. [Train a SVM classification model with Watson NLP](#svm)\n","5. [Train an ensemble classification model with Watson NLP](#ensemble)\n","6. [Store and load classification models](#storeLoad)\n","7. [Classify test data and compare model quality](#scoring)\n","8. [Summary](#summary)\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"beforeYouStart\"></a>\n","## Before you start\n","\n","Before you can begin working on this notebook in Watson Studio in Cloud Pak for Data as a Service, you need to ensure that the project token is set so that you can access the project assets via the notebook.\n","\n","When this notebook is added to the project, a project access token should be inserted at the top of the notebook in a code cell. If you do not see the cell above, add the token to the notebook by clicking **More > Insert project token** from the notebook action bar.  By running the inserted hidden code cell, a project object is created that you can use to access project resources.\n","\n","![ws-project.mov](https://media.giphy.com/media/jSVxX2spqwWF9unYrs/giphy.gif)\n","\n","Note that you can step through the notebook execution cell by cell, by selecting Shift-Enter. Or you can execute the entire notebook by selecting **Cell -> Run All** from the menu.\n"]},{"cell_type":"markdown","metadata":{"id":"4e59bd08-ccae-425c-9343-3b5a0f3b1a66"},"source":["\n","Begin by importing and initializing some helper libs that are used throughout the notebook."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"16342249-8ba1-46c7-ab99-59ced5ee7933"},"outputs":[],"source":["import pandas as pd\n","# we want to show large text snippets to be able to explore the relevant text\n","pd.options.display.max_colwidth = 400\n","\n","import json\n","import seaborn as sn\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"eedd06c4-2252-4025-84c8-2af806022391"},"outputs":[],"source":["import watson_nlp\n","\n","from watson_nlp.toolkit.classification_utils.train_util import prepare_data_from_json\n","from watson_core.toolkit import fileio\n","from watson_nlp.blocks.classification.svm import SVM"]},{"cell_type":"markdown","metadata":{"id":"7039cc98-9173-4b83-8e05-f1bcf717034e"},"source":["<a id=\"loadData\"></a>\n","## Load the complaint data"]},{"cell_type":"markdown","metadata":{"id":"acab6cc3-fdb1-42ec-9be1-957c46131736"},"source":["The data can be downloaded via an API from https://www.consumerfinance.gov/data-research/consumer-complaints/. The data contains one month of data and only those complaints that contain the consumer narrative text. The data is exported in CSV format. The URL to retrieve this data looks like this:"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"a0979cfc-95b1-4b89-a7a9-49f40bff5901"},"outputs":[],"source":["url = \"https://www.consumerfinance.gov/data-research/consumer-complaints/search/api/v1/?date_received_max=2021-03-30&date_received_min=2021-02-28&field=all&format=csv&has_narrative=true&no_aggs=true&size=18102\""]},{"cell_type":"markdown","metadata":{"id":"73c6f4e5-1522-45f7-9a97-3e43557a30c3"},"source":["Read the data into a dataframe.\n","You can find a detailed explanation of the available columns here: https://www.consumerfinance.gov/complaint/data-use/#:~:text=Types%20of%20complaint%20data%20we%20publish .\n","\n","In your analysis you will focus on the *Product* column, which contains the product group, and the column with the complaint text *Consumer complaint narrative*."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"4834599b-0c45-420c-99b7-811b32530ada"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Date received</th>\n","      <th>Product</th>\n","      <th>Sub-product</th>\n","      <th>Issue</th>\n","      <th>Sub-issue</th>\n","      <th>Consumer complaint narrative</th>\n","      <th>Company public response</th>\n","      <th>Company</th>\n","      <th>State</th>\n","      <th>ZIP code</th>\n","      <th>Tags</th>\n","      <th>Consumer consent provided?</th>\n","      <th>Submitted via</th>\n","      <th>Date sent to company</th>\n","      <th>Company response to consumer</th>\n","      <th>Timely response?</th>\n","      <th>Consumer disputed?</th>\n","      <th>Complaint ID</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>03/16/21</td>\n","      <td>Mortgage</td>\n","      <td>Other type of mortgage</td>\n","      <td>Closing on a mortgage</td>\n","      <td>NaN</td>\n","      <td>I have spoken with the representative for guaranteed rate with no positive results. this company was very negligent and handling my loan process which called me to lose XXXX and to lose the home that I was trying to purchase. they would wait until the day of clothes or one day before close and continue to ask for a documentation that I sent in to them every single time. They would wait 3 to 4 ...</td>\n","      <td>NaN</td>\n","      <td>GUARANTEED RATE INC.</td>\n","      <td>GA</td>\n","      <td>30233</td>\n","      <td>NaN</td>\n","      <td>Consent provided</td>\n","      <td>Web</td>\n","      <td>03/16/21</td>\n","      <td>Closed with explanation</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>4217655</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>03/23/21</td>\n","      <td>Credit reporting, credit repair services, or other personal consumer reports</td>\n","      <td>Credit reporting</td>\n","      <td>Problem with a credit reporting company's investigation into an existing problem</td>\n","      <td>Their investigation did not fix an error on your report</td>\n","      <td>Im submitting this complaint against EQUIFAX due to their total disregard for my consumer rights under the FCRA/FCBA/FDCPA. For several months now, I've been disputing inaccurate and unverifiable information showing up on my credit report by this company. I have requested intimate information about the alleged accounts, including a copy of an agreement with my signature on it, but I have yet t...</td>\n","      <td>NaN</td>\n","      <td>EQUIFAX, INC.</td>\n","      <td>TX</td>\n","      <td>77449</td>\n","      <td>NaN</td>\n","      <td>Consent provided</td>\n","      <td>Web</td>\n","      <td>03/23/21</td>\n","      <td>Closed with explanation</td>\n","      <td>Yes</td>\n","      <td>NaN</td>\n","      <td>4240468</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Date received  \\\n","0      03/16/21   \n","1      03/23/21   \n","\n","                                                                        Product  \\\n","0                                                                      Mortgage   \n","1  Credit reporting, credit repair services, or other personal consumer reports   \n","\n","              Sub-product  \\\n","0  Other type of mortgage   \n","1        Credit reporting   \n","\n","                                                                              Issue  \\\n","0                                                             Closing on a mortgage   \n","1  Problem with a credit reporting company's investigation into an existing problem   \n","\n","                                                 Sub-issue  \\\n","0                                                      NaN   \n","1  Their investigation did not fix an error on your report   \n","\n","                                                                                                                                                                                                                                                                                                                                                                                      Consumer complaint narrative  \\\n","0  I have spoken with the representative for guaranteed rate with no positive results. this company was very negligent and handling my loan process which called me to lose XXXX and to lose the home that I was trying to purchase. they would wait until the day of clothes or one day before close and continue to ask for a documentation that I sent in to them every single time. They would wait 3 to 4 ...   \n","1  Im submitting this complaint against EQUIFAX due to their total disregard for my consumer rights under the FCRA/FCBA/FDCPA. For several months now, I've been disputing inaccurate and unverifiable information showing up on my credit report by this company. I have requested intimate information about the alleged accounts, including a copy of an agreement with my signature on it, but I have yet t...   \n","\n","  Company public response               Company State ZIP code Tags  \\\n","0                     NaN  GUARANTEED RATE INC.    GA    30233  NaN   \n","1                     NaN         EQUIFAX, INC.    TX    77449  NaN   \n","\n","  Consumer consent provided? Submitted via Date sent to company  \\\n","0           Consent provided           Web             03/16/21   \n","1           Consent provided           Web             03/23/21   \n","\n","  Company response to consumer Timely response?  Consumer disputed?  \\\n","0      Closed with explanation              Yes                 NaN   \n","1      Closed with explanation              Yes                 NaN   \n","\n","   Complaint ID  \n","0       4217655  \n","1       4240468  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["complaint_df = pd.read_csv(url)\n","text_col = 'Consumer complaint narrative'\n","\n","complaint_df.head(2)"]},{"cell_type":"markdown","metadata":{"id":"76c8353d-287e-4d99-a026-e4058b33e97e"},"source":["Let's look at all product groups that are available in the data set because these are the classes that the classifier should predict from a given complaint text."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8670f96c-769f-4594-ba2e-0befcc915701"},"outputs":[{"data":{"text/plain":["Product\n","Credit reporting, credit repair services, or other personal consumer reports    8890\n","Debt collection                                                                 3340\n","Credit card or prepaid card                                                     1555\n","Mortgage                                                                        1548\n","Checking or savings account                                                     1122\n","Money transfer, virtual currency, or money service                               914\n","Vehicle loan or lease                                                            373\n","Student loan                                                                     193\n","Payday loan, title loan, or personal loan                                        193\n","Name: count, dtype: int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["product_counts = complaint_df['Product'].value_counts()\n","product_counts"]},{"cell_type":"markdown","metadata":{"id":"ccdad89c-88f2-4937-be6f-b4f53802b590"},"source":["<a id=\"prepareData\"></a>\n","## Prepare training and test data"]},{"cell_type":"markdown","metadata":{"id":"f9d79564-2d1e-4024-aa97-83b69791f51f"},"source":["Many classification algorithms work best if the training samples are equally split across the classes. If the data is unbalanced, algorithms might decide to favor classes with many samples to achieve an overall good result. To avoid this, you will sample the data in the next step to have a similar amount of samples for each class.\n","\n","To avoid long runtimes in this sample notebook, you will use only a small number of samples. However, this can reduce the quality of the classification models. In a real-case scenario, you should increase the number of samples per product group to get better results."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"85ec8349-e0e5-4990-b6af-0d68816b7664"},"outputs":[],"source":["# number of complaints for the each product group\n","sample_size = 300\n","\n","train_test_df = complaint_df.query(\"Product != 'Student loan' and Product != 'Payday loan, title loan, or personal loan'\")\n","\n","# sample the data to have the same number of complaints for each product group\n","train_test_df = train_test_df.groupby('Product').sample(n=sample_size, random_state=5).reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"ab11b3fa-e109-4401-b380-fc162dedf5a8"},"source":["In the next step, you will split the data into training and test data (ratio:80/20)."]},{"cell_type":"code","execution_count":8,"metadata":{"id":"c41ac188-0a68-4d8e-b595-c40b9044bc9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training data:\n","Number of training samples: 1680\n","Samples by product group:\n","Product\n","Checking or savings account                                                     240\n","Credit card or prepaid card                                                     240\n","Credit reporting, credit repair services, or other personal consumer reports    240\n","Debt collection                                                                 240\n","Money transfer, virtual currency, or money service                              240\n","Mortgage                                                                        240\n","Vehicle loan or lease                                                           240\n","Name: count, dtype: int64\n","\n","Test data:\n","Number of test samples: 420\n","Samples by product group:\n","Product\n","Checking or savings account                                                     60\n","Credit card or prepaid card                                                     60\n","Credit reporting, credit repair services, or other personal consumer reports    60\n","Debt collection                                                                 60\n","Money transfer, virtual currency, or money service                              60\n","Mortgage                                                                        60\n","Vehicle loan or lease                                                           60\n","Name: count, dtype: int64\n"]}],"source":["# 80% training data\n","train_orig_df = train_test_df.groupby('Product').sample(frac=0.8, random_state=6)\n","print(\"Training data:\")\n","print(\"Number of training samples: {}\".format(len(train_orig_df)))\n","print(\"Samples by product group:\\n{}\".format(train_orig_df['Product'].value_counts()))\n","\n","# 20% test data\n","test_orig_df = train_test_df.drop(train_orig_df.index)\n","print(\"\\nTest data:\")\n","print(\"Number of test samples: {}\".format(len(test_orig_df)))\n","print(\"Samples by product group:\\n{}\".format(test_orig_df['Product'].value_counts()))\n","\n","# re-index after sampling\n","train_orig_df = train_orig_df.reset_index(drop=True)\n","test_orig_df = test_orig_df.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{"id":"07d862cc-3cc4-42c7-a19a-d55118083ba8"},"source":["You have created two dataframes, one for the training and one for the test data. The data is still in its original format. Now you need to bring the data into a format that is usable by the Watson NLP classification algorithms. This can be either *JSON* or *CSV* format. \n","\n","In the sample, you will create the data in *JSON* format. The training and test data is written to files."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"230ff2a2-4095-4cf3-ae29-6a8deaa36a29"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I have not supplied proof under the doctrine of estoppel by silence, XXXX XXXX XXXX ( Mo ) XXXX XXXX XXXX, XXXX, I may presume that no proof of the alleged debt, in fact exists.</td>\n","      <td>[Checking or savings account]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Due to the impact of corona virus, i have been financially unwell. Most recently i began to really be affected where i had no income at all and no unemployment. I am trying to catch up with my bank, i had 3 transactions charged for XXXX each, and for each one i inherited an overdraft fee of {$35.00}. Right now i owe the bank {$200.00}, stemming from the three XXXX charges. Which is {$140.00} i...</td>\n","      <td>[Checking or savings account]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                                                                                                                                                                                                                                                                                                                                                                              text  \\\n","0                                                                                                                                                                                                                                I have not supplied proof under the doctrine of estoppel by silence, XXXX XXXX XXXX ( Mo ) XXXX XXXX XXXX, XXXX, I may presume that no proof of the alleged debt, in fact exists.   \n","1  Due to the impact of corona virus, i have been financially unwell. Most recently i began to really be affected where i had no income at all and no unemployment. I am trying to catch up with my bank, i had 3 transactions charged for XXXX each, and for each one i inherited an overdraft fee of {$35.00}. Right now i owe the bank {$200.00}, stemming from the three XXXX charges. Which is {$140.00} i...   \n","\n","                          labels  \n","0  [Checking or savings account]  \n","1  [Checking or savings account]  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["def prepare_data(df):\n","    # only the text column and the target label *Product* are needed\n","    df_out = df[[text_col, 'Product']].reset_index(drop=True)\n","    # rename to the identifiers expected by Watson NLP\n","    df_out = df_out.rename(columns={text_col: \"text\", 'Product': 'labels'})\n","    # the label column should be an array (although we have only one label per complaint)\n","    df_out['labels'] = df_out['labels'].map(lambda label: [label,])\n","    return df_out\n","    \n","train_df = prepare_data(train_orig_df)\n","train_file = './train_data.json'\n","train_df.to_json(train_file, orient='records')\n","    \n","test_df = prepare_data(test_orig_df)\n","test_file = './test_data.json'\n","test_df.to_json(test_file, orient='records')\n","\n","train_df.head(2)"]},{"cell_type":"markdown","metadata":{"id":"17ffb4e4-bed1-403f-98d3-07ae4b2dedc3"},"source":["<a id=\"svm\"></a>\n","## Train a SVM classification model with Watson NLP"]},{"cell_type":"markdown","metadata":{"id":"078c5074-b5dc-4950-bb12-73d8a391761a"},"source":["SVM is an establishd classification approach. Watson NLP includes an SVM algorithm that exploits the `SnapML` libraries for faster training. The algorithm utilizes USE embeddings that encode word-level semantics into a vector space.\n","\n","The SVM classifier block depends on the syntax block. So, start by loading the syntax model and the USE embeddings."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"69907356-2cbd-47f0-8e57-aa634b18cd40"},"outputs":[],"source":["# Syntax Model\n","syntax_model = watson_nlp.load('syntax_izumo_en_stock')\n","# USE Embedding Model\n","use_model = watson_nlp.load('embedding_use_en_stock')"]},{"cell_type":"markdown","metadata":{"id":"c19dc436-83bf-4e91-977e-60b6b8ca86b2"},"source":["Classification blocks expect the training data in data streams. You can create data streams using several utility methods, as shown below."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"37b4fbf2-30f0-44c7-a534-75449c2fd336"},"outputs":[],"source":["training_data_file = train_file\n","\n","# Create datastream from training data\n","training_data = prepare_data_from_json(training_data_file, syntax_model)\n","\n","# Create Syntax stream\n","syntax_stream, labels_stream = training_data[0], training_data[1]\n","\n","use_train_stream = use_model.stream(syntax_stream, doc_embed_style='raw_text')\n","use_svm_train_stream = watson_nlp.data_model.DataStream.zip(use_train_stream, labels_stream)"]},{"cell_type":"markdown","metadata":{"id":"052b20f4-941b-4e9f-9a62-bc4abef37b77"},"source":["Train the classifier. **Note:** This cell will run for several minutes."]},{"cell_type":"code","execution_count":12,"metadata":{"id":"dcd05e07-d4f5-4967-9862-e833a2aef001"},"outputs":[],"source":["# Train the SVM model\n","svm_model = SVM.train(use_svm_train_stream)"]},{"cell_type":"markdown","metadata":{"id":"a9d51076-59ac-4bb7-98ee-0d6e32cb09a0"},"source":["Before you evalute the model, you will train another one and look at how to store and reload models from the project."]},{"cell_type":"markdown","metadata":{"id":"95570c15-5b12-4abd-873c-ca83c2a4e308"},"source":["<a id=\"ensemble\"></a>\n","## Train an ensemble classification model with Watson NLP"]},{"cell_type":"markdown","metadata":{"id":"23d23ac9-a879-4e56-9efb-f32501b628d7"},"source":["The ensemble model may combine three classification models: \n","\n","- SVM with TF-IDF features\n","- SVM with USE (Universal Sentence Encoder) features \n","- CNN \n","\n","You will use SVM with TF-IDF and SVM with USE as algorithms for the Ensemble classifier.\n","It computes the weighted mean of classification predictions using confidence scores. You will use the default weights which can be fine-tuned in subsequent steps.\n","\n","The ensemble workflow is very easy to use and the model performance can be a lot better than individual algorithms.\n","\n","It depends on the syntax model and the USE embeddings. They are passed with the file containing the training data."]},{"cell_type":"markdown","metadata":{"id":"0342ddb4-4c26-4818-b937-3d7ddf11b0fa"},"source":["Train the ensemble classifier."]},{"cell_type":"code","execution_count":13,"metadata":{"id":"411dd851929641c3ae19855f7ea26826"},"outputs":[],"source":["from watson_nlp.workflows.classification import GenericEnsemble\n","from watson_nlp.workflows.classification.base_classifier import TFidfSvm\n","from watson_nlp.workflows.classification.base_classifier import UseSvm\n","\n","ensemble_model = GenericEnsemble.train(training_data_file, \n","                                       syntax_model, \n","                                       base_classifiers_params=[\n","                                           TFidfSvm.TrainParams(syntax_model=syntax_model),\n","                                           UseSvm.TrainParams(syntax_model=syntax_model, use_embedding_model=use_model, doc_embed_style='raw_text')])"]},{"cell_type":"markdown","metadata":{"id":"7296890f206c4f7682997a6ca217ce8b"},"source":["<a id=\"storeLoad\"></a>\n","## Store and load classification models (optional)"]},{"cell_type":"markdown","metadata":{"id":"00a803c1dfcb4be489d9c3e8b6af410e"},"source":["You can save a model as a project asset. `model.as_bytes()` creates a ZIP archive, which is provided as a *BytesIO* object that is stored in the project.\n","\n","**Note:** These steps are **optional**. You can skip them, and continue at [Classify test data and compare model quality](#scoring)\n","\n","Save both models in your project."]},{"cell_type":"code","execution_count":14,"metadata":{"id":"6f2d4d1c23ea49e880498b0ed9010f24"},"outputs":[{"data":{"text/plain":["{'name': 'svm_model',\n"," 'asset_type': 'data_asset',\n"," 'asset_id': '88a32bc3-943c-4238-9da6-1a576b46f9b5',\n"," 'attachment_id': 'e2f3f128-58d4-43ea-922c-062dea33b404',\n"," 'filepath': 'svm_model.',\n"," 'data_size': None,\n"," 'mime': 'application/binary',\n"," 'summary': ['created or overwritten file',\n","  'created data asset',\n","  'created attachment']}"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["wslib.save_data('svm_model', data=svm_model.as_bytes(), overwrite=True)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"2676c868db474636a01cf162db66a973"},"outputs":[{"data":{"text/plain":["{'name': 'ensemble_model',\n"," 'asset_type': 'data_asset',\n"," 'asset_id': '5fbdca3b-b0ac-4542-9a80-f0359e8ecc77',\n"," 'attachment_id': '7e922ba6-3085-4bf4-bee5-2d9553a2d676',\n"," 'filepath': 'ensemble_model.',\n"," 'data_size': None,\n"," 'mime': 'application/binary',\n"," 'summary': ['created or overwritten file',\n","  'created data asset',\n","  'created attachment']}"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["wslib.save_data('ensemble_model', data=ensemble_model.as_bytes(), overwrite=True)"]},{"cell_type":"markdown","metadata":{"id":"fb8f5eaec4c34761807fe4c447c5e1df"},"source":["The ZIP archive created by the `save_data` function is compatible to the `watson_nlp.load()` function that is also used to load the predefined Watson NLP models."]},{"cell_type":"code","execution_count":16,"metadata":{"id":"96ff086baade4fe69e7e2ae7f671f49e"},"outputs":[],"source":["svm_model = watson_nlp.load(wslib.load_data('svm_model'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ab15b4b37e184d72bf680a845c2be52c","msg_id":"33be998c-f088-46ff-af4f-240911e072ea"},"outputs":[],"source":["ensemble_model = watson_nlp.load(wslib.load_data('ensemble_model'))"]},{"cell_type":"markdown","metadata":{"id":"db9b3096-1942-45a0-bdd7-0d1bd93cdd70"},"source":["<a id=\"scoring\"></a>\n","## Classify test data and compare model quality"]},{"cell_type":"markdown","metadata":{"id":"16a8f9b8-8f3c-43f4-abce-2f19b080739e"},"source":["Now you are able to run the trained models on new data. You will run the models on the test data so that the results can also be used for model evaluation. For illustration purposes, the data is used in the original format that you started out with because the format of the new complaints that you receive might also be in that format.\n","\n","Notice that the SVM with USE embeddings model requires you to run the syntax model on the input texts first.\n","\n","Create a helper method to run both models on a single complaint and return the predicted product groups of both models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"146f73b2-aac8-4ce4-894e-45e0adaf1596","msg_id":"68bcf93d-fd27-4471-9ebb-3f5cae8f131b"},"outputs":[],"source":["def predict_product(text):\n","    # run syntax model first\n","    syntax_result = syntax_model.run(text)\n","    # run SVM model on top of syntax result\n","    svm_preds = svm_model.run(use_model.run(syntax_result, doc_embed_style='raw_text'))\n","    \n","    predicted_svm = svm_preds.to_dict()[\"classes\"][0][\"class_name\"]\n","    \n","    ensemble_preds = ensemble_model.run(text)\n","    predicted_ensemble = ensemble_preds.to_dict()[\"classes\"][0][\"class_name\"]\n","    return (predicted_svm, predicted_ensemble)"]},{"cell_type":"markdown","metadata":{"id":"c0150739-b655-4b94-bb14-12b58ea29905"},"source":["Run the models on the complete test data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"426c35ff-c049-4c39-a9d0-084f053db050","msg_id":"8b660333-870a-4929-aa1d-e62caf3667cf"},"outputs":[],"source":["predictions = test_orig_df[text_col].apply(lambda text: predict_product(text))\n","predictions_df = pd.DataFrame.from_records(predictions, columns=('Predicted SVM', 'Predicted Ensemble'))\n","   \n","result_df = test_orig_df[[text_col, \"Product\"]].merge(predictions_df, how='left', left_index=True, right_index=True)\n","result_df.head()"]},{"cell_type":"markdown","metadata":{"id":"d923a5c1-2c7c-460d-b7bc-73880b999a3f"},"source":["### Out-of-the-box model evaluation using Watson NLP"]},{"cell_type":"markdown","metadata":{"id":"49954f72-7d17-4a33-a090-64d119d5262e"},"source":["Watson NLP offers a method to calculate different quality metrics for a given model. Use the test data to evaluate the quality of your models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5a15ff2a-1f46-49e7-bd84-b9a32efd17bd","msg_id":"88df3e32-976e-41a6-a8d9-6b328e335381"},"outputs":[],"source":["# run the models on the test data - this time in batch mode\n","preprocess_func = lambda raw_doc: use_model.run_batch(syntax_model.run_batch(raw_doc))\n","svm_model.evaluate_quality(test_file, preprocess_func=preprocess_func)"]},{"cell_type":"markdown","metadata":{"id":"82255bf2-47ea-4c84-aa13-de545d2bb1e4"},"source":["You can see that the precision, recall and f1-measure for some classes is much lower than for others. The reason might be that it is difficult to differentiate between some classes. \n","\n","To find out if this is true, create a custom confusion matrix to see if there are classes that seem to be very close and might have been classified inappropriately."]},{"cell_type":"markdown","metadata":{"id":"c68ca5eb-eb69-40bd-83c8-f984c740c522"},"source":["### Creating and plotting a confusion matrix"]},{"cell_type":"markdown","metadata":{"id":"030b1678-3fac-49a7-8c97-a42c3e496263"},"source":["Use the pandas *crosstab* to create a confusion matrix for both the SVM and the ensemble model and plot them as *Seaborn* heatmaps."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3103777-c4b8-4a32-baf9-7c8a306f5b19","msg_id":"f535fce7-d4a7-4a7b-a5d9-02e343df73f0"},"outputs":[],"source":["SVM_confusion_df = pd.crosstab(result_df['Product'], result_df['Predicted SVM'], rownames=['Actual'], normalize='index')\n","ensemble_confusion_df = pd.crosstab(result_df['Product'], result_df['Predicted Ensemble'], rownames=['Actual'], normalize='index')\n","\n","figure, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,7))\n","\n","sn.heatmap(SVM_confusion_df, annot=True, cmap=\"YlGnBu\", ax=ax1, cbar=False)\n","sn.heatmap(ensemble_confusion_df, annot=True, cmap=\"YlGnBu\", ax=ax2, cbar=False)\n","ax1.title.set_text(\"SVM\")\n","ax2.title.set_text(\"Ensemble\")\n","ax2.set_yticklabels([])\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"081bae89-6295-4813-aaa1-22f703ccf61f"},"source":["#### Findings\n","\n","In the confusion matrix for the SVM model you can now see that complaints for `Credit reporting, credit repair services, or other personal consumer reports` are often misclassified as `Debt collection` - and vice versa. Other common misclassifications can be gathered from the table.\n","\n","Overall, the ensemble model performs better than the SVM model. \n","\n","In subsequent steps, consider increasing the size of the training data or adjusting the weights of the ensemble model to gain better results."]},{"cell_type":"markdown","metadata":{"id":"5eb6fb72-bdfc-4065-9993-123c904556a8"},"source":["<a id=\"summary\"></a>\n","## Summary"]},{"cell_type":"markdown","metadata":{"id":"06180a3b-c3fd-4df8-8894-77ce43e8865f"},"source":["This notebook shows you how to use the Watson NLP library and how quickly and easily you can train and run different text classifiers using Watson NLP."]},{"cell_type":"markdown","metadata":{"id":"bbbfe417-ba3a-4b39-b4e0-d510af1599e9"},"source":["### Authors\n","Simone Zerfass IBM, Germany\n","\n","Alexander Lang IBM, Germany"]},{"cell_type":"markdown","metadata":{"id":"a93d3d2e-779b-45bb-9c98-fa0ae595566c"},"source":["# <hr>\n","Copyright © 2021-2024 IBM. This notebook and its source code are released under the terms of the MIT License."]}],"metadata":{"kernelspec":{"display_name":"Python 3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":4}
